{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a954e92e-393d-485a-a5d1-a90c17afc38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e47093c0-791d-4ea7-a826-83403ad07983",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolov1(nn.Module):\n",
    "    def __init__(self,S=7, B=2, C=20):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet152(pretrained=True)\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-2]) \n",
    "\n",
    "        # YOLO Detection Head (Example)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2048*7*7, 4096),\n",
    "            nn.Dropout(0.0),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(4096, S*S*(C+B*5))\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84803024-b137-4276-a9fc-e97317482469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1470])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1,3,224,224)\n",
    "yolo = Yolov1()\n",
    "yolo(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890561d9-e72d-4896-8c1b-95ac94fa0ca5",
   "metadata": {},
   "source": [
    "#=============================================================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fc36ff9-3e33-410c-b08b-484f6387483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bn_act = True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias= not bn_act, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.LeakyReLU(0.1)\n",
    "        self.use_bn_act = bn_act\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_bn_act:\n",
    "            return self.act(self.bn(self.conv(x)))\n",
    "        else:\n",
    "            return self.conv(x)             \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "799cedf0-59f0-44f4-9ca8-6891700a2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScalePrediction(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.head = nn.Sequential(\n",
    "            CNNBlock(in_channels, 2*in_channels,kernel_size=3, padding=1),\n",
    "            CNNBlock(2*in_channels, (num_classes +5) *3, bn_act=False, kernel_size=1), #[po, x, y, w,h]\n",
    "        )\n",
    "        self.num_classes = num_classes\n",
    "    def forward(self,x):\n",
    "        x = self.head(x)\n",
    "        x = x.reshape(x.shape[0], 3, self.num_classes + 5, x.shape[2], x.shape[3])\n",
    "        x = x.permute(0,1,3,4,2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed32450d-c2a8-4029-a787-ccef1fc77919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 222, 222])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = CNNBlock(3,64,kernel_size=3)\n",
    "conv(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23d477ca-b477-4024-a9ec-52e8045fc0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolov3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet152(pretrained=True)\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-2]) \n",
    "\n",
    "        # YOLO Detection Head (Example)\n",
    "        self.head = ScalePrediction(2048, 20)\n",
    "    def forward(self,x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65ea4104-324f-4c63-97f0-b8435d8b00e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 7, 7, 25])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1,3,224,224)\n",
    "yolo = Yolov3()\n",
    "yolo(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa853c41-f99e-4e93-a3f1-05ae29b9d4ab",
   "metadata": {},
   "source": [
    "#==================================================================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537028e0-488d-49db-b150-de04f73eef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFL(nn.Module):\n",
    "    \"\"\"\n",
    "    Integral module of Distribution Focal Loss (DFL).\n",
    "\n",
    "    Proposed in Generalized Focal Loss https://ieeexplore.ieee.org/document/9792391\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, c1=16):\n",
    "        \"\"\"Initialize a convolutional layer with a given number of input channels.\"\"\"\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(c1, 1, 1, bias=False).requires_grad_(False)\n",
    "        x = torch.arange(c1, dtype=torch.float)\n",
    "        self.conv.weight.data[:] = nn.Parameter(x.view(1, c1, 1, 1))\n",
    "        self.c1 = c1\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Applies a transformer layer on input tensor 'x' and returns a tensor.\"\"\"\n",
    "        b, _, a = x.shape  # batch, channels, anchors\n",
    "        return self.conv(x.view(b, 4, self.c1, a).transpose(2, 1).softmax(1)).view(b, 4, a)\n",
    "        # return self.conv(x.view(b, self.c1, 4, a).softmax(1)).view(b, 4, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87558d21-1f20-47bd-9a50-97e1bd07310e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3da37274-afbb-46e7-a24e-e01ed993ad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = deque(maxlen=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7d29d7b-52d9-4511-ad4f-5ba4c3c15419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([], maxlen=10000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ae5fafe-841d-484f-aed6-aa761264b764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([10, 10, 11, 1, 2, 3], maxlen=10000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.extend([1,2,3])\n",
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a86824d7-a148-451b-8ecf-a98f4f8e8d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.deque"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "969b995a-8bde-4fdb-941d-c641adea30af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 0 Shape: torch.Size([1, 80, 80, 85])\n",
      "Output 1 Shape: torch.Size([1, 40, 40, 85])\n",
      "Output 2 Shape: torch.Size([1, 20, 20, 85])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class YOLOv8Detect(nn.Module):\n",
    "    def __init__(self, num_classes=80, num_features=3, ch_in=[256, 512, 1024]):\n",
    "        \"\"\"\n",
    "        YOLOv8 Detection Head\n",
    "        :param num_classes: Number of object classes\n",
    "        :param num_features: Number of feature levels (e.g., P3, P4, P5)\n",
    "        :param ch_in: Input channels from backbone/FPN (P3, P4, P5)\n",
    "        \"\"\"\n",
    "        super(YOLOv8Detect, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_features = num_features\n",
    "        \n",
    "        self.reg_heads = nn.ModuleList()  # Regression heads (box prediction)\n",
    "        self.cls_heads = nn.ModuleList()  # Classification heads\n",
    "        self.obj_heads = nn.ModuleList()  # Objectness score heads\n",
    "\n",
    "        for ch in ch_in:\n",
    "            self.reg_heads.append(self._conv_block(ch, 4))       # Box regression: (x, y, w, h)\n",
    "            self.cls_heads.append(self._conv_block(ch, num_classes))  # Classification\n",
    "            self.obj_heads.append(self._conv_block(ch, 1))       # Objectness score\n",
    "        \n",
    "    def _conv_block(self, in_channels, out_channels):\n",
    "        \"\"\"Basic Conv Block for Detection Head\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels, out_channels, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of YOLOv8 detection head\n",
    "        :param x: List of feature maps from backbone (P3, P4, P5)\n",
    "        :return: Bounding boxes, class scores, and objectness scores\n",
    "        \"\"\"\n",
    "        outputs = []\n",
    "        for i in range(self.num_features):\n",
    "            reg = self.reg_heads[i](x[i])  # (B, 4, H, W)\n",
    "            cls = self.cls_heads[i](x[i])  # (B, num_classes, H, W)\n",
    "            obj = self.obj_heads[i](x[i])  # (B, 1, H, W)\n",
    "            \n",
    "            # Reshape to match YOLO format\n",
    "            reg = reg.permute(0, 2, 3, 1).contiguous()  # (B, H, W, 4)\n",
    "            cls = cls.permute(0, 2, 3, 1).contiguous()  # (B, H, W, num_classes)\n",
    "            obj = obj.permute(0, 2, 3, 1).contiguous()  # (B, H, W, 1)\n",
    "            \n",
    "            # Concatenate all predictions\n",
    "            out = torch.cat([reg, obj, cls], dim=-1)  # (B, H, W, 4 + 1 + num_classes)\n",
    "            outputs.append(out)\n",
    "        \n",
    "        return outputs  # List of feature maps with predictions\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    model = YOLOv8Detect(num_classes=80)\n",
    "    P3, P4, P5 = torch.randn(1, 256, 80, 80), torch.randn(1, 512, 40, 40), torch.randn(1, 1024, 20, 20)\n",
    "    preds = model([P3, P4, P5])\n",
    "    for i, p in enumerate(preds):\n",
    "        print(f\"Output {i} Shape: {p.shape}\")  # Expecting (1, H, W, num_classes + 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "770f56ba-9092-4486-bd6f-06b6e7b7922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class YOLOv8Detect(nn.Module):\n",
    "    def __init__(self, num_classes=80, num_features=3, ch_in=[256, 512, 1024], inference = False):\n",
    "        \"\"\"\n",
    "        YOLOv8 Detection Head with Post-Processing\n",
    "        :param num_classes: Number of object classes\n",
    "        :param num_features: Number of feature levels (e.g., P3, P4, P5)\n",
    "        :param ch_in: Input channels from backbone/FPN (P3, P4, P5)\n",
    "        \"\"\"\n",
    "        super(YOLOv8Detect, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_features = num_features\n",
    "        \n",
    "        self.reg_heads = nn.ModuleList()\n",
    "        self.cls_heads = nn.ModuleList()\n",
    "        self.obj_heads = nn.ModuleList()\n",
    "\n",
    "        for ch in ch_in:\n",
    "            self.reg_heads.append(self._conv_block(ch, 4))       # Box regression: (x, y, w, h)\n",
    "            self.cls_heads.append(self._conv_block(ch, num_classes))  # Classification\n",
    "            self.obj_heads.append(self._conv_block(ch, 1))       # Objectness score\n",
    "        \n",
    "    def _conv_block(self, in_channels, out_channels):\n",
    "        \"\"\"Basic Conv Block for Detection Head\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels, out_channels, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of YOLOv8 detection head\n",
    "        :param x: List of feature maps from backbone (P3, P4, P5)\n",
    "        :return: List of bounding boxes, class scores, and objectness scores\n",
    "        \"\"\"\n",
    "        outputs = []\n",
    "        for i in range(self.num_features):\n",
    "            reg = self.reg_heads[i](x[i])  # (B, 4, H, W)\n",
    "            cls = self.cls_heads[i](x[i])  # (B, num_classes, H, W)\n",
    "            obj = self.obj_heads[i](x[i])  # (B, 1, H, W)\n",
    "            \n",
    "            # Reshape to match YOLO format\n",
    "            reg = reg.permute(0, 2, 3, 1).contiguous()  # (B, H, W, 4)\n",
    "            cls = cls.permute(0, 2, 3, 1).contiguous()  # (B, H, W, num_classes)\n",
    "            obj = obj.permute(0, 2, 3, 1).contiguous()  # (B, H, W, 1)\n",
    "            \n",
    "            # Concatenate all predictions\n",
    "            out = torch.cat([reg, obj, cls], dim=-1)  # (B, H, W, 4 + 1 + num_classes)\n",
    "            outputs.append(out)\n",
    "        \n",
    "        return self.decode_predictions(outputs)\n",
    "\n",
    "    def decode_predictions(self, outputs, conf_thresh=0.3, iou_thresh=0.5):\n",
    "        \"\"\"\n",
    "        Decode predictions and apply Non-Maximum Suppression (NMS)\n",
    "        :param outputs: Raw predictions from the model\n",
    "        :param conf_thresh: Confidence threshold\n",
    "        :param iou_thresh: IOU threshold for NMS\n",
    "        :return: Filtered detections\n",
    "        \"\"\"\n",
    "        batch_detections = []\n",
    "        \n",
    "        for output in outputs:  # Loop over P3, P4, P5 feature maps\n",
    "            B, H, W, C = output.shape  # Get shape\n",
    "            output = output.view(B, H * W, C)  # Flatten spatial dimensions\n",
    "            \n",
    "            # Split predictions\n",
    "            reg = output[..., :4]  # Bounding box (x, y, w, h)\n",
    "            obj = output[..., 4:5]  # Objectness score\n",
    "            cls = output[..., 5:]  # Class scores\n",
    "            \n",
    "            # Convert objectness and class scores\n",
    "            obj = obj.sigmoid()  # Normalize objectness\n",
    "            cls = cls.softmax(dim=-1)  # Normalize class probabilities\n",
    "            \n",
    "            # Compute final confidence score\n",
    "            scores, labels = cls.max(dim=-1)  # Get highest confidence class\n",
    "            scores = scores * obj.squeeze(-1)  # Multiply by objectness score\n",
    "            \n",
    "            # Filter by confidence threshold\n",
    "            mask = scores > conf_thresh\n",
    "            reg, scores, labels = reg[mask], scores[mask], labels[mask]\n",
    "\n",
    "            # Apply Non-Maximum Suppression (NMS)\n",
    "            if reg.shape[0] > 0:\n",
    "                keep = self.nms(reg, scores, iou_thresh)\n",
    "                batch_detections.append((reg[keep], scores[keep], labels[keep]))\n",
    "\n",
    "        return batch_detections\n",
    "\n",
    "    def nms(self, boxes, scores, iou_thresh):\n",
    "        \"\"\"\n",
    "        Apply Non-Maximum Suppression (NMS)\n",
    "        :param boxes: Bounding boxes\n",
    "        :param scores: Confidence scores\n",
    "        :param iou_thresh: IOU threshold\n",
    "        :return: Indices of kept boxes\n",
    "        \"\"\"\n",
    "        keep = []\n",
    "        _, idxs = scores.sort(descending=True)  # Sort by score\n",
    "\n",
    "        while idxs.numel() > 0:\n",
    "            max_idx = idxs[0]  # Highest confidence box\n",
    "            keep.append(max_idx)\n",
    "\n",
    "            if idxs.numel() == 1:\n",
    "                break\n",
    "\n",
    "            ious = self.iou(boxes[max_idx], boxes[idxs[1:]])\n",
    "            idxs = idxs[1:][ious < iou_thresh]  # Keep boxes with low IOU\n",
    "\n",
    "        return torch.tensor(keep, dtype=torch.long)\n",
    "\n",
    "    def iou(self, box1, boxes):\n",
    "        \"\"\"\n",
    "        Compute Intersection over Union (IoU)\n",
    "        :param box1: Single bounding box\n",
    "        :param boxes: Multiple bounding boxes\n",
    "        :return: IoU values\n",
    "        \"\"\"\n",
    "        # Compute intersection\n",
    "        x1 = torch.max(box1[0], boxes[:, 0])\n",
    "        y1 = torch.max(box1[1], boxes[:, 1])\n",
    "        x2 = torch.min(box1[2], boxes[:, 2])\n",
    "        y2 = torch.min(box1[3], boxes[:, 3])\n",
    "\n",
    "        inter_area = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
    "\n",
    "        # Compute union\n",
    "        box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        boxes_area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "        union_area = box1_area + boxes_area - inter_area\n",
    "\n",
    "        return inter_area / (union_area + 1e-6)  # Avoid division by zero\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    model = YOLOv8Detect(num_classes=80)\n",
    "    P3, P4, P5 = torch.randn(1, 256, 80, 80), torch.randn(1, 512, 40, 40), torch.randn(1, 1024, 20, 20)\n",
    "    detections = model([P3, P4, P5])\n",
    "\n",
    "    # Print detections\n",
    "    for i, (boxes, scores, labels) in enumerate(detections):\n",
    "        print(f\"Feature Map {i}: {len(boxes)} detections\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fea0128c-29df-447f-8504-a8db41112c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLOv8Detect(num_classes=80)\n",
    "P3, P4, P5 = torch.randn(1, 256, 80, 80), torch.randn(1, 512, 40, 40), torch.randn(1, 1024, 20, 20)\n",
    "detections = model([P3, P4, P5])\n",
    "\n",
    "# Print detections\n",
    "for i, (boxes, scores, labels) in enumerate(detections):\n",
    "    print(f\"Feature Map {i}: {len(boxes)} detections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b88b934-b835-4e8e-bfaa-31a7c5b3b731",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'python' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpython\u001b[49m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m-\u001b[39mversion\n",
      "\u001b[1;31mNameError\u001b[0m: name 'python' is not defined"
     ]
    }
   ],
   "source": [
    "python--version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8602588a-9088-436a-8864-21d9cb276b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.18\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac6cf55-0a29-4a8e-b413-982486e5fb28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
