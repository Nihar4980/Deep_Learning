{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56f08aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6af4f887-a071-4f31-a5d9-ebce7a377d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBnAct(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 n_in, # Input Channels\n",
    "                 n_out, # Output Channels\n",
    "                 kernel_size = 3, \n",
    "                 stride = 1, \n",
    "                 padding = 0, \n",
    "                 groups = 1, \n",
    "                 bn = True, # Batch Norm\n",
    "                 act = True, # Activation\n",
    "                 bias = False\n",
    "                ):\n",
    "        \n",
    "        super(ConvBnAct, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels=n_in, \n",
    "                              out_channels=n_out, \n",
    "                              kernel_size=kernel_size, \n",
    "                              stride=stride, \n",
    "                              padding=padding, \n",
    "                              groups=groups, \n",
    "                              bias=bias\n",
    "                             )\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=n_out) if bn else nn.Identity()\n",
    "        self.activation = nn.LeakyReLU() if act else nn.Identity()\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.activation(self.batch_norm(self.conv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77d2ebf6-c542-4926-83ee-c9346786b860",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OSAModule(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 n_in, # Input Channels\n",
    "                 n_stage,# Channels in stage\n",
    "                 n_out, # Output channel (after aggregation)\n",
    "                 n_layers_per_block # number of layers per block\n",
    "                ):\n",
    "        super(OSAModule, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        n_input = n_in\n",
    "\n",
    "        for _ in range(n_layers_per_block):\n",
    "            self.layers.append(ConvBnAct(n_input, \n",
    "                                         n_stage, \n",
    "                                         kernel_size=3, \n",
    "                                         stride=1, \n",
    "                                         padding=1, \n",
    "                                         groups=1, \n",
    "                                         bn=True, \n",
    "                                         act=True\n",
    "                                        ))\n",
    "            n_input = n_stage\n",
    "        \n",
    "        #self.layers = nn.Sequential(*self.layers)\n",
    "            \n",
    "        # Feature Aggregation\n",
    "        n_input = n_in + (n_layers_per_block * n_stage)\n",
    "        \n",
    "        self.feat_aggregation = ConvBnAct(n_input, \n",
    "                                          n_out, \n",
    "                                          kernel_size=1, \n",
    "                                          stride=1, \n",
    "                                          padding=0, \n",
    "                                          groups=1, \n",
    "                                          bn=True, \n",
    "                                          act=True\n",
    "                                         )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        output = []\n",
    "        output.append(x)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            output.append(x)\n",
    "        \n",
    "        # Concat and Aggregate\n",
    "        x = torch.cat(output, dim=1)\n",
    "        #print(x.shape)\n",
    "        x = self.feat_aggregation(x)\n",
    "        print(self.feat_aggregation.conv.in_channels)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08ecdf29-8c4c-40a0-8fd1-cf444eae96db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 64, 64])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = OSAModule(n_in = 128, #VoVNet-27-Slim-Configuration (Stage-2 OSA Module)\n",
    "                  n_stage=64, \n",
    "                  n_out=128,\n",
    "                  n_layers_per_block = 5\n",
    "                 )\n",
    "x = torch.randn(1, 128, 64, 64)\n",
    "block(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "092b1a56-08ef-4c20-b8f6-b680d2c84f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Conv2d(3,12, 1).in_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9064987-9ae7-41ed-a95f-b186028e5832",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepConv(nn.Module):\n",
    "    def __init__(self, \n",
    "                 n_in, # Input Channels\n",
    "                 n_out):\n",
    "        super(RepConv, self).__init__()\n",
    "        self.conv3x3 = nn.Conv2d(n_in, n_out,3,padding=1)\n",
    "        self.conv1X1 = nn.Conv2d(n_in, n_out,1)\n",
    "        self.bn = nn.BatchNorm2d(n_in)\n",
    "    def forward(self, x):\n",
    "        x = self.conv3x3(x) + self.conv1X1(x) + self.bn(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "285fee25-3be0-4ff8-9c71-85354b1f3088",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RepConv(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b4b5341-d48f-4810-87c5-f5b1f27413a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.randn(1,3,224,224)\n",
    "model(y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32bcd826-b693-4598-828e-5a266becada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELAN(nn.Module):\n",
    "    \n",
    "    '''\n",
    "      Combine CSPNet + VoVNet (OSA Stages)\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 n_in, # Input channels\n",
    "                 n_stage, # Channels in stage\n",
    "                 n_out, # Output channels\n",
    "                 n_layers_per_block = 2, # number of layers per block,\n",
    "                 n_stages_to_combine = 2 # number of stages before aggregating\n",
    "                ):\n",
    "        super(ELAN, self).__init__()\n",
    "        \n",
    "        # CSP Layers\n",
    "        self.base_layer = nn.Sequential(\n",
    "            ConvBnAct(n_in, \n",
    "                      2 * n_in, \n",
    "                      kernel_size=3, \n",
    "                      stride=1, \n",
    "                      padding=1, \n",
    "                      groups=1, \n",
    "                      bn=True, \n",
    "                      act=True\n",
    "                     ), \n",
    "            ConvBnAct(2 * n_in, \n",
    "                      n_in, \n",
    "                      kernel_size=1, \n",
    "                      stride=1, \n",
    "                      padding=0, \n",
    "                      groups=1, \n",
    "                      bn=True, \n",
    "                      act=True\n",
    "                     ),\n",
    "        )\n",
    "        # VoVNet layers\n",
    "        n_input = n_in//2\n",
    "        self.stage_layers = []\n",
    "        \n",
    "        for _ in range(n_stages_to_combine):\n",
    "            block_layers = []\n",
    "            for _ in range(n_layers_per_block):\n",
    "                block_layers.append(ConvBnAct(n_input, \n",
    "                                              n_stage, \n",
    "                                              kernel_size=3, \n",
    "                                              stride=1, \n",
    "                                              padding=1, \n",
    "                                              groups=1, \n",
    "                                              bn=True, \n",
    "                                              act=True\n",
    "                                             )\n",
    "                                   ) \n",
    "                n_input = n_stage\n",
    "             # Collect feature after every stage\n",
    "            block_layers = nn.Sequential(*block_layers)\n",
    "            self.stage_layers.append(block_layers)\n",
    "        \n",
    "        self.stage_layers = nn.Sequential(*self.stage_layers)\n",
    "        \n",
    "        # Feature Aggregation\n",
    "        n_input = n_in + n_in//2 + (n_stages_to_combine * n_stage)\n",
    "        \n",
    "        self.feat_aggregation = ConvBnAct(n_input, \n",
    "                                          n_out, \n",
    "                                          kernel_size=1, \n",
    "                                          stride=1, \n",
    "                                          padding=0, \n",
    "                                          groups=1, \n",
    "                                          bn=True, \n",
    "                                          act=True\n",
    "                                         )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = []\n",
    "        output.append(x)\n",
    "        \n",
    "        # Base layer\n",
    "        x = self.base_layer(x)\n",
    "        \n",
    "        # Partition in 2 parts\n",
    "        x1, x2 = x.chunk(2, dim=1)\n",
    "        output.append(x1)\n",
    "        \n",
    "        for layer in self.stage_layers:\n",
    "            x2 = layer(x2)\n",
    "            output.append(x2)\n",
    "        \n",
    "        # Concat and Aggregate\n",
    "        [print(i.shape) for i in output]\n",
    "        x = torch.cat(output, dim=1)\n",
    "        x = self.feat_aggregation(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72de44a0-367f-46b4-b7ae-9f300237a191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 64, 64])\n",
      "torch.Size([1, 64, 64, 64])\n",
      "torch.Size([1, 64, 64, 64])\n",
      "torch.Size([1, 64, 64, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-7.6246e-04,  3.7295e-01,  5.0131e-01,  ..., -1.7312e-02,\n",
       "            7.3806e-01, -1.5050e-02],\n",
       "          [ 9.3829e-01, -1.3767e-02,  6.8926e-01,  ..., -5.1319e-03,\n",
       "            1.6566e+00,  9.0356e-01],\n",
       "          [ 1.1516e+00, -6.7091e-03,  5.6886e-01,  ..., -2.0229e-02,\n",
       "            2.2276e-01, -1.2774e-02],\n",
       "          ...,\n",
       "          [ 5.6693e-02, -1.4866e-02, -1.1851e-02,  ...,  8.7788e-01,\n",
       "           -2.6503e-04, -8.9352e-03],\n",
       "          [-1.2073e-02,  1.5202e-01, -7.4300e-03,  ...,  1.2531e+00,\n",
       "           -1.8616e-02, -3.8209e-03],\n",
       "          [-1.7929e-02,  1.1516e+00,  3.7885e-01,  ...,  1.9867e-01,\n",
       "           -9.1930e-03, -1.1661e-02]],\n",
       "\n",
       "         [[ 1.7268e+00,  4.7714e-01,  4.1079e-01,  ...,  2.9288e-01,\n",
       "           -6.6743e-03, -1.0654e-04],\n",
       "          [ 1.3292e+00,  1.7059e+00, -7.0571e-03,  ...,  5.1221e-01,\n",
       "            2.1367e-01,  6.6429e-02],\n",
       "          [ 4.6191e-01, -1.2336e-03, -1.3481e-02,  ...,  2.7611e-01,\n",
       "            8.9970e-01,  5.1949e-01],\n",
       "          ...,\n",
       "          [ 6.5845e-01,  5.3471e-01,  1.4731e-01,  ..., -1.6269e-03,\n",
       "           -2.1268e-02, -9.4379e-03],\n",
       "          [ 5.1453e-01, -7.2377e-03,  1.8978e+00,  ...,  8.2104e-01,\n",
       "           -5.9046e-03,  3.9412e-01],\n",
       "          [ 2.3054e-01, -5.2996e-03, -1.7640e-02,  ...,  1.5521e+00,\n",
       "            7.9610e-01, -1.3800e-02]],\n",
       "\n",
       "         [[ 9.7599e-01, -7.0875e-03, -5.9287e-03,  ..., -4.4222e-03,\n",
       "            4.8700e-01, -2.0810e-02],\n",
       "          [ 7.0093e-01, -1.6523e-02, -9.5780e-03,  ...,  1.8599e-01,\n",
       "           -1.5201e-02, -1.0671e-02],\n",
       "          [ 8.9376e-01, -5.5402e-03,  3.5653e-02,  ..., -3.9210e-03,\n",
       "            1.0328e-01,  1.4419e-01],\n",
       "          ...,\n",
       "          [ 1.6649e+00,  2.8361e-01,  1.5298e+00,  ...,  5.1234e-01,\n",
       "           -1.7312e-02, -4.5880e-03],\n",
       "          [ 8.5121e-01, -2.1337e-02, -8.8534e-03,  ..., -3.0694e-03,\n",
       "           -1.8544e-02, -4.7065e-03],\n",
       "          [ 6.5577e-01,  4.1358e-01, -1.4421e-02,  ...,  1.6216e+00,\n",
       "           -4.5331e-03, -4.3798e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.3569e+00, -4.4166e-03,  4.7778e-01,  ...,  9.2214e-01,\n",
       "            5.9774e-01, -2.5820e-03],\n",
       "          [ 2.7082e-01,  5.1525e-01,  1.2376e+00,  ..., -1.5138e-02,\n",
       "           -1.2948e-02, -1.3524e-03],\n",
       "          [-1.1782e-03, -6.6472e-03,  7.3887e-02,  ..., -5.3417e-03,\n",
       "            4.8755e-01, -1.3211e-02],\n",
       "          ...,\n",
       "          [ 9.7896e-01, -9.9389e-03, -2.8263e-02,  ..., -1.1582e-02,\n",
       "           -7.3285e-04, -7.2626e-04],\n",
       "          [ 8.5965e-01, -1.6204e-03,  5.4601e-01,  ...,  2.3746e+00,\n",
       "            1.1248e+00,  9.1586e-01],\n",
       "          [-1.2461e-03, -9.7654e-04, -3.2337e-03,  ..., -1.9568e-02,\n",
       "            1.8250e+00, -8.3009e-03]],\n",
       "\n",
       "         [[ 5.4697e-01,  8.6229e-01,  3.8868e-01,  ..., -3.5766e-03,\n",
       "            1.2375e+00, -3.1692e-03],\n",
       "          [-3.3644e-03,  9.9457e-01, -1.3137e-03,  ...,  1.4321e+00,\n",
       "           -1.5742e-03,  2.5935e-01],\n",
       "          [ 1.8136e+00, -5.4897e-03, -7.4846e-03,  ...,  1.3049e+00,\n",
       "           -2.8911e-03,  2.7037e-01],\n",
       "          ...,\n",
       "          [ 6.8507e-01,  7.4847e-01,  4.4615e-01,  ...,  1.8273e+00,\n",
       "           -4.5060e-03,  7.5082e-01],\n",
       "          [ 9.0442e-02, -7.2435e-03,  6.4307e-01,  ...,  7.0564e-02,\n",
       "           -8.2986e-03, -6.9925e-03],\n",
       "          [-1.0580e-02, -4.2113e-03, -1.6095e-02,  ..., -1.0340e-02,\n",
       "           -6.0101e-03, -9.3103e-03]],\n",
       "\n",
       "         [[-7.7753e-03, -4.1968e-03,  8.1218e-01,  ...,  6.3173e-01,\n",
       "           -1.1032e-02, -1.2153e-02],\n",
       "          [ 3.0268e-01,  5.5298e-02, -9.8754e-03,  ..., -3.8460e-03,\n",
       "           -4.9085e-03, -1.1122e-02],\n",
       "          [ 1.0741e+00, -1.5244e-02,  1.3234e+00,  ..., -6.1127e-03,\n",
       "           -9.6084e-03,  1.3440e+00],\n",
       "          ...,\n",
       "          [ 1.4159e+00, -6.7873e-03,  1.0904e+00,  ...,  9.8289e-03,\n",
       "           -1.1527e-02, -1.6983e-03],\n",
       "          [ 4.8077e-02,  1.7323e-01, -3.1509e-04,  ..., -5.5961e-03,\n",
       "           -8.6485e-03, -1.4037e-02],\n",
       "          [ 1.2932e+00, -2.8745e-03,  8.4319e-01,  ..., -3.0848e-03,\n",
       "            1.1372e-01, -3.5248e-03]]]], grad_fn=<LeakyReluBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "block = ELAN(n_in = 128,\n",
    "             n_stage=64, \n",
    "             n_out=128,\n",
    "             n_layers_per_block = 2,\n",
    "             n_stages_to_combine = 2\n",
    "            )\n",
    "\n",
    "x = torch.randn(1, 128, 64, 64)\n",
    "block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c75cc4-4d6c-4d8b-b22e-2a1ba6588d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class E_ELAN(nn.Module):\n",
    "    \n",
    "    '''\n",
    "      Extension of ELAN\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 n_in, # Input channels\n",
    "                 n_stage, # Channels in stage\n",
    "                 n_out, # Output channels\n",
    "                 n_layers_per_block = 2, # number of layers per block,\n",
    "                 n_stages_to_combine = 2 # number of stages before aggregating\n",
    "                ):\n",
    "        super(E_ELAN, self).__init__()\n",
    "        \n",
    "        # CSP Layers\n",
    "        self.base_layer = nn.Sequential(\n",
    "            ConvBnAct(n_in, \n",
    "                      2 * n_in, \n",
    "                      kernel_size=3, \n",
    "                      stride=1, \n",
    "                      padding=1, \n",
    "                      groups=n_in, \n",
    "                      bn=True, \n",
    "                      act=True\n",
    "                     ), \n",
    "            ConvBnAct(2 * n_in, \n",
    "                      n_in, \n",
    "                      kernel_size=1, \n",
    "                      stride=1, \n",
    "                      padding=0, \n",
    "                      groups=1, \n",
    "                      bn=True, \n",
    "                      act=True\n",
    "                     ),\n",
    "        )\n",
    "        # VoVNet layers\n",
    "        n_input = n_in//2\n",
    "        self.stage_layers = []\n",
    "        \n",
    "        for _ in range(n_stages_to_combine):\n",
    "            block_layers = []\n",
    "            for _ in range(n_layers_per_block):\n",
    "                block_layers.append(ConvBnAct(n_input, \n",
    "                                              n_stage, \n",
    "                                              kernel_size=3, \n",
    "                                              stride=1, \n",
    "                                              padding=1, \n",
    "                                              groups=1, \n",
    "                                              bn=True, \n",
    "                                              act=True\n",
    "                                             )\n",
    "                                   ) \n",
    "                n_input = n_stage\n",
    "             # Collect feature after every stage\n",
    "            block_layers = nn.Sequential(*block_layers)\n",
    "            self.stage_layers.append(block_layers)\n",
    "        \n",
    "        self.stage_layers = nn.Sequential(*self.stage_layers)\n",
    "        \n",
    "        # Feature Aggregation\n",
    "        n_input = n_in + n_in//2 + (n_stages_to_combine * n_stage)\n",
    "        \n",
    "        self.feat_aggregation = ConvBnAct(n_input, \n",
    "                                          n_out, \n",
    "                                          kernel_size=1, \n",
    "                                          stride=1, \n",
    "                                          padding=0, \n",
    "                                          groups=1, \n",
    "                                          bn=True, \n",
    "                                          act=True\n",
    "                                         )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = []\n",
    "        output.append(x)\n",
    "        \n",
    "        # Base layer\n",
    "        x = self.base_layer(x)\n",
    "        \n",
    "        # Partition in 2 parts\n",
    "        x1, x2 = x.chunk(2, dim=1)\n",
    "        output.append(x1)\n",
    "        \n",
    "        for layer in self.stage_layers:\n",
    "            x2 = layer(x2)\n",
    "            output.append(x2)\n",
    "        \n",
    "        # Concat and Aggregate\n",
    "        [print(i.shape) for i in output]\n",
    "        x = torch.cat(output, dim=1)\n",
    "        x = self.feat_aggregation(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fc44c8-393f-44d9-ad1c-9c0303bc27fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd80b1de-ff77-4cf2-8a05-24fa84b8f2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow-pytorch)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
