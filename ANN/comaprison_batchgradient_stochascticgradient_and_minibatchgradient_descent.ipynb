{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8be35e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20b33714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Social_Network_Ads.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df45fc21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fc920bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b030a8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Gender           400 non-null    object\n",
      " 1   Age              400 non-null    int64 \n",
      " 2   EstimatedSalary  400 non-null    int64 \n",
      " 3   Purchased        400 non-null    int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 12.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19199f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4efc1682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age  EstimatedSalary  Purchased\n",
       "0       1   19            19000          0\n",
       "1       1   35            20000          0\n",
       "2       0   26            43000          0\n",
       "3       0   27            57000          0\n",
       "4       1   19            76000          0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = LabelEncoder()\n",
    "df['Gender'] = ohe.fit_transform(df['Gender'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75f4f81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "041a1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44f9c80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adbb1003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b15d8f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "188d8b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10,activation='relu',input_dim=3))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab795dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                40        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87144d34",
   "metadata": {},
   "source": [
    "# Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2508898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nihar\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\data_adapter.py:1508: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.7269 - accuracy: 0.4648 - val_loss: 0.6949 - val_accuracy: 0.5469\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7193 - accuracy: 0.4805 - val_loss: 0.6892 - val_accuracy: 0.5781\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7139 - accuracy: 0.5078 - val_loss: 0.6844 - val_accuracy: 0.5938\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7094 - accuracy: 0.5117 - val_loss: 0.6802 - val_accuracy: 0.5781\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7055 - accuracy: 0.5234 - val_loss: 0.6763 - val_accuracy: 0.6094\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7019 - accuracy: 0.5273 - val_loss: 0.6725 - val_accuracy: 0.6406\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6984 - accuracy: 0.5391 - val_loss: 0.6689 - val_accuracy: 0.6406\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6952 - accuracy: 0.5391 - val_loss: 0.6655 - val_accuracy: 0.6562\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6921 - accuracy: 0.5430 - val_loss: 0.6621 - val_accuracy: 0.6719\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6891 - accuracy: 0.5469 - val_loss: 0.6590 - val_accuracy: 0.6875\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6863 - accuracy: 0.5469 - val_loss: 0.6559 - val_accuracy: 0.6875\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6836 - accuracy: 0.5586 - val_loss: 0.6529 - val_accuracy: 0.6719\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6809 - accuracy: 0.5664 - val_loss: 0.6501 - val_accuracy: 0.6719\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6784 - accuracy: 0.5703 - val_loss: 0.6473 - val_accuracy: 0.6875\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6760 - accuracy: 0.5820 - val_loss: 0.6447 - val_accuracy: 0.6875\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6737 - accuracy: 0.5859 - val_loss: 0.6421 - val_accuracy: 0.6875\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6714 - accuracy: 0.5859 - val_loss: 0.6396 - val_accuracy: 0.6875\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6691 - accuracy: 0.5898 - val_loss: 0.6372 - val_accuracy: 0.6875\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6669 - accuracy: 0.5898 - val_loss: 0.6349 - val_accuracy: 0.6875\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6647 - accuracy: 0.5898 - val_loss: 0.6327 - val_accuracy: 0.6875\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6626 - accuracy: 0.5938 - val_loss: 0.6304 - val_accuracy: 0.6875\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6604 - accuracy: 0.6055 - val_loss: 0.6283 - val_accuracy: 0.6875\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6583 - accuracy: 0.6016 - val_loss: 0.6261 - val_accuracy: 0.6875\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6563 - accuracy: 0.5977 - val_loss: 0.6240 - val_accuracy: 0.6875\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6542 - accuracy: 0.5977 - val_loss: 0.6219 - val_accuracy: 0.6875\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6522 - accuracy: 0.5938 - val_loss: 0.6198 - val_accuracy: 0.6875\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6502 - accuracy: 0.5938 - val_loss: 0.6177 - val_accuracy: 0.6875\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6482 - accuracy: 0.5977 - val_loss: 0.6156 - val_accuracy: 0.6875\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6462 - accuracy: 0.5977 - val_loss: 0.6136 - val_accuracy: 0.6875\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6443 - accuracy: 0.5977 - val_loss: 0.6115 - val_accuracy: 0.6875\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6423 - accuracy: 0.6055 - val_loss: 0.6094 - val_accuracy: 0.6875\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6402 - accuracy: 0.6055 - val_loss: 0.6073 - val_accuracy: 0.6719\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6382 - accuracy: 0.6055 - val_loss: 0.6051 - val_accuracy: 0.6719\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6361 - accuracy: 0.6055 - val_loss: 0.6031 - val_accuracy: 0.6719\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6341 - accuracy: 0.5938 - val_loss: 0.6010 - val_accuracy: 0.6719\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6320 - accuracy: 0.5977 - val_loss: 0.5990 - val_accuracy: 0.6719\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6299 - accuracy: 0.5938 - val_loss: 0.5969 - val_accuracy: 0.6875\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6279 - accuracy: 0.6094 - val_loss: 0.5949 - val_accuracy: 0.6875\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6258 - accuracy: 0.6133 - val_loss: 0.5928 - val_accuracy: 0.6875\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6238 - accuracy: 0.6250 - val_loss: 0.5908 - val_accuracy: 0.6875\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6218 - accuracy: 0.6367 - val_loss: 0.5887 - val_accuracy: 0.7031\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6198 - accuracy: 0.6445 - val_loss: 0.5866 - val_accuracy: 0.7031\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6178 - accuracy: 0.6445 - val_loss: 0.5846 - val_accuracy: 0.7031\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6158 - accuracy: 0.6445 - val_loss: 0.5825 - val_accuracy: 0.7031\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6139 - accuracy: 0.6445 - val_loss: 0.5804 - val_accuracy: 0.7031\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6119 - accuracy: 0.6445 - val_loss: 0.5784 - val_accuracy: 0.7031\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6100 - accuracy: 0.6445 - val_loss: 0.5763 - val_accuracy: 0.7031\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6081 - accuracy: 0.6406 - val_loss: 0.5744 - val_accuracy: 0.7031\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6062 - accuracy: 0.6367 - val_loss: 0.5724 - val_accuracy: 0.7031\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6043 - accuracy: 0.6367 - val_loss: 0.5705 - val_accuracy: 0.7031\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6025 - accuracy: 0.6367 - val_loss: 0.5686 - val_accuracy: 0.7031\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6007 - accuracy: 0.6367 - val_loss: 0.5667 - val_accuracy: 0.7031\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5989 - accuracy: 0.6367 - val_loss: 0.5648 - val_accuracy: 0.7031\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5971 - accuracy: 0.6367 - val_loss: 0.5630 - val_accuracy: 0.7031\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5953 - accuracy: 0.6367 - val_loss: 0.5611 - val_accuracy: 0.7031\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5935 - accuracy: 0.6367 - val_loss: 0.5593 - val_accuracy: 0.7031\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5917 - accuracy: 0.6328 - val_loss: 0.5576 - val_accuracy: 0.7031\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5900 - accuracy: 0.6328 - val_loss: 0.5558 - val_accuracy: 0.7031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5882 - accuracy: 0.6328 - val_loss: 0.5540 - val_accuracy: 0.7031\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5864 - accuracy: 0.6328 - val_loss: 0.5523 - val_accuracy: 0.7031\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5847 - accuracy: 0.6328 - val_loss: 0.5505 - val_accuracy: 0.7031\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5829 - accuracy: 0.6328 - val_loss: 0.5488 - val_accuracy: 0.7031\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5812 - accuracy: 0.6328 - val_loss: 0.5471 - val_accuracy: 0.7031\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5794 - accuracy: 0.6328 - val_loss: 0.5453 - val_accuracy: 0.6875\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5777 - accuracy: 0.6328 - val_loss: 0.5436 - val_accuracy: 0.6875\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5760 - accuracy: 0.6328 - val_loss: 0.5419 - val_accuracy: 0.6875\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5743 - accuracy: 0.6328 - val_loss: 0.5402 - val_accuracy: 0.6875\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5726 - accuracy: 0.6328 - val_loss: 0.5385 - val_accuracy: 0.6875\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5709 - accuracy: 0.6328 - val_loss: 0.5369 - val_accuracy: 0.6875\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5692 - accuracy: 0.6328 - val_loss: 0.5352 - val_accuracy: 0.6875\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5674 - accuracy: 0.6328 - val_loss: 0.5335 - val_accuracy: 0.7031\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5657 - accuracy: 0.6328 - val_loss: 0.5319 - val_accuracy: 0.7031\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5640 - accuracy: 0.6328 - val_loss: 0.5303 - val_accuracy: 0.7031\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5623 - accuracy: 0.6367 - val_loss: 0.5286 - val_accuracy: 0.7031\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5606 - accuracy: 0.6445 - val_loss: 0.5270 - val_accuracy: 0.7031\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5590 - accuracy: 0.6523 - val_loss: 0.5254 - val_accuracy: 0.6875\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5573 - accuracy: 0.6484 - val_loss: 0.5238 - val_accuracy: 0.6875\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5556 - accuracy: 0.6523 - val_loss: 0.5222 - val_accuracy: 0.6875\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5539 - accuracy: 0.6562 - val_loss: 0.5206 - val_accuracy: 0.6875\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5522 - accuracy: 0.6602 - val_loss: 0.5190 - val_accuracy: 0.6875\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5505 - accuracy: 0.6602 - val_loss: 0.5174 - val_accuracy: 0.6875\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5488 - accuracy: 0.6602 - val_loss: 0.5157 - val_accuracy: 0.6875\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5471 - accuracy: 0.6602 - val_loss: 0.5142 - val_accuracy: 0.6875\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5454 - accuracy: 0.6602 - val_loss: 0.5125 - val_accuracy: 0.6875\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5437 - accuracy: 0.6641 - val_loss: 0.5109 - val_accuracy: 0.6875\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5420 - accuracy: 0.6641 - val_loss: 0.5093 - val_accuracy: 0.6875\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5404 - accuracy: 0.6641 - val_loss: 0.5077 - val_accuracy: 0.6875\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5387 - accuracy: 0.6641 - val_loss: 0.5062 - val_accuracy: 0.6875\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5370 - accuracy: 0.6719 - val_loss: 0.5045 - val_accuracy: 0.6719\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5353 - accuracy: 0.6758 - val_loss: 0.5030 - val_accuracy: 0.6875\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5337 - accuracy: 0.6797 - val_loss: 0.5014 - val_accuracy: 0.6875\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5320 - accuracy: 0.6953 - val_loss: 0.4998 - val_accuracy: 0.7188\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5303 - accuracy: 0.7227 - val_loss: 0.4982 - val_accuracy: 0.7031\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5287 - accuracy: 0.7227 - val_loss: 0.4966 - val_accuracy: 0.7188\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5270 - accuracy: 0.7227 - val_loss: 0.4950 - val_accuracy: 0.7188\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5254 - accuracy: 0.7227 - val_loss: 0.4933 - val_accuracy: 0.7188\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5237 - accuracy: 0.7305 - val_loss: 0.4916 - val_accuracy: 0.7188\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5220 - accuracy: 0.7344 - val_loss: 0.4900 - val_accuracy: 0.7188\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5203 - accuracy: 0.7344 - val_loss: 0.4883 - val_accuracy: 0.7188\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5187 - accuracy: 0.7461 - val_loss: 0.4867 - val_accuracy: 0.7188\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5170 - accuracy: 0.7500 - val_loss: 0.4850 - val_accuracy: 0.7344\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5153 - accuracy: 0.7617 - val_loss: 0.4833 - val_accuracy: 0.7344\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5136 - accuracy: 0.7734 - val_loss: 0.4817 - val_accuracy: 0.7344\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5119 - accuracy: 0.7773 - val_loss: 0.4800 - val_accuracy: 0.7344\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5103 - accuracy: 0.7812 - val_loss: 0.4783 - val_accuracy: 0.7344\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5086 - accuracy: 0.7812 - val_loss: 0.4766 - val_accuracy: 0.7344\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5069 - accuracy: 0.7852 - val_loss: 0.4749 - val_accuracy: 0.7500\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5053 - accuracy: 0.7891 - val_loss: 0.4732 - val_accuracy: 0.7500\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5036 - accuracy: 0.7852 - val_loss: 0.4715 - val_accuracy: 0.7656\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5019 - accuracy: 0.8008 - val_loss: 0.4698 - val_accuracy: 0.7656\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5002 - accuracy: 0.8086 - val_loss: 0.4681 - val_accuracy: 0.7812\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4985 - accuracy: 0.8125 - val_loss: 0.4664 - val_accuracy: 0.7812\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4967 - accuracy: 0.8164 - val_loss: 0.4647 - val_accuracy: 0.7812\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4950 - accuracy: 0.8203 - val_loss: 0.4630 - val_accuracy: 0.7812\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4933 - accuracy: 0.8203 - val_loss: 0.4613 - val_accuracy: 0.7812\n",
      "Epoch 116/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4916 - accuracy: 0.8242 - val_loss: 0.4596 - val_accuracy: 0.7969\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4899 - accuracy: 0.8242 - val_loss: 0.4579 - val_accuracy: 0.7969\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4882 - accuracy: 0.8242 - val_loss: 0.4562 - val_accuracy: 0.8281\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4865 - accuracy: 0.8242 - val_loss: 0.4544 - val_accuracy: 0.8281\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4847 - accuracy: 0.8203 - val_loss: 0.4527 - val_accuracy: 0.8281\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4830 - accuracy: 0.8203 - val_loss: 0.4509 - val_accuracy: 0.8438\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4813 - accuracy: 0.8242 - val_loss: 0.4492 - val_accuracy: 0.8438\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4796 - accuracy: 0.8242 - val_loss: 0.4475 - val_accuracy: 0.8438\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4779 - accuracy: 0.8242 - val_loss: 0.4458 - val_accuracy: 0.8281\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4762 - accuracy: 0.8242 - val_loss: 0.4440 - val_accuracy: 0.8281\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4745 - accuracy: 0.8242 - val_loss: 0.4423 - val_accuracy: 0.8281\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4728 - accuracy: 0.8281 - val_loss: 0.4405 - val_accuracy: 0.8281\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4711 - accuracy: 0.8281 - val_loss: 0.4387 - val_accuracy: 0.8281\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4693 - accuracy: 0.8320 - val_loss: 0.4369 - val_accuracy: 0.8438\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4676 - accuracy: 0.8320 - val_loss: 0.4352 - val_accuracy: 0.8438\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4659 - accuracy: 0.8320 - val_loss: 0.4334 - val_accuracy: 0.8438\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4641 - accuracy: 0.8320 - val_loss: 0.4316 - val_accuracy: 0.8438\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4624 - accuracy: 0.8359 - val_loss: 0.4299 - val_accuracy: 0.8438\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4606 - accuracy: 0.8359 - val_loss: 0.4282 - val_accuracy: 0.8438\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4589 - accuracy: 0.8359 - val_loss: 0.4265 - val_accuracy: 0.8438\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4572 - accuracy: 0.8320 - val_loss: 0.4247 - val_accuracy: 0.8438\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4555 - accuracy: 0.8320 - val_loss: 0.4230 - val_accuracy: 0.8438\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4538 - accuracy: 0.8320 - val_loss: 0.4213 - val_accuracy: 0.8438\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4521 - accuracy: 0.8398 - val_loss: 0.4196 - val_accuracy: 0.8438\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4503 - accuracy: 0.8398 - val_loss: 0.4179 - val_accuracy: 0.8438\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4486 - accuracy: 0.8398 - val_loss: 0.4162 - val_accuracy: 0.8438\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4469 - accuracy: 0.8398 - val_loss: 0.4146 - val_accuracy: 0.8438\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4452 - accuracy: 0.8438 - val_loss: 0.4129 - val_accuracy: 0.8438\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4435 - accuracy: 0.8438 - val_loss: 0.4113 - val_accuracy: 0.8438\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4419 - accuracy: 0.8438 - val_loss: 0.4096 - val_accuracy: 0.8438\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4402 - accuracy: 0.8438 - val_loss: 0.4080 - val_accuracy: 0.8438\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4386 - accuracy: 0.8438 - val_loss: 0.4064 - val_accuracy: 0.8438\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4369 - accuracy: 0.8438 - val_loss: 0.4048 - val_accuracy: 0.8438\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4353 - accuracy: 0.8438 - val_loss: 0.4032 - val_accuracy: 0.8594\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4337 - accuracy: 0.8438 - val_loss: 0.4016 - val_accuracy: 0.8750\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4321 - accuracy: 0.8438 - val_loss: 0.4001 - val_accuracy: 0.8750\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4304 - accuracy: 0.8438 - val_loss: 0.3986 - val_accuracy: 0.8750\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4288 - accuracy: 0.8438 - val_loss: 0.3970 - val_accuracy: 0.8750\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4272 - accuracy: 0.8438 - val_loss: 0.3954 - val_accuracy: 0.8750\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4256 - accuracy: 0.8438 - val_loss: 0.3937 - val_accuracy: 0.8750\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4241 - accuracy: 0.8438 - val_loss: 0.3921 - val_accuracy: 0.8750\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4225 - accuracy: 0.8438 - val_loss: 0.3906 - val_accuracy: 0.8750\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4210 - accuracy: 0.8398 - val_loss: 0.3890 - val_accuracy: 0.8750\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4194 - accuracy: 0.8398 - val_loss: 0.3874 - val_accuracy: 0.8750\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4178 - accuracy: 0.8398 - val_loss: 0.3858 - val_accuracy: 0.8750\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4163 - accuracy: 0.8398 - val_loss: 0.3843 - val_accuracy: 0.8750\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4148 - accuracy: 0.8398 - val_loss: 0.3828 - val_accuracy: 0.8750\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4133 - accuracy: 0.8398 - val_loss: 0.3813 - val_accuracy: 0.8906\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4117 - accuracy: 0.8398 - val_loss: 0.3799 - val_accuracy: 0.8906\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4102 - accuracy: 0.8359 - val_loss: 0.3784 - val_accuracy: 0.8906\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4087 - accuracy: 0.8398 - val_loss: 0.3769 - val_accuracy: 0.8906\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4072 - accuracy: 0.8398 - val_loss: 0.3755 - val_accuracy: 0.8906\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4057 - accuracy: 0.8398 - val_loss: 0.3740 - val_accuracy: 0.8906\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4042 - accuracy: 0.8398 - val_loss: 0.3725 - val_accuracy: 0.8906\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4027 - accuracy: 0.8438 - val_loss: 0.3710 - val_accuracy: 0.8906\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4012 - accuracy: 0.8438 - val_loss: 0.3695 - val_accuracy: 0.8906\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3997 - accuracy: 0.8438 - val_loss: 0.3681 - val_accuracy: 0.8906\n",
      "Epoch 173/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3982 - accuracy: 0.8438 - val_loss: 0.3666 - val_accuracy: 0.8906\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3968 - accuracy: 0.8438 - val_loss: 0.3652 - val_accuracy: 0.8906\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3953 - accuracy: 0.8438 - val_loss: 0.3637 - val_accuracy: 0.8906\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3939 - accuracy: 0.8438 - val_loss: 0.3622 - val_accuracy: 0.8906\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3924 - accuracy: 0.8438 - val_loss: 0.3608 - val_accuracy: 0.8906\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3910 - accuracy: 0.8438 - val_loss: 0.3593 - val_accuracy: 0.8906\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3896 - accuracy: 0.8438 - val_loss: 0.3580 - val_accuracy: 0.8906\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3882 - accuracy: 0.8438 - val_loss: 0.3566 - val_accuracy: 0.8906\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3868 - accuracy: 0.8438 - val_loss: 0.3553 - val_accuracy: 0.8906\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3855 - accuracy: 0.8438 - val_loss: 0.3540 - val_accuracy: 0.8906\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3841 - accuracy: 0.8438 - val_loss: 0.3527 - val_accuracy: 0.8906\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3827 - accuracy: 0.8477 - val_loss: 0.3514 - val_accuracy: 0.8906\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3814 - accuracy: 0.8477 - val_loss: 0.3502 - val_accuracy: 0.8906\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3800 - accuracy: 0.8477 - val_loss: 0.3489 - val_accuracy: 0.8906\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3787 - accuracy: 0.8477 - val_loss: 0.3477 - val_accuracy: 0.8906\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3774 - accuracy: 0.8477 - val_loss: 0.3465 - val_accuracy: 0.8906\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3761 - accuracy: 0.8477 - val_loss: 0.3452 - val_accuracy: 0.8906\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3747 - accuracy: 0.8477 - val_loss: 0.3440 - val_accuracy: 0.8906\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3735 - accuracy: 0.8477 - val_loss: 0.3428 - val_accuracy: 0.8906\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3722 - accuracy: 0.8438 - val_loss: 0.3416 - val_accuracy: 0.8906\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3709 - accuracy: 0.8438 - val_loss: 0.3404 - val_accuracy: 0.9062\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3696 - accuracy: 0.8516 - val_loss: 0.3391 - val_accuracy: 0.9062\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3683 - accuracy: 0.8516 - val_loss: 0.3379 - val_accuracy: 0.9062\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3670 - accuracy: 0.8516 - val_loss: 0.3367 - val_accuracy: 0.9062\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3658 - accuracy: 0.8516 - val_loss: 0.3354 - val_accuracy: 0.9062\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3645 - accuracy: 0.8516 - val_loss: 0.3342 - val_accuracy: 0.9062\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3632 - accuracy: 0.8516 - val_loss: 0.3330 - val_accuracy: 0.9062\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3620 - accuracy: 0.8516 - val_loss: 0.3317 - val_accuracy: 0.8906\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3607 - accuracy: 0.8555 - val_loss: 0.3305 - val_accuracy: 0.8906\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3595 - accuracy: 0.8555 - val_loss: 0.3294 - val_accuracy: 0.8906\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3582 - accuracy: 0.8594 - val_loss: 0.3281 - val_accuracy: 0.8906\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3570 - accuracy: 0.8594 - val_loss: 0.3269 - val_accuracy: 0.8906\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3558 - accuracy: 0.8594 - val_loss: 0.3258 - val_accuracy: 0.8906\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3546 - accuracy: 0.8633 - val_loss: 0.3246 - val_accuracy: 0.8906\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3534 - accuracy: 0.8633 - val_loss: 0.3235 - val_accuracy: 0.8906\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3522 - accuracy: 0.8633 - val_loss: 0.3224 - val_accuracy: 0.8906\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3510 - accuracy: 0.8633 - val_loss: 0.3213 - val_accuracy: 0.8906\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3498 - accuracy: 0.8633 - val_loss: 0.3202 - val_accuracy: 0.8906\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3487 - accuracy: 0.8633 - val_loss: 0.3192 - val_accuracy: 0.8906\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3475 - accuracy: 0.8633 - val_loss: 0.3181 - val_accuracy: 0.8906\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3464 - accuracy: 0.8633 - val_loss: 0.3170 - val_accuracy: 0.8906\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3452 - accuracy: 0.8633 - val_loss: 0.3159 - val_accuracy: 0.8906\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3441 - accuracy: 0.8633 - val_loss: 0.3149 - val_accuracy: 0.8906\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3429 - accuracy: 0.8633 - val_loss: 0.3138 - val_accuracy: 0.8906\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3418 - accuracy: 0.8633 - val_loss: 0.3129 - val_accuracy: 0.8906\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3407 - accuracy: 0.8633 - val_loss: 0.3119 - val_accuracy: 0.8906\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3396 - accuracy: 0.8633 - val_loss: 0.3109 - val_accuracy: 0.8906\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3385 - accuracy: 0.8633 - val_loss: 0.3099 - val_accuracy: 0.8906\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3374 - accuracy: 0.8633 - val_loss: 0.3089 - val_accuracy: 0.8906\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3363 - accuracy: 0.8633 - val_loss: 0.3080 - val_accuracy: 0.8906\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3352 - accuracy: 0.8633 - val_loss: 0.3070 - val_accuracy: 0.8906\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3341 - accuracy: 0.8633 - val_loss: 0.3060 - val_accuracy: 0.8906\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3330 - accuracy: 0.8633 - val_loss: 0.3051 - val_accuracy: 0.8906\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3319 - accuracy: 0.8633 - val_loss: 0.3041 - val_accuracy: 0.8906\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3309 - accuracy: 0.8633 - val_loss: 0.3033 - val_accuracy: 0.8906\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3298 - accuracy: 0.8633 - val_loss: 0.3024 - val_accuracy: 0.8906\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3288 - accuracy: 0.8633 - val_loss: 0.3015 - val_accuracy: 0.8906\n",
      "Epoch 230/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3277 - accuracy: 0.8633 - val_loss: 0.3007 - val_accuracy: 0.8906\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3267 - accuracy: 0.8633 - val_loss: 0.2999 - val_accuracy: 0.8906\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3257 - accuracy: 0.8633 - val_loss: 0.2991 - val_accuracy: 0.8906\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3246 - accuracy: 0.8633 - val_loss: 0.2984 - val_accuracy: 0.8906\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3236 - accuracy: 0.8633 - val_loss: 0.2976 - val_accuracy: 0.8906\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3225 - accuracy: 0.8633 - val_loss: 0.2968 - val_accuracy: 0.8906\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3215 - accuracy: 0.8672 - val_loss: 0.2960 - val_accuracy: 0.8906\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3205 - accuracy: 0.8711 - val_loss: 0.2952 - val_accuracy: 0.8906\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3196 - accuracy: 0.8711 - val_loss: 0.2945 - val_accuracy: 0.8906\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3186 - accuracy: 0.8711 - val_loss: 0.2937 - val_accuracy: 0.8906\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3176 - accuracy: 0.8711 - val_loss: 0.2931 - val_accuracy: 0.8906\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3167 - accuracy: 0.8711 - val_loss: 0.2923 - val_accuracy: 0.8906\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3157 - accuracy: 0.8789 - val_loss: 0.2917 - val_accuracy: 0.8906\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3148 - accuracy: 0.8789 - val_loss: 0.2910 - val_accuracy: 0.8906\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3139 - accuracy: 0.8789 - val_loss: 0.2903 - val_accuracy: 0.8906\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3130 - accuracy: 0.8789 - val_loss: 0.2897 - val_accuracy: 0.8906\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3121 - accuracy: 0.8789 - val_loss: 0.2890 - val_accuracy: 0.8906\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3112 - accuracy: 0.8789 - val_loss: 0.2885 - val_accuracy: 0.8906\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3103 - accuracy: 0.8789 - val_loss: 0.2878 - val_accuracy: 0.8906\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3094 - accuracy: 0.8789 - val_loss: 0.2872 - val_accuracy: 0.8906\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3086 - accuracy: 0.8789 - val_loss: 0.2866 - val_accuracy: 0.8906\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3077 - accuracy: 0.8789 - val_loss: 0.2860 - val_accuracy: 0.8906\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3068 - accuracy: 0.8789 - val_loss: 0.2854 - val_accuracy: 0.8906\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3060 - accuracy: 0.8789 - val_loss: 0.2849 - val_accuracy: 0.8906\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3051 - accuracy: 0.8789 - val_loss: 0.2844 - val_accuracy: 0.8906\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3043 - accuracy: 0.8789 - val_loss: 0.2839 - val_accuracy: 0.8906\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3035 - accuracy: 0.8828 - val_loss: 0.2834 - val_accuracy: 0.8906\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3027 - accuracy: 0.8828 - val_loss: 0.2829 - val_accuracy: 0.8906\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3019 - accuracy: 0.8828 - val_loss: 0.2825 - val_accuracy: 0.8906\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3011 - accuracy: 0.8828 - val_loss: 0.2820 - val_accuracy: 0.8906\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3003 - accuracy: 0.8828 - val_loss: 0.2814 - val_accuracy: 0.8906\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2995 - accuracy: 0.8828 - val_loss: 0.2809 - val_accuracy: 0.8906\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2988 - accuracy: 0.8828 - val_loss: 0.2804 - val_accuracy: 0.8906\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2980 - accuracy: 0.8828 - val_loss: 0.2800 - val_accuracy: 0.8906\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2973 - accuracy: 0.8867 - val_loss: 0.2795 - val_accuracy: 0.8906\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2965 - accuracy: 0.8867 - val_loss: 0.2791 - val_accuracy: 0.8906\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2958 - accuracy: 0.8867 - val_loss: 0.2787 - val_accuracy: 0.8906\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2950 - accuracy: 0.8867 - val_loss: 0.2783 - val_accuracy: 0.8906\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2943 - accuracy: 0.8867 - val_loss: 0.2779 - val_accuracy: 0.8906\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2935 - accuracy: 0.8867 - val_loss: 0.2775 - val_accuracy: 0.8906\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2928 - accuracy: 0.8867 - val_loss: 0.2771 - val_accuracy: 0.8906\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2921 - accuracy: 0.8867 - val_loss: 0.2767 - val_accuracy: 0.8750\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2914 - accuracy: 0.8867 - val_loss: 0.2763 - val_accuracy: 0.8750\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2907 - accuracy: 0.8867 - val_loss: 0.2758 - val_accuracy: 0.8750\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2899 - accuracy: 0.8867 - val_loss: 0.2755 - val_accuracy: 0.8750\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2892 - accuracy: 0.8867 - val_loss: 0.2751 - val_accuracy: 0.8750\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2885 - accuracy: 0.8867 - val_loss: 0.2747 - val_accuracy: 0.8750\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2878 - accuracy: 0.8867 - val_loss: 0.2742 - val_accuracy: 0.8750\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2872 - accuracy: 0.8867 - val_loss: 0.2739 - val_accuracy: 0.8750\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2865 - accuracy: 0.8867 - val_loss: 0.2735 - val_accuracy: 0.8750\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2858 - accuracy: 0.8867 - val_loss: 0.2731 - val_accuracy: 0.8750\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2851 - accuracy: 0.8867 - val_loss: 0.2727 - val_accuracy: 0.8750\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2844 - accuracy: 0.8867 - val_loss: 0.2724 - val_accuracy: 0.8750\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2837 - accuracy: 0.8867 - val_loss: 0.2721 - val_accuracy: 0.8750\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2831 - accuracy: 0.8867 - val_loss: 0.2716 - val_accuracy: 0.8750\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2824 - accuracy: 0.8867 - val_loss: 0.2714 - val_accuracy: 0.8750\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2818 - accuracy: 0.8867 - val_loss: 0.2709 - val_accuracy: 0.8750\n",
      "Epoch 287/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2811 - accuracy: 0.8867 - val_loss: 0.2707 - val_accuracy: 0.8750\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2805 - accuracy: 0.8867 - val_loss: 0.2702 - val_accuracy: 0.8750\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2799 - accuracy: 0.8867 - val_loss: 0.2700 - val_accuracy: 0.8750\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2792 - accuracy: 0.8867 - val_loss: 0.2696 - val_accuracy: 0.8750\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2786 - accuracy: 0.8867 - val_loss: 0.2694 - val_accuracy: 0.8750\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2780 - accuracy: 0.8867 - val_loss: 0.2691 - val_accuracy: 0.8750\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2774 - accuracy: 0.8906 - val_loss: 0.2686 - val_accuracy: 0.8750\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2768 - accuracy: 0.8906 - val_loss: 0.2683 - val_accuracy: 0.8750\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2761 - accuracy: 0.8945 - val_loss: 0.2680 - val_accuracy: 0.8750\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2755 - accuracy: 0.8945 - val_loss: 0.2677 - val_accuracy: 0.8750\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2749 - accuracy: 0.8945 - val_loss: 0.2675 - val_accuracy: 0.8750\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2743 - accuracy: 0.8945 - val_loss: 0.2672 - val_accuracy: 0.8750\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2737 - accuracy: 0.8945 - val_loss: 0.2670 - val_accuracy: 0.8750\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2731 - accuracy: 0.8945 - val_loss: 0.2667 - val_accuracy: 0.8750\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2725 - accuracy: 0.8945 - val_loss: 0.2666 - val_accuracy: 0.8750\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2719 - accuracy: 0.8984 - val_loss: 0.2664 - val_accuracy: 0.8750\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2713 - accuracy: 0.8984 - val_loss: 0.2663 - val_accuracy: 0.8906\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2707 - accuracy: 0.8984 - val_loss: 0.2661 - val_accuracy: 0.8906\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2702 - accuracy: 0.8984 - val_loss: 0.2659 - val_accuracy: 0.8906\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2696 - accuracy: 0.8984 - val_loss: 0.2657 - val_accuracy: 0.8906\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2690 - accuracy: 0.8984 - val_loss: 0.2656 - val_accuracy: 0.8906\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2684 - accuracy: 0.8984 - val_loss: 0.2654 - val_accuracy: 0.8906\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2678 - accuracy: 0.8984 - val_loss: 0.2652 - val_accuracy: 0.8906\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2672 - accuracy: 0.8984 - val_loss: 0.2651 - val_accuracy: 0.8906\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2667 - accuracy: 0.8984 - val_loss: 0.2649 - val_accuracy: 0.8906\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2661 - accuracy: 0.8984 - val_loss: 0.2647 - val_accuracy: 0.8906\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2655 - accuracy: 0.8984 - val_loss: 0.2645 - val_accuracy: 0.8906\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2648 - accuracy: 0.8984 - val_loss: 0.2643 - val_accuracy: 0.8906\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2642 - accuracy: 0.8984 - val_loss: 0.2641 - val_accuracy: 0.8906\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2636 - accuracy: 0.9023 - val_loss: 0.2640 - val_accuracy: 0.8906\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2630 - accuracy: 0.9023 - val_loss: 0.2638 - val_accuracy: 0.8906\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2624 - accuracy: 0.9023 - val_loss: 0.2636 - val_accuracy: 0.8906\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2618 - accuracy: 0.9023 - val_loss: 0.2635 - val_accuracy: 0.8906\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2612 - accuracy: 0.9023 - val_loss: 0.2633 - val_accuracy: 0.8906\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2606 - accuracy: 0.9023 - val_loss: 0.2631 - val_accuracy: 0.8906\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2600 - accuracy: 0.9023 - val_loss: 0.2631 - val_accuracy: 0.8906\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2594 - accuracy: 0.9023 - val_loss: 0.2629 - val_accuracy: 0.8906\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2589 - accuracy: 0.9023 - val_loss: 0.2628 - val_accuracy: 0.8906\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2583 - accuracy: 0.9023 - val_loss: 0.2626 - val_accuracy: 0.8906\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2578 - accuracy: 0.9023 - val_loss: 0.2625 - val_accuracy: 0.8906\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2572 - accuracy: 0.9023 - val_loss: 0.2624 - val_accuracy: 0.8906\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2567 - accuracy: 0.9023 - val_loss: 0.2623 - val_accuracy: 0.8906\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2561 - accuracy: 0.9023 - val_loss: 0.2623 - val_accuracy: 0.8906\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2556 - accuracy: 0.9023 - val_loss: 0.2622 - val_accuracy: 0.8906\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2550 - accuracy: 0.9023 - val_loss: 0.2622 - val_accuracy: 0.8906\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2545 - accuracy: 0.9023 - val_loss: 0.2621 - val_accuracy: 0.8906\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2540 - accuracy: 0.9023 - val_loss: 0.2620 - val_accuracy: 0.8906\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2534 - accuracy: 0.9023 - val_loss: 0.2618 - val_accuracy: 0.8906\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2529 - accuracy: 0.9023 - val_loss: 0.2617 - val_accuracy: 0.8906\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2524 - accuracy: 0.9023 - val_loss: 0.2617 - val_accuracy: 0.8906\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2519 - accuracy: 0.9023 - val_loss: 0.2616 - val_accuracy: 0.8906\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2514 - accuracy: 0.9023 - val_loss: 0.2615 - val_accuracy: 0.8906\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2509 - accuracy: 0.9023 - val_loss: 0.2613 - val_accuracy: 0.8906\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2505 - accuracy: 0.9023 - val_loss: 0.2613 - val_accuracy: 0.8906\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2500 - accuracy: 0.9023 - val_loss: 0.2611 - val_accuracy: 0.8906\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2495 - accuracy: 0.9023 - val_loss: 0.2611 - val_accuracy: 0.8906\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2491 - accuracy: 0.9023 - val_loss: 0.2610 - val_accuracy: 0.8906\n",
      "Epoch 344/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2486 - accuracy: 0.9023 - val_loss: 0.2611 - val_accuracy: 0.8906\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2482 - accuracy: 0.9062 - val_loss: 0.2609 - val_accuracy: 0.8906\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2477 - accuracy: 0.9023 - val_loss: 0.2610 - val_accuracy: 0.8906\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2473 - accuracy: 0.9062 - val_loss: 0.2608 - val_accuracy: 0.8906\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2468 - accuracy: 0.9062 - val_loss: 0.2609 - val_accuracy: 0.8906\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2464 - accuracy: 0.9062 - val_loss: 0.2609 - val_accuracy: 0.8906\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2460 - accuracy: 0.9062 - val_loss: 0.2608 - val_accuracy: 0.8906\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2455 - accuracy: 0.9062 - val_loss: 0.2609 - val_accuracy: 0.8906\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2451 - accuracy: 0.9062 - val_loss: 0.2609 - val_accuracy: 0.8906\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2447 - accuracy: 0.9062 - val_loss: 0.2609 - val_accuracy: 0.8906\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2443 - accuracy: 0.9062 - val_loss: 0.2610 - val_accuracy: 0.8906\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2439 - accuracy: 0.9062 - val_loss: 0.2610 - val_accuracy: 0.8906\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2435 - accuracy: 0.9062 - val_loss: 0.2610 - val_accuracy: 0.8906\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2431 - accuracy: 0.9062 - val_loss: 0.2612 - val_accuracy: 0.8906\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2427 - accuracy: 0.9062 - val_loss: 0.2612 - val_accuracy: 0.8906\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2423 - accuracy: 0.9062 - val_loss: 0.2612 - val_accuracy: 0.8906\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2419 - accuracy: 0.9062 - val_loss: 0.2614 - val_accuracy: 0.8906\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2415 - accuracy: 0.9062 - val_loss: 0.2614 - val_accuracy: 0.8906\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2411 - accuracy: 0.9062 - val_loss: 0.2616 - val_accuracy: 0.8906\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2407 - accuracy: 0.9062 - val_loss: 0.2616 - val_accuracy: 0.8906\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2404 - accuracy: 0.9062 - val_loss: 0.2617 - val_accuracy: 0.8906\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2400 - accuracy: 0.9062 - val_loss: 0.2617 - val_accuracy: 0.8906\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2396 - accuracy: 0.9062 - val_loss: 0.2622 - val_accuracy: 0.8906\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2393 - accuracy: 0.9102 - val_loss: 0.2620 - val_accuracy: 0.8906\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2389 - accuracy: 0.9102 - val_loss: 0.2623 - val_accuracy: 0.8906\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2385 - accuracy: 0.9102 - val_loss: 0.2623 - val_accuracy: 0.8906\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2382 - accuracy: 0.9102 - val_loss: 0.2625 - val_accuracy: 0.9062\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2378 - accuracy: 0.9102 - val_loss: 0.2624 - val_accuracy: 0.9062\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2375 - accuracy: 0.9102 - val_loss: 0.2625 - val_accuracy: 0.8906\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2371 - accuracy: 0.9102 - val_loss: 0.2627 - val_accuracy: 0.9062\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2368 - accuracy: 0.9102 - val_loss: 0.2627 - val_accuracy: 0.9062\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2364 - accuracy: 0.9102 - val_loss: 0.2629 - val_accuracy: 0.9062\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2361 - accuracy: 0.9102 - val_loss: 0.2629 - val_accuracy: 0.9062\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2357 - accuracy: 0.9102 - val_loss: 0.2631 - val_accuracy: 0.9062\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2354 - accuracy: 0.9102 - val_loss: 0.2632 - val_accuracy: 0.9062\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2350 - accuracy: 0.9102 - val_loss: 0.2632 - val_accuracy: 0.9062\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2347 - accuracy: 0.9102 - val_loss: 0.2633 - val_accuracy: 0.9062\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2343 - accuracy: 0.9102 - val_loss: 0.2634 - val_accuracy: 0.9062\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2340 - accuracy: 0.9102 - val_loss: 0.2634 - val_accuracy: 0.9062\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2635 - val_accuracy: 0.9062\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2333 - accuracy: 0.9102 - val_loss: 0.2636 - val_accuracy: 0.9062\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2330 - accuracy: 0.9102 - val_loss: 0.2636 - val_accuracy: 0.9062\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2327 - accuracy: 0.9102 - val_loss: 0.2638 - val_accuracy: 0.9062\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2324 - accuracy: 0.9102 - val_loss: 0.2637 - val_accuracy: 0.9062\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2321 - accuracy: 0.9102 - val_loss: 0.2639 - val_accuracy: 0.9062\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2318 - accuracy: 0.9102 - val_loss: 0.2638 - val_accuracy: 0.9062\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2315 - accuracy: 0.9102 - val_loss: 0.2641 - val_accuracy: 0.9062\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2312 - accuracy: 0.9102 - val_loss: 0.2640 - val_accuracy: 0.9062\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2309 - accuracy: 0.9102 - val_loss: 0.2641 - val_accuracy: 0.9062\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2306 - accuracy: 0.9102 - val_loss: 0.2642 - val_accuracy: 0.9062\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2303 - accuracy: 0.9102 - val_loss: 0.2642 - val_accuracy: 0.9062\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2300 - accuracy: 0.9102 - val_loss: 0.2643 - val_accuracy: 0.9062\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2297 - accuracy: 0.9102 - val_loss: 0.2643 - val_accuracy: 0.9062\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2294 - accuracy: 0.9102 - val_loss: 0.2644 - val_accuracy: 0.9062\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2291 - accuracy: 0.9102 - val_loss: 0.2644 - val_accuracy: 0.9062\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2288 - accuracy: 0.9102 - val_loss: 0.2644 - val_accuracy: 0.9062\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2285 - accuracy: 0.9102 - val_loss: 0.2647 - val_accuracy: 0.9062\n",
      "Epoch 401/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2283 - accuracy: 0.9102 - val_loss: 0.2644 - val_accuracy: 0.9062\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2280 - accuracy: 0.9102 - val_loss: 0.2649 - val_accuracy: 0.9062\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2277 - accuracy: 0.9102 - val_loss: 0.2647 - val_accuracy: 0.9062\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2275 - accuracy: 0.9102 - val_loss: 0.2650 - val_accuracy: 0.9062\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2272 - accuracy: 0.9102 - val_loss: 0.2649 - val_accuracy: 0.9062\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2269 - accuracy: 0.9102 - val_loss: 0.2652 - val_accuracy: 0.9062\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2267 - accuracy: 0.9102 - val_loss: 0.2652 - val_accuracy: 0.9062\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2264 - accuracy: 0.9102 - val_loss: 0.2652 - val_accuracy: 0.9062\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2262 - accuracy: 0.9102 - val_loss: 0.2654 - val_accuracy: 0.9062\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2259 - accuracy: 0.9102 - val_loss: 0.2654 - val_accuracy: 0.9062\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2256 - accuracy: 0.9102 - val_loss: 0.2658 - val_accuracy: 0.9062\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2254 - accuracy: 0.9102 - val_loss: 0.2657 - val_accuracy: 0.9062\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2251 - accuracy: 0.9102 - val_loss: 0.2658 - val_accuracy: 0.9062\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2249 - accuracy: 0.9102 - val_loss: 0.2659 - val_accuracy: 0.9062\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2246 - accuracy: 0.9102 - val_loss: 0.2662 - val_accuracy: 0.9062\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2244 - accuracy: 0.9102 - val_loss: 0.2661 - val_accuracy: 0.9062\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2242 - accuracy: 0.9102 - val_loss: 0.2663 - val_accuracy: 0.9062\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2239 - accuracy: 0.9102 - val_loss: 0.2664 - val_accuracy: 0.9062\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2237 - accuracy: 0.9102 - val_loss: 0.2666 - val_accuracy: 0.9062\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2235 - accuracy: 0.9102 - val_loss: 0.2665 - val_accuracy: 0.9062\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2233 - accuracy: 0.9102 - val_loss: 0.2668 - val_accuracy: 0.9062\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2230 - accuracy: 0.9102 - val_loss: 0.2667 - val_accuracy: 0.9062\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2228 - accuracy: 0.9102 - val_loss: 0.2671 - val_accuracy: 0.9062\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2226 - accuracy: 0.9102 - val_loss: 0.2669 - val_accuracy: 0.9062\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2224 - accuracy: 0.9102 - val_loss: 0.2672 - val_accuracy: 0.9062\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2221 - accuracy: 0.9102 - val_loss: 0.2672 - val_accuracy: 0.9062\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2219 - accuracy: 0.9141 - val_loss: 0.2674 - val_accuracy: 0.9062\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2217 - accuracy: 0.9141 - val_loss: 0.2675 - val_accuracy: 0.9062\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2215 - accuracy: 0.9141 - val_loss: 0.2676 - val_accuracy: 0.9062\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2213 - accuracy: 0.9141 - val_loss: 0.2677 - val_accuracy: 0.9062\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2211 - accuracy: 0.9141 - val_loss: 0.2680 - val_accuracy: 0.9062\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2208 - accuracy: 0.9141 - val_loss: 0.2679 - val_accuracy: 0.9062\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2206 - accuracy: 0.9141 - val_loss: 0.2682 - val_accuracy: 0.9062\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2204 - accuracy: 0.9141 - val_loss: 0.2682 - val_accuracy: 0.9062\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2202 - accuracy: 0.9141 - val_loss: 0.2682 - val_accuracy: 0.9062\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2200 - accuracy: 0.9141 - val_loss: 0.2686 - val_accuracy: 0.9062\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2197 - accuracy: 0.9141 - val_loss: 0.2683 - val_accuracy: 0.9062\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2195 - accuracy: 0.9141 - val_loss: 0.2689 - val_accuracy: 0.9062\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2193 - accuracy: 0.9141 - val_loss: 0.2684 - val_accuracy: 0.9062\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2191 - accuracy: 0.9141 - val_loss: 0.2689 - val_accuracy: 0.9062\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2189 - accuracy: 0.9141 - val_loss: 0.2688 - val_accuracy: 0.9062\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2188 - accuracy: 0.9141 - val_loss: 0.2689 - val_accuracy: 0.9062\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2186 - accuracy: 0.9141 - val_loss: 0.2691 - val_accuracy: 0.9062\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2184 - accuracy: 0.9141 - val_loss: 0.2689 - val_accuracy: 0.9062\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2182 - accuracy: 0.9141 - val_loss: 0.2694 - val_accuracy: 0.9062\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2180 - accuracy: 0.9141 - val_loss: 0.2693 - val_accuracy: 0.9062\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2179 - accuracy: 0.9141 - val_loss: 0.2692 - val_accuracy: 0.9062\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2177 - accuracy: 0.9141 - val_loss: 0.2697 - val_accuracy: 0.9062\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2175 - accuracy: 0.9141 - val_loss: 0.2693 - val_accuracy: 0.9062\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2174 - accuracy: 0.9141 - val_loss: 0.2696 - val_accuracy: 0.9062\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2172 - accuracy: 0.9141 - val_loss: 0.2696 - val_accuracy: 0.9062\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2170 - accuracy: 0.9141 - val_loss: 0.2696 - val_accuracy: 0.9062\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2169 - accuracy: 0.9141 - val_loss: 0.2697 - val_accuracy: 0.9062\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2167 - accuracy: 0.9141 - val_loss: 0.2698 - val_accuracy: 0.9062\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2166 - accuracy: 0.9141 - val_loss: 0.2697 - val_accuracy: 0.9062\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2164 - accuracy: 0.9141 - val_loss: 0.2699 - val_accuracy: 0.9062\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2162 - accuracy: 0.9141 - val_loss: 0.2695 - val_accuracy: 0.9062\n",
      "Epoch 458/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2161 - accuracy: 0.9141 - val_loss: 0.2702 - val_accuracy: 0.9062\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2159 - accuracy: 0.9141 - val_loss: 0.2696 - val_accuracy: 0.9062\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2158 - accuracy: 0.9141 - val_loss: 0.2703 - val_accuracy: 0.9062\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2156 - accuracy: 0.9141 - val_loss: 0.2695 - val_accuracy: 0.9062\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2154 - accuracy: 0.9141 - val_loss: 0.2701 - val_accuracy: 0.9062\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2153 - accuracy: 0.9141 - val_loss: 0.2693 - val_accuracy: 0.9062\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2151 - accuracy: 0.9141 - val_loss: 0.2700 - val_accuracy: 0.9062\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2149 - accuracy: 0.9141 - val_loss: 0.2697 - val_accuracy: 0.9062\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2147 - accuracy: 0.9141 - val_loss: 0.2699 - val_accuracy: 0.9062\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2146 - accuracy: 0.9141 - val_loss: 0.2698 - val_accuracy: 0.9062\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2144 - accuracy: 0.9141 - val_loss: 0.2696 - val_accuracy: 0.9062\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2142 - accuracy: 0.9141 - val_loss: 0.2698 - val_accuracy: 0.9062\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2141 - accuracy: 0.9141 - val_loss: 0.2698 - val_accuracy: 0.9062\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2139 - accuracy: 0.9141 - val_loss: 0.2694 - val_accuracy: 0.9062\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2138 - accuracy: 0.9141 - val_loss: 0.2701 - val_accuracy: 0.9062\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2136 - accuracy: 0.9141 - val_loss: 0.2695 - val_accuracy: 0.9062\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2135 - accuracy: 0.9141 - val_loss: 0.2700 - val_accuracy: 0.9062\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2133 - accuracy: 0.9141 - val_loss: 0.2695 - val_accuracy: 0.9062\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2131 - accuracy: 0.9141 - val_loss: 0.2698 - val_accuracy: 0.9062\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2130 - accuracy: 0.9141 - val_loss: 0.2696 - val_accuracy: 0.9062\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2128 - accuracy: 0.9141 - val_loss: 0.2696 - val_accuracy: 0.9062\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2126 - accuracy: 0.9180 - val_loss: 0.2698 - val_accuracy: 0.9062\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2124 - accuracy: 0.9180 - val_loss: 0.2693 - val_accuracy: 0.9062\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2122 - accuracy: 0.9180 - val_loss: 0.2703 - val_accuracy: 0.9062\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2121 - accuracy: 0.9180 - val_loss: 0.2692 - val_accuracy: 0.9062\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2119 - accuracy: 0.9180 - val_loss: 0.2702 - val_accuracy: 0.9062\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2118 - accuracy: 0.9180 - val_loss: 0.2691 - val_accuracy: 0.9062\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2116 - accuracy: 0.9180 - val_loss: 0.2704 - val_accuracy: 0.9062\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2114 - accuracy: 0.9180 - val_loss: 0.2694 - val_accuracy: 0.9062\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2113 - accuracy: 0.9180 - val_loss: 0.2700 - val_accuracy: 0.9062\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2111 - accuracy: 0.9180 - val_loss: 0.2698 - val_accuracy: 0.9062\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2110 - accuracy: 0.9180 - val_loss: 0.2699 - val_accuracy: 0.9062\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2108 - accuracy: 0.9180 - val_loss: 0.2697 - val_accuracy: 0.9062\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2107 - accuracy: 0.9180 - val_loss: 0.2698 - val_accuracy: 0.9062\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2105 - accuracy: 0.9180 - val_loss: 0.2702 - val_accuracy: 0.9062\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2104 - accuracy: 0.9180 - val_loss: 0.2696 - val_accuracy: 0.9062\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2102 - accuracy: 0.9180 - val_loss: 0.2703 - val_accuracy: 0.9062\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2101 - accuracy: 0.9180 - val_loss: 0.2699 - val_accuracy: 0.9062\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2099 - accuracy: 0.9180 - val_loss: 0.2700 - val_accuracy: 0.9062\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2098 - accuracy: 0.9180 - val_loss: 0.2703 - val_accuracy: 0.9062\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2096 - accuracy: 0.9180 - val_loss: 0.2699 - val_accuracy: 0.9062\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2095 - accuracy: 0.9180 - val_loss: 0.2705 - val_accuracy: 0.9062\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2093 - accuracy: 0.9141 - val_loss: 0.2699 - val_accuracy: 0.9062\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2092 - accuracy: 0.9180 - val_loss: 0.2709 - val_accuracy: 0.9062\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2091 - accuracy: 0.9141 - val_loss: 0.2699 - val_accuracy: 0.9062\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2089 - accuracy: 0.9180 - val_loss: 0.2712 - val_accuracy: 0.9062\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2088 - accuracy: 0.9141 - val_loss: 0.2699 - val_accuracy: 0.9062\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2087 - accuracy: 0.9180 - val_loss: 0.2712 - val_accuracy: 0.9062\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2085 - accuracy: 0.9141 - val_loss: 0.2704 - val_accuracy: 0.9062\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2084 - accuracy: 0.9180 - val_loss: 0.2708 - val_accuracy: 0.9062\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2083 - accuracy: 0.9141 - val_loss: 0.2708 - val_accuracy: 0.9062\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2081 - accuracy: 0.9180 - val_loss: 0.2710 - val_accuracy: 0.9062\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2080 - accuracy: 0.9141 - val_loss: 0.2711 - val_accuracy: 0.9062\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2079 - accuracy: 0.9141 - val_loss: 0.2711 - val_accuracy: 0.9062\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2078 - accuracy: 0.9141 - val_loss: 0.2714 - val_accuracy: 0.9062\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2077 - accuracy: 0.9141 - val_loss: 0.2711 - val_accuracy: 0.9062\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2075 - accuracy: 0.9141 - val_loss: 0.2714 - val_accuracy: 0.9062\n",
      "Epoch 515/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2074 - accuracy: 0.9141 - val_loss: 0.2716 - val_accuracy: 0.9062\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2073 - accuracy: 0.9141 - val_loss: 0.2713 - val_accuracy: 0.9062\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2072 - accuracy: 0.9141 - val_loss: 0.2717 - val_accuracy: 0.9062\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2070 - accuracy: 0.9141 - val_loss: 0.2715 - val_accuracy: 0.9062\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2069 - accuracy: 0.9141 - val_loss: 0.2716 - val_accuracy: 0.9062\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2067 - accuracy: 0.9141 - val_loss: 0.2714 - val_accuracy: 0.9062\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2066 - accuracy: 0.9141 - val_loss: 0.2717 - val_accuracy: 0.9062\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2065 - accuracy: 0.9141 - val_loss: 0.2715 - val_accuracy: 0.9062\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2063 - accuracy: 0.9141 - val_loss: 0.2717 - val_accuracy: 0.9062\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2062 - accuracy: 0.9141 - val_loss: 0.2720 - val_accuracy: 0.9062\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2060 - accuracy: 0.9141 - val_loss: 0.2715 - val_accuracy: 0.9062\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2059 - accuracy: 0.9141 - val_loss: 0.2719 - val_accuracy: 0.9062\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2057 - accuracy: 0.9180 - val_loss: 0.2716 - val_accuracy: 0.9062\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2056 - accuracy: 0.9180 - val_loss: 0.2721 - val_accuracy: 0.9062\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2055 - accuracy: 0.9180 - val_loss: 0.2714 - val_accuracy: 0.9062\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2054 - accuracy: 0.9180 - val_loss: 0.2730 - val_accuracy: 0.9062\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2053 - accuracy: 0.9180 - val_loss: 0.2715 - val_accuracy: 0.9062\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2051 - accuracy: 0.9180 - val_loss: 0.2728 - val_accuracy: 0.9062\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2050 - accuracy: 0.9180 - val_loss: 0.2717 - val_accuracy: 0.9062\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2049 - accuracy: 0.9180 - val_loss: 0.2729 - val_accuracy: 0.9062\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2047 - accuracy: 0.9180 - val_loss: 0.2720 - val_accuracy: 0.9062\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2046 - accuracy: 0.9180 - val_loss: 0.2730 - val_accuracy: 0.9062\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2045 - accuracy: 0.9180 - val_loss: 0.2724 - val_accuracy: 0.9062\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2044 - accuracy: 0.9180 - val_loss: 0.2728 - val_accuracy: 0.9062\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2043 - accuracy: 0.9180 - val_loss: 0.2728 - val_accuracy: 0.9062\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2042 - accuracy: 0.9180 - val_loss: 0.2729 - val_accuracy: 0.9062\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2040 - accuracy: 0.9180 - val_loss: 0.2730 - val_accuracy: 0.9062\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2039 - accuracy: 0.9180 - val_loss: 0.2728 - val_accuracy: 0.9062\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2038 - accuracy: 0.9180 - val_loss: 0.2733 - val_accuracy: 0.9062\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2037 - accuracy: 0.9180 - val_loss: 0.2730 - val_accuracy: 0.9062\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2036 - accuracy: 0.9180 - val_loss: 0.2733 - val_accuracy: 0.9062\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2035 - accuracy: 0.9180 - val_loss: 0.2732 - val_accuracy: 0.9062\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2033 - accuracy: 0.9180 - val_loss: 0.2732 - val_accuracy: 0.9062\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2032 - accuracy: 0.9180 - val_loss: 0.2734 - val_accuracy: 0.9062\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2031 - accuracy: 0.9180 - val_loss: 0.2732 - val_accuracy: 0.9062\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2030 - accuracy: 0.9180 - val_loss: 0.2739 - val_accuracy: 0.9062\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2029 - accuracy: 0.9180 - val_loss: 0.2731 - val_accuracy: 0.9062\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2028 - accuracy: 0.9180 - val_loss: 0.2741 - val_accuracy: 0.9062\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2027 - accuracy: 0.9219 - val_loss: 0.2730 - val_accuracy: 0.9062\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2026 - accuracy: 0.9180 - val_loss: 0.2743 - val_accuracy: 0.9062\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2025 - accuracy: 0.9180 - val_loss: 0.2732 - val_accuracy: 0.9062\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2024 - accuracy: 0.9180 - val_loss: 0.2743 - val_accuracy: 0.9062\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2022 - accuracy: 0.9219 - val_loss: 0.2735 - val_accuracy: 0.9062\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2021 - accuracy: 0.9180 - val_loss: 0.2744 - val_accuracy: 0.9062\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2020 - accuracy: 0.9219 - val_loss: 0.2735 - val_accuracy: 0.9062\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2019 - accuracy: 0.9180 - val_loss: 0.2746 - val_accuracy: 0.9062\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2018 - accuracy: 0.9219 - val_loss: 0.2739 - val_accuracy: 0.9062\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2017 - accuracy: 0.9180 - val_loss: 0.2746 - val_accuracy: 0.9062\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2016 - accuracy: 0.9219 - val_loss: 0.2744 - val_accuracy: 0.9062\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2015 - accuracy: 0.9219 - val_loss: 0.2744 - val_accuracy: 0.9062\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2013 - accuracy: 0.9180 - val_loss: 0.2747 - val_accuracy: 0.9062\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2013 - accuracy: 0.9219 - val_loss: 0.2747 - val_accuracy: 0.9062\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2012 - accuracy: 0.9180 - val_loss: 0.2746 - val_accuracy: 0.9062\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2010 - accuracy: 0.9219 - val_loss: 0.2752 - val_accuracy: 0.9062\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2009 - accuracy: 0.9219 - val_loss: 0.2744 - val_accuracy: 0.9062\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2008 - accuracy: 0.9180 - val_loss: 0.2757 - val_accuracy: 0.9062\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2007 - accuracy: 0.9219 - val_loss: 0.2745 - val_accuracy: 0.9062\n",
      "Epoch 572/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2006 - accuracy: 0.9180 - val_loss: 0.2756 - val_accuracy: 0.9062\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2005 - accuracy: 0.9219 - val_loss: 0.2754 - val_accuracy: 0.9062\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2004 - accuracy: 0.9219 - val_loss: 0.2754 - val_accuracy: 0.9062\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2003 - accuracy: 0.9219 - val_loss: 0.2755 - val_accuracy: 0.9062\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2002 - accuracy: 0.9219 - val_loss: 0.2758 - val_accuracy: 0.9062\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2001 - accuracy: 0.9219 - val_loss: 0.2753 - val_accuracy: 0.9062\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2000 - accuracy: 0.9219 - val_loss: 0.2761 - val_accuracy: 0.9062\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1999 - accuracy: 0.9219 - val_loss: 0.2750 - val_accuracy: 0.9062\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1998 - accuracy: 0.9219 - val_loss: 0.2762 - val_accuracy: 0.9062\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1997 - accuracy: 0.9219 - val_loss: 0.2752 - val_accuracy: 0.9062\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1996 - accuracy: 0.9219 - val_loss: 0.2765 - val_accuracy: 0.9062\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1995 - accuracy: 0.9219 - val_loss: 0.2755 - val_accuracy: 0.9062\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1994 - accuracy: 0.9219 - val_loss: 0.2766 - val_accuracy: 0.9062\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1993 - accuracy: 0.9219 - val_loss: 0.2757 - val_accuracy: 0.9062\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1992 - accuracy: 0.9219 - val_loss: 0.2765 - val_accuracy: 0.9062\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1991 - accuracy: 0.9219 - val_loss: 0.2760 - val_accuracy: 0.9062\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1990 - accuracy: 0.9219 - val_loss: 0.2768 - val_accuracy: 0.9062\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1989 - accuracy: 0.9219 - val_loss: 0.2763 - val_accuracy: 0.9062\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1988 - accuracy: 0.9219 - val_loss: 0.2769 - val_accuracy: 0.9062\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1987 - accuracy: 0.9219 - val_loss: 0.2761 - val_accuracy: 0.9062\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1986 - accuracy: 0.9219 - val_loss: 0.2771 - val_accuracy: 0.9062\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1985 - accuracy: 0.9219 - val_loss: 0.2767 - val_accuracy: 0.9062\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1984 - accuracy: 0.9219 - val_loss: 0.2769 - val_accuracy: 0.9062\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1983 - accuracy: 0.9219 - val_loss: 0.2771 - val_accuracy: 0.9062\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1983 - accuracy: 0.9219 - val_loss: 0.2772 - val_accuracy: 0.9062\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1982 - accuracy: 0.9219 - val_loss: 0.2769 - val_accuracy: 0.9062\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1980 - accuracy: 0.9219 - val_loss: 0.2776 - val_accuracy: 0.9062\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1980 - accuracy: 0.9219 - val_loss: 0.2770 - val_accuracy: 0.9062\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1979 - accuracy: 0.9219 - val_loss: 0.2778 - val_accuracy: 0.9062\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1978 - accuracy: 0.9219 - val_loss: 0.2770 - val_accuracy: 0.9062\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1977 - accuracy: 0.9219 - val_loss: 0.2781 - val_accuracy: 0.9062\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1976 - accuracy: 0.9219 - val_loss: 0.2773 - val_accuracy: 0.9062\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1975 - accuracy: 0.9219 - val_loss: 0.2782 - val_accuracy: 0.9062\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1974 - accuracy: 0.9219 - val_loss: 0.2775 - val_accuracy: 0.9062\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1973 - accuracy: 0.9219 - val_loss: 0.2782 - val_accuracy: 0.9062\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1972 - accuracy: 0.9219 - val_loss: 0.2779 - val_accuracy: 0.9062\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1971 - accuracy: 0.9219 - val_loss: 0.2781 - val_accuracy: 0.9062\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1970 - accuracy: 0.9219 - val_loss: 0.2782 - val_accuracy: 0.9062\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1969 - accuracy: 0.9219 - val_loss: 0.2787 - val_accuracy: 0.9062\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1968 - accuracy: 0.9219 - val_loss: 0.2781 - val_accuracy: 0.9062\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1967 - accuracy: 0.9219 - val_loss: 0.2786 - val_accuracy: 0.9062\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1966 - accuracy: 0.9219 - val_loss: 0.2788 - val_accuracy: 0.9062\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1966 - accuracy: 0.9219 - val_loss: 0.2789 - val_accuracy: 0.9062\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1964 - accuracy: 0.9219 - val_loss: 0.2788 - val_accuracy: 0.9062\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1963 - accuracy: 0.9219 - val_loss: 0.2794 - val_accuracy: 0.9062\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1963 - accuracy: 0.9219 - val_loss: 0.2789 - val_accuracy: 0.9062\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1961 - accuracy: 0.9219 - val_loss: 0.2791 - val_accuracy: 0.9062\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1960 - accuracy: 0.9219 - val_loss: 0.2787 - val_accuracy: 0.9062\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1959 - accuracy: 0.9219 - val_loss: 0.2797 - val_accuracy: 0.9062\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1958 - accuracy: 0.9219 - val_loss: 0.2787 - val_accuracy: 0.9062\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1957 - accuracy: 0.9219 - val_loss: 0.2799 - val_accuracy: 0.9062\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1955 - accuracy: 0.9219 - val_loss: 0.2793 - val_accuracy: 0.9062\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1954 - accuracy: 0.9219 - val_loss: 0.2800 - val_accuracy: 0.9062\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1953 - accuracy: 0.9219 - val_loss: 0.2792 - val_accuracy: 0.9062\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1952 - accuracy: 0.9219 - val_loss: 0.2804 - val_accuracy: 0.9062\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1951 - accuracy: 0.9219 - val_loss: 0.2794 - val_accuracy: 0.9062\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1950 - accuracy: 0.9219 - val_loss: 0.2808 - val_accuracy: 0.9062\n",
      "Epoch 629/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1949 - accuracy: 0.9219 - val_loss: 0.2798 - val_accuracy: 0.9062\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1948 - accuracy: 0.9219 - val_loss: 0.2809 - val_accuracy: 0.9062\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1947 - accuracy: 0.9219 - val_loss: 0.2800 - val_accuracy: 0.9062\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1946 - accuracy: 0.9219 - val_loss: 0.2809 - val_accuracy: 0.9062\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1945 - accuracy: 0.9219 - val_loss: 0.2802 - val_accuracy: 0.9062\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1944 - accuracy: 0.9219 - val_loss: 0.2807 - val_accuracy: 0.9062\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1943 - accuracy: 0.9219 - val_loss: 0.2810 - val_accuracy: 0.9062\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1942 - accuracy: 0.9219 - val_loss: 0.2808 - val_accuracy: 0.9062\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1941 - accuracy: 0.9219 - val_loss: 0.2810 - val_accuracy: 0.9062\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1940 - accuracy: 0.9219 - val_loss: 0.2812 - val_accuracy: 0.9062\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1939 - accuracy: 0.9219 - val_loss: 0.2811 - val_accuracy: 0.9062\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1938 - accuracy: 0.9219 - val_loss: 0.2813 - val_accuracy: 0.9062\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1937 - accuracy: 0.9219 - val_loss: 0.2815 - val_accuracy: 0.9062\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1936 - accuracy: 0.9219 - val_loss: 0.2811 - val_accuracy: 0.9062\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1935 - accuracy: 0.9219 - val_loss: 0.2822 - val_accuracy: 0.9062\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1934 - accuracy: 0.9258 - val_loss: 0.2814 - val_accuracy: 0.9062\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1933 - accuracy: 0.9219 - val_loss: 0.2824 - val_accuracy: 0.9062\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1932 - accuracy: 0.9219 - val_loss: 0.2815 - val_accuracy: 0.9062\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1931 - accuracy: 0.9219 - val_loss: 0.2826 - val_accuracy: 0.9062\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1931 - accuracy: 0.9258 - val_loss: 0.2814 - val_accuracy: 0.9062\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1929 - accuracy: 0.9219 - val_loss: 0.2825 - val_accuracy: 0.9062\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1928 - accuracy: 0.9219 - val_loss: 0.2821 - val_accuracy: 0.9062\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1927 - accuracy: 0.9219 - val_loss: 0.2822 - val_accuracy: 0.9062\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1927 - accuracy: 0.9219 - val_loss: 0.2821 - val_accuracy: 0.9062\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1926 - accuracy: 0.9219 - val_loss: 0.2831 - val_accuracy: 0.9062\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1925 - accuracy: 0.9258 - val_loss: 0.2821 - val_accuracy: 0.9062\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1924 - accuracy: 0.9258 - val_loss: 0.2831 - val_accuracy: 0.9062\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1923 - accuracy: 0.9258 - val_loss: 0.2825 - val_accuracy: 0.9062\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1922 - accuracy: 0.9258 - val_loss: 0.2834 - val_accuracy: 0.9062\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1921 - accuracy: 0.9258 - val_loss: 0.2824 - val_accuracy: 0.9062\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1920 - accuracy: 0.9258 - val_loss: 0.2835 - val_accuracy: 0.9062\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1919 - accuracy: 0.9258 - val_loss: 0.2827 - val_accuracy: 0.9062\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1918 - accuracy: 0.9258 - val_loss: 0.2836 - val_accuracy: 0.9062\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1917 - accuracy: 0.9258 - val_loss: 0.2830 - val_accuracy: 0.9062\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1916 - accuracy: 0.9258 - val_loss: 0.2839 - val_accuracy: 0.9062\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1915 - accuracy: 0.9258 - val_loss: 0.2832 - val_accuracy: 0.9062\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1915 - accuracy: 0.9258 - val_loss: 0.2840 - val_accuracy: 0.9062\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1914 - accuracy: 0.9297 - val_loss: 0.2835 - val_accuracy: 0.9062\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1913 - accuracy: 0.9258 - val_loss: 0.2844 - val_accuracy: 0.9062\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1912 - accuracy: 0.9297 - val_loss: 0.2836 - val_accuracy: 0.9062\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1911 - accuracy: 0.9258 - val_loss: 0.2844 - val_accuracy: 0.9062\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1910 - accuracy: 0.9297 - val_loss: 0.2838 - val_accuracy: 0.9062\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1909 - accuracy: 0.9258 - val_loss: 0.2848 - val_accuracy: 0.9062\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1908 - accuracy: 0.9297 - val_loss: 0.2841 - val_accuracy: 0.9062\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1907 - accuracy: 0.9258 - val_loss: 0.2851 - val_accuracy: 0.9062\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1906 - accuracy: 0.9297 - val_loss: 0.2844 - val_accuracy: 0.9062\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1906 - accuracy: 0.9258 - val_loss: 0.2850 - val_accuracy: 0.9062\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1904 - accuracy: 0.9297 - val_loss: 0.2848 - val_accuracy: 0.9062\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1903 - accuracy: 0.9258 - val_loss: 0.2851 - val_accuracy: 0.9062\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1903 - accuracy: 0.9297 - val_loss: 0.2845 - val_accuracy: 0.9062\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1902 - accuracy: 0.9258 - val_loss: 0.2857 - val_accuracy: 0.9062\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1901 - accuracy: 0.9297 - val_loss: 0.2846 - val_accuracy: 0.9062\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1901 - accuracy: 0.9258 - val_loss: 0.2858 - val_accuracy: 0.9062\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1900 - accuracy: 0.9297 - val_loss: 0.2849 - val_accuracy: 0.9062\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1899 - accuracy: 0.9258 - val_loss: 0.2857 - val_accuracy: 0.9062\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1898 - accuracy: 0.9297 - val_loss: 0.2850 - val_accuracy: 0.9062\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1897 - accuracy: 0.9258 - val_loss: 0.2858 - val_accuracy: 0.9062\n",
      "Epoch 686/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1896 - accuracy: 0.9297 - val_loss: 0.2857 - val_accuracy: 0.9062\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1895 - accuracy: 0.9297 - val_loss: 0.2861 - val_accuracy: 0.9062\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1895 - accuracy: 0.9297 - val_loss: 0.2858 - val_accuracy: 0.9062\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1894 - accuracy: 0.9258 - val_loss: 0.2862 - val_accuracy: 0.9062\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1893 - accuracy: 0.9297 - val_loss: 0.2857 - val_accuracy: 0.9062\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1892 - accuracy: 0.9258 - val_loss: 0.2866 - val_accuracy: 0.9062\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1891 - accuracy: 0.9297 - val_loss: 0.2860 - val_accuracy: 0.9062\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1890 - accuracy: 0.9258 - val_loss: 0.2868 - val_accuracy: 0.9062\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1890 - accuracy: 0.9297 - val_loss: 0.2860 - val_accuracy: 0.9062\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1889 - accuracy: 0.9258 - val_loss: 0.2871 - val_accuracy: 0.9062\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1888 - accuracy: 0.9297 - val_loss: 0.2864 - val_accuracy: 0.9062\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1887 - accuracy: 0.9258 - val_loss: 0.2868 - val_accuracy: 0.9062\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1887 - accuracy: 0.9297 - val_loss: 0.2866 - val_accuracy: 0.9062\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1886 - accuracy: 0.9258 - val_loss: 0.2874 - val_accuracy: 0.9062\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1885 - accuracy: 0.9297 - val_loss: 0.2865 - val_accuracy: 0.9062\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1884 - accuracy: 0.9258 - val_loss: 0.2880 - val_accuracy: 0.9062\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1884 - accuracy: 0.9297 - val_loss: 0.2868 - val_accuracy: 0.9062\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1883 - accuracy: 0.9258 - val_loss: 0.2877 - val_accuracy: 0.9062\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1882 - accuracy: 0.9297 - val_loss: 0.2873 - val_accuracy: 0.9062\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1881 - accuracy: 0.9258 - val_loss: 0.2880 - val_accuracy: 0.9062\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1880 - accuracy: 0.9297 - val_loss: 0.2872 - val_accuracy: 0.9062\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1880 - accuracy: 0.9258 - val_loss: 0.2886 - val_accuracy: 0.9062\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1879 - accuracy: 0.9297 - val_loss: 0.2877 - val_accuracy: 0.9062\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1878 - accuracy: 0.9297 - val_loss: 0.2883 - val_accuracy: 0.9062\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1877 - accuracy: 0.9297 - val_loss: 0.2878 - val_accuracy: 0.9062\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1876 - accuracy: 0.9258 - val_loss: 0.2884 - val_accuracy: 0.9062\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1876 - accuracy: 0.9297 - val_loss: 0.2883 - val_accuracy: 0.9062\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1875 - accuracy: 0.9297 - val_loss: 0.2889 - val_accuracy: 0.9062\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1874 - accuracy: 0.9297 - val_loss: 0.2883 - val_accuracy: 0.9062\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1873 - accuracy: 0.9258 - val_loss: 0.2892 - val_accuracy: 0.9062\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1873 - accuracy: 0.9297 - val_loss: 0.2881 - val_accuracy: 0.9062\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1872 - accuracy: 0.9258 - val_loss: 0.2894 - val_accuracy: 0.9062\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1871 - accuracy: 0.9297 - val_loss: 0.2889 - val_accuracy: 0.9062\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1870 - accuracy: 0.9297 - val_loss: 0.2891 - val_accuracy: 0.9062\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1870 - accuracy: 0.9297 - val_loss: 0.2891 - val_accuracy: 0.9062\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1869 - accuracy: 0.9297 - val_loss: 0.2897 - val_accuracy: 0.9062\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1868 - accuracy: 0.9297 - val_loss: 0.2892 - val_accuracy: 0.9062\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1868 - accuracy: 0.9297 - val_loss: 0.2902 - val_accuracy: 0.9062\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1867 - accuracy: 0.9297 - val_loss: 0.2895 - val_accuracy: 0.9062\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1866 - accuracy: 0.9258 - val_loss: 0.2907 - val_accuracy: 0.9062\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1866 - accuracy: 0.9297 - val_loss: 0.2894 - val_accuracy: 0.9062\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1865 - accuracy: 0.9258 - val_loss: 0.2906 - val_accuracy: 0.9062\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1864 - accuracy: 0.9297 - val_loss: 0.2897 - val_accuracy: 0.9062\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1864 - accuracy: 0.9258 - val_loss: 0.2909 - val_accuracy: 0.9062\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1863 - accuracy: 0.9297 - val_loss: 0.2902 - val_accuracy: 0.9062\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1862 - accuracy: 0.9297 - val_loss: 0.2909 - val_accuracy: 0.9062\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1861 - accuracy: 0.9297 - val_loss: 0.2902 - val_accuracy: 0.9062\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1860 - accuracy: 0.9297 - val_loss: 0.2909 - val_accuracy: 0.9062\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1860 - accuracy: 0.9297 - val_loss: 0.2907 - val_accuracy: 0.9062\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1859 - accuracy: 0.9297 - val_loss: 0.2909 - val_accuracy: 0.9062\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1858 - accuracy: 0.9297 - val_loss: 0.2913 - val_accuracy: 0.9062\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1858 - accuracy: 0.9297 - val_loss: 0.2912 - val_accuracy: 0.9062\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1857 - accuracy: 0.9297 - val_loss: 0.2910 - val_accuracy: 0.9062\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1856 - accuracy: 0.9297 - val_loss: 0.2914 - val_accuracy: 0.9062\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1856 - accuracy: 0.9297 - val_loss: 0.2911 - val_accuracy: 0.9062\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1855 - accuracy: 0.9297 - val_loss: 0.2916 - val_accuracy: 0.9062\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1854 - accuracy: 0.9297 - val_loss: 0.2913 - val_accuracy: 0.9062\n",
      "Epoch 743/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1854 - accuracy: 0.9297 - val_loss: 0.2920 - val_accuracy: 0.9062\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1853 - accuracy: 0.9336 - val_loss: 0.2909 - val_accuracy: 0.9062\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1853 - accuracy: 0.9258 - val_loss: 0.2926 - val_accuracy: 0.9062\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1852 - accuracy: 0.9336 - val_loss: 0.2913 - val_accuracy: 0.9062\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1851 - accuracy: 0.9297 - val_loss: 0.2926 - val_accuracy: 0.9062\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1851 - accuracy: 0.9336 - val_loss: 0.2915 - val_accuracy: 0.9062\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1850 - accuracy: 0.9297 - val_loss: 0.2924 - val_accuracy: 0.9062\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1848 - accuracy: 0.9336 - val_loss: 0.2921 - val_accuracy: 0.9062\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1848 - accuracy: 0.9297 - val_loss: 0.2923 - val_accuracy: 0.9062\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1847 - accuracy: 0.9336 - val_loss: 0.2923 - val_accuracy: 0.9062\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1846 - accuracy: 0.9297 - val_loss: 0.2926 - val_accuracy: 0.9062\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1846 - accuracy: 0.9336 - val_loss: 0.2921 - val_accuracy: 0.9062\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1845 - accuracy: 0.9297 - val_loss: 0.2930 - val_accuracy: 0.9062\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1845 - accuracy: 0.9336 - val_loss: 0.2921 - val_accuracy: 0.9062\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1844 - accuracy: 0.9336 - val_loss: 0.2930 - val_accuracy: 0.9062\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1843 - accuracy: 0.9336 - val_loss: 0.2927 - val_accuracy: 0.9062\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1843 - accuracy: 0.9336 - val_loss: 0.2934 - val_accuracy: 0.9062\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1842 - accuracy: 0.9336 - val_loss: 0.2924 - val_accuracy: 0.9062\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1841 - accuracy: 0.9297 - val_loss: 0.2937 - val_accuracy: 0.9062\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1841 - accuracy: 0.9336 - val_loss: 0.2926 - val_accuracy: 0.9062\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1840 - accuracy: 0.9336 - val_loss: 0.2938 - val_accuracy: 0.9062\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1840 - accuracy: 0.9336 - val_loss: 0.2928 - val_accuracy: 0.9062\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1838 - accuracy: 0.9336 - val_loss: 0.2938 - val_accuracy: 0.9062\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1838 - accuracy: 0.9336 - val_loss: 0.2932 - val_accuracy: 0.9062\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1837 - accuracy: 0.9336 - val_loss: 0.2939 - val_accuracy: 0.9062\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1836 - accuracy: 0.9336 - val_loss: 0.2930 - val_accuracy: 0.9062\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1837 - accuracy: 0.9336 - val_loss: 0.2942 - val_accuracy: 0.9062\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1836 - accuracy: 0.9336 - val_loss: 0.2934 - val_accuracy: 0.9062\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1835 - accuracy: 0.9336 - val_loss: 0.2944 - val_accuracy: 0.9062\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1834 - accuracy: 0.9336 - val_loss: 0.2933 - val_accuracy: 0.9062\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1834 - accuracy: 0.9336 - val_loss: 0.2946 - val_accuracy: 0.9062\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1833 - accuracy: 0.9336 - val_loss: 0.2933 - val_accuracy: 0.9062\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1832 - accuracy: 0.9336 - val_loss: 0.2941 - val_accuracy: 0.9062\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1831 - accuracy: 0.9336 - val_loss: 0.2940 - val_accuracy: 0.9062\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1830 - accuracy: 0.9336 - val_loss: 0.2941 - val_accuracy: 0.9062\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1830 - accuracy: 0.9336 - val_loss: 0.2940 - val_accuracy: 0.9062\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1829 - accuracy: 0.9336 - val_loss: 0.2947 - val_accuracy: 0.9062\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1829 - accuracy: 0.9336 - val_loss: 0.2939 - val_accuracy: 0.9062\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1828 - accuracy: 0.9336 - val_loss: 0.2949 - val_accuracy: 0.9062\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1828 - accuracy: 0.9336 - val_loss: 0.2939 - val_accuracy: 0.9062\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1827 - accuracy: 0.9336 - val_loss: 0.2952 - val_accuracy: 0.9062\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1826 - accuracy: 0.9336 - val_loss: 0.2941 - val_accuracy: 0.9062\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1826 - accuracy: 0.9336 - val_loss: 0.2949 - val_accuracy: 0.9062\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1825 - accuracy: 0.9336 - val_loss: 0.2943 - val_accuracy: 0.9062\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1824 - accuracy: 0.9336 - val_loss: 0.2951 - val_accuracy: 0.9062\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1823 - accuracy: 0.9336 - val_loss: 0.2946 - val_accuracy: 0.9062\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1823 - accuracy: 0.9336 - val_loss: 0.2955 - val_accuracy: 0.9062\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1822 - accuracy: 0.9336 - val_loss: 0.2948 - val_accuracy: 0.9062\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1822 - accuracy: 0.9336 - val_loss: 0.2956 - val_accuracy: 0.9062\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1821 - accuracy: 0.9336 - val_loss: 0.2946 - val_accuracy: 0.9062\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1821 - accuracy: 0.9336 - val_loss: 0.2957 - val_accuracy: 0.9062\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1820 - accuracy: 0.9336 - val_loss: 0.2949 - val_accuracy: 0.9062\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1819 - accuracy: 0.9336 - val_loss: 0.2960 - val_accuracy: 0.9062\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1818 - accuracy: 0.9336 - val_loss: 0.2947 - val_accuracy: 0.9062\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1817 - accuracy: 0.9336 - val_loss: 0.2960 - val_accuracy: 0.9062\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1817 - accuracy: 0.9336 - val_loss: 0.2950 - val_accuracy: 0.9062\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1817 - accuracy: 0.9336 - val_loss: 0.2959 - val_accuracy: 0.9062\n",
      "Epoch 800/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1816 - accuracy: 0.9336 - val_loss: 0.2955 - val_accuracy: 0.9062\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1815 - accuracy: 0.9336 - val_loss: 0.2959 - val_accuracy: 0.9062\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1814 - accuracy: 0.9336 - val_loss: 0.2955 - val_accuracy: 0.9062\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1814 - accuracy: 0.9336 - val_loss: 0.2963 - val_accuracy: 0.9062\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1813 - accuracy: 0.9336 - val_loss: 0.2957 - val_accuracy: 0.9062\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1812 - accuracy: 0.9336 - val_loss: 0.2965 - val_accuracy: 0.9062\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1812 - accuracy: 0.9336 - val_loss: 0.2958 - val_accuracy: 0.9062\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1811 - accuracy: 0.9336 - val_loss: 0.2967 - val_accuracy: 0.9062\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1811 - accuracy: 0.9336 - val_loss: 0.2958 - val_accuracy: 0.9062\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1810 - accuracy: 0.9336 - val_loss: 0.2967 - val_accuracy: 0.9062\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1809 - accuracy: 0.9336 - val_loss: 0.2967 - val_accuracy: 0.9062\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1808 - accuracy: 0.9336 - val_loss: 0.2967 - val_accuracy: 0.9062\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1808 - accuracy: 0.9336 - val_loss: 0.2966 - val_accuracy: 0.9062\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1807 - accuracy: 0.9336 - val_loss: 0.2973 - val_accuracy: 0.9062\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1806 - accuracy: 0.9336 - val_loss: 0.2963 - val_accuracy: 0.9062\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1806 - accuracy: 0.9336 - val_loss: 0.2973 - val_accuracy: 0.9062\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1805 - accuracy: 0.9336 - val_loss: 0.2964 - val_accuracy: 0.9062\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1805 - accuracy: 0.9336 - val_loss: 0.2980 - val_accuracy: 0.9062\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1804 - accuracy: 0.9336 - val_loss: 0.2967 - val_accuracy: 0.9062\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1803 - accuracy: 0.9336 - val_loss: 0.2980 - val_accuracy: 0.9062\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1803 - accuracy: 0.9336 - val_loss: 0.2970 - val_accuracy: 0.9062\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1802 - accuracy: 0.9336 - val_loss: 0.2979 - val_accuracy: 0.9062\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1801 - accuracy: 0.9336 - val_loss: 0.2968 - val_accuracy: 0.9062\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1801 - accuracy: 0.9336 - val_loss: 0.2985 - val_accuracy: 0.9062\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1800 - accuracy: 0.9336 - val_loss: 0.2977 - val_accuracy: 0.9062\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1799 - accuracy: 0.9336 - val_loss: 0.2985 - val_accuracy: 0.9062\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1799 - accuracy: 0.9336 - val_loss: 0.2976 - val_accuracy: 0.9062\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1798 - accuracy: 0.9336 - val_loss: 0.2984 - val_accuracy: 0.9062\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1797 - accuracy: 0.9336 - val_loss: 0.2979 - val_accuracy: 0.9062\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1797 - accuracy: 0.9336 - val_loss: 0.2983 - val_accuracy: 0.9062\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1796 - accuracy: 0.9336 - val_loss: 0.2980 - val_accuracy: 0.9062\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1796 - accuracy: 0.9336 - val_loss: 0.2992 - val_accuracy: 0.9062\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1795 - accuracy: 0.9336 - val_loss: 0.2981 - val_accuracy: 0.9062\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1794 - accuracy: 0.9336 - val_loss: 0.2993 - val_accuracy: 0.9062\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1793 - accuracy: 0.9336 - val_loss: 0.2981 - val_accuracy: 0.9062\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1793 - accuracy: 0.9336 - val_loss: 0.2997 - val_accuracy: 0.9062\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1792 - accuracy: 0.9336 - val_loss: 0.2987 - val_accuracy: 0.9062\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1791 - accuracy: 0.9336 - val_loss: 0.2998 - val_accuracy: 0.9062\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1790 - accuracy: 0.9336 - val_loss: 0.2990 - val_accuracy: 0.9062\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1790 - accuracy: 0.9336 - val_loss: 0.3003 - val_accuracy: 0.9062\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1789 - accuracy: 0.9336 - val_loss: 0.2993 - val_accuracy: 0.9062\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1788 - accuracy: 0.9336 - val_loss: 0.3004 - val_accuracy: 0.9062\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1788 - accuracy: 0.9336 - val_loss: 0.2995 - val_accuracy: 0.9062\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1787 - accuracy: 0.9336 - val_loss: 0.3005 - val_accuracy: 0.9062\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1786 - accuracy: 0.9336 - val_loss: 0.2999 - val_accuracy: 0.9062\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1786 - accuracy: 0.9336 - val_loss: 0.3010 - val_accuracy: 0.9062\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1785 - accuracy: 0.9336 - val_loss: 0.2997 - val_accuracy: 0.9062\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1784 - accuracy: 0.9336 - val_loss: 0.3010 - val_accuracy: 0.9062\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1784 - accuracy: 0.9336 - val_loss: 0.2999 - val_accuracy: 0.9062\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1783 - accuracy: 0.9336 - val_loss: 0.3011 - val_accuracy: 0.9062\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1782 - accuracy: 0.9336 - val_loss: 0.3001 - val_accuracy: 0.9062\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1782 - accuracy: 0.9336 - val_loss: 0.3008 - val_accuracy: 0.9062\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1781 - accuracy: 0.9336 - val_loss: 0.3009 - val_accuracy: 0.9062\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1780 - accuracy: 0.9336 - val_loss: 0.3012 - val_accuracy: 0.9062\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1780 - accuracy: 0.9336 - val_loss: 0.3007 - val_accuracy: 0.9062\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1779 - accuracy: 0.9336 - val_loss: 0.3016 - val_accuracy: 0.9062\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1779 - accuracy: 0.9336 - val_loss: 0.3008 - val_accuracy: 0.9062\n",
      "Epoch 857/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1778 - accuracy: 0.9336 - val_loss: 0.3018 - val_accuracy: 0.9062\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1777 - accuracy: 0.9336 - val_loss: 0.3011 - val_accuracy: 0.9062\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1776 - accuracy: 0.9336 - val_loss: 0.3019 - val_accuracy: 0.9062\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1776 - accuracy: 0.9336 - val_loss: 0.3014 - val_accuracy: 0.9062\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1775 - accuracy: 0.9336 - val_loss: 0.3022 - val_accuracy: 0.9062\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1775 - accuracy: 0.9336 - val_loss: 0.3014 - val_accuracy: 0.9062\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1774 - accuracy: 0.9336 - val_loss: 0.3025 - val_accuracy: 0.9062\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1773 - accuracy: 0.9336 - val_loss: 0.3015 - val_accuracy: 0.9062\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1773 - accuracy: 0.9336 - val_loss: 0.3026 - val_accuracy: 0.9062\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1772 - accuracy: 0.9336 - val_loss: 0.3017 - val_accuracy: 0.9062\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1771 - accuracy: 0.9336 - val_loss: 0.3030 - val_accuracy: 0.9062\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1770 - accuracy: 0.9336 - val_loss: 0.3020 - val_accuracy: 0.9062\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1770 - accuracy: 0.9336 - val_loss: 0.3030 - val_accuracy: 0.9062\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1769 - accuracy: 0.9336 - val_loss: 0.3022 - val_accuracy: 0.9062\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1769 - accuracy: 0.9336 - val_loss: 0.3032 - val_accuracy: 0.9062\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1769 - accuracy: 0.9336 - val_loss: 0.3023 - val_accuracy: 0.9062\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1767 - accuracy: 0.9336 - val_loss: 0.3031 - val_accuracy: 0.9062\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1767 - accuracy: 0.9336 - val_loss: 0.3025 - val_accuracy: 0.9062\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1766 - accuracy: 0.9336 - val_loss: 0.3035 - val_accuracy: 0.9062\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1765 - accuracy: 0.9336 - val_loss: 0.3028 - val_accuracy: 0.9062\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1765 - accuracy: 0.9336 - val_loss: 0.3037 - val_accuracy: 0.9062\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1764 - accuracy: 0.9336 - val_loss: 0.3027 - val_accuracy: 0.9062\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1764 - accuracy: 0.9336 - val_loss: 0.3039 - val_accuracy: 0.9062\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1763 - accuracy: 0.9336 - val_loss: 0.3029 - val_accuracy: 0.9062\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1762 - accuracy: 0.9336 - val_loss: 0.3041 - val_accuracy: 0.9062\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1762 - accuracy: 0.9336 - val_loss: 0.3030 - val_accuracy: 0.9062\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1761 - accuracy: 0.9336 - val_loss: 0.3043 - val_accuracy: 0.9062\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1761 - accuracy: 0.9336 - val_loss: 0.3030 - val_accuracy: 0.9062\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1759 - accuracy: 0.9336 - val_loss: 0.3041 - val_accuracy: 0.9062\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1759 - accuracy: 0.9336 - val_loss: 0.3032 - val_accuracy: 0.9062\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1759 - accuracy: 0.9336 - val_loss: 0.3045 - val_accuracy: 0.9062\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1758 - accuracy: 0.9336 - val_loss: 0.3034 - val_accuracy: 0.9062\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1757 - accuracy: 0.9336 - val_loss: 0.3042 - val_accuracy: 0.9062\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1756 - accuracy: 0.9336 - val_loss: 0.3036 - val_accuracy: 0.9062\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1754 - accuracy: 0.9336 - val_loss: 0.3043 - val_accuracy: 0.9062\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1753 - accuracy: 0.9336 - val_loss: 0.3043 - val_accuracy: 0.9062\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1752 - accuracy: 0.9336 - val_loss: 0.3046 - val_accuracy: 0.9062\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1751 - accuracy: 0.9336 - val_loss: 0.3041 - val_accuracy: 0.9062\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1750 - accuracy: 0.9336 - val_loss: 0.3052 - val_accuracy: 0.9062\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1749 - accuracy: 0.9336 - val_loss: 0.3043 - val_accuracy: 0.9062\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1748 - accuracy: 0.9336 - val_loss: 0.3052 - val_accuracy: 0.9062\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1747 - accuracy: 0.9336 - val_loss: 0.3046 - val_accuracy: 0.9062\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1746 - accuracy: 0.9336 - val_loss: 0.3053 - val_accuracy: 0.9062\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1745 - accuracy: 0.9336 - val_loss: 0.3047 - val_accuracy: 0.9062\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1744 - accuracy: 0.9336 - val_loss: 0.3056 - val_accuracy: 0.9062\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1743 - accuracy: 0.9336 - val_loss: 0.3044 - val_accuracy: 0.9062\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1742 - accuracy: 0.9297 - val_loss: 0.3058 - val_accuracy: 0.9062\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1741 - accuracy: 0.9336 - val_loss: 0.3045 - val_accuracy: 0.9062\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1739 - accuracy: 0.9336 - val_loss: 0.3054 - val_accuracy: 0.9062\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1738 - accuracy: 0.9336 - val_loss: 0.3044 - val_accuracy: 0.9062\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1737 - accuracy: 0.9336 - val_loss: 0.3056 - val_accuracy: 0.9062\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1735 - accuracy: 0.9336 - val_loss: 0.3045 - val_accuracy: 0.9062\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1735 - accuracy: 0.9336 - val_loss: 0.3051 - val_accuracy: 0.9062\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1733 - accuracy: 0.9336 - val_loss: 0.3042 - val_accuracy: 0.9062\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1732 - accuracy: 0.9336 - val_loss: 0.3055 - val_accuracy: 0.9062\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1731 - accuracy: 0.9336 - val_loss: 0.3040 - val_accuracy: 0.9062\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1730 - accuracy: 0.9336 - val_loss: 0.3051 - val_accuracy: 0.9062\n",
      "Epoch 914/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1728 - accuracy: 0.9336 - val_loss: 0.3041 - val_accuracy: 0.9062\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1727 - accuracy: 0.9336 - val_loss: 0.3048 - val_accuracy: 0.9062\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1726 - accuracy: 0.9336 - val_loss: 0.3045 - val_accuracy: 0.9062\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1725 - accuracy: 0.9336 - val_loss: 0.3052 - val_accuracy: 0.9062\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1724 - accuracy: 0.9336 - val_loss: 0.3042 - val_accuracy: 0.9062\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1723 - accuracy: 0.9336 - val_loss: 0.3054 - val_accuracy: 0.9062\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1722 - accuracy: 0.9336 - val_loss: 0.3047 - val_accuracy: 0.9062\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1721 - accuracy: 0.9336 - val_loss: 0.3051 - val_accuracy: 0.9062\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1720 - accuracy: 0.9336 - val_loss: 0.3048 - val_accuracy: 0.9062\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1719 - accuracy: 0.9336 - val_loss: 0.3053 - val_accuracy: 0.9062\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1717 - accuracy: 0.9336 - val_loss: 0.3050 - val_accuracy: 0.9062\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1717 - accuracy: 0.9336 - val_loss: 0.3058 - val_accuracy: 0.9062\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1715 - accuracy: 0.9336 - val_loss: 0.3050 - val_accuracy: 0.9062\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1715 - accuracy: 0.9336 - val_loss: 0.3064 - val_accuracy: 0.9062\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1714 - accuracy: 0.9336 - val_loss: 0.3053 - val_accuracy: 0.9062\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1712 - accuracy: 0.9336 - val_loss: 0.3059 - val_accuracy: 0.9062\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1712 - accuracy: 0.9336 - val_loss: 0.3054 - val_accuracy: 0.9062\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1711 - accuracy: 0.9336 - val_loss: 0.3062 - val_accuracy: 0.9062\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1710 - accuracy: 0.9336 - val_loss: 0.3057 - val_accuracy: 0.9062\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1709 - accuracy: 0.9336 - val_loss: 0.3069 - val_accuracy: 0.9062\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1708 - accuracy: 0.9336 - val_loss: 0.3057 - val_accuracy: 0.9062\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1707 - accuracy: 0.9336 - val_loss: 0.3069 - val_accuracy: 0.9062\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1705 - accuracy: 0.9336 - val_loss: 0.3065 - val_accuracy: 0.9062\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1705 - accuracy: 0.9336 - val_loss: 0.3067 - val_accuracy: 0.9062\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1704 - accuracy: 0.9336 - val_loss: 0.3069 - val_accuracy: 0.9062\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1703 - accuracy: 0.9336 - val_loss: 0.3069 - val_accuracy: 0.9062\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1702 - accuracy: 0.9336 - val_loss: 0.3072 - val_accuracy: 0.9062\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1701 - accuracy: 0.9336 - val_loss: 0.3067 - val_accuracy: 0.9062\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1700 - accuracy: 0.9336 - val_loss: 0.3074 - val_accuracy: 0.9062\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1699 - accuracy: 0.9336 - val_loss: 0.3073 - val_accuracy: 0.9062\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1698 - accuracy: 0.9336 - val_loss: 0.3071 - val_accuracy: 0.9062\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1697 - accuracy: 0.9336 - val_loss: 0.3083 - val_accuracy: 0.9062\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1697 - accuracy: 0.9336 - val_loss: 0.3068 - val_accuracy: 0.9062\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1696 - accuracy: 0.9336 - val_loss: 0.3087 - val_accuracy: 0.9062\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1695 - accuracy: 0.9336 - val_loss: 0.3075 - val_accuracy: 0.9062\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1694 - accuracy: 0.9336 - val_loss: 0.3082 - val_accuracy: 0.9062\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1693 - accuracy: 0.9336 - val_loss: 0.3074 - val_accuracy: 0.9062\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1692 - accuracy: 0.9336 - val_loss: 0.3086 - val_accuracy: 0.9062\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1692 - accuracy: 0.9336 - val_loss: 0.3079 - val_accuracy: 0.9062\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1691 - accuracy: 0.9336 - val_loss: 0.3087 - val_accuracy: 0.9062\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1690 - accuracy: 0.9336 - val_loss: 0.3079 - val_accuracy: 0.9062\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1689 - accuracy: 0.9336 - val_loss: 0.3094 - val_accuracy: 0.9062\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1689 - accuracy: 0.9297 - val_loss: 0.3079 - val_accuracy: 0.9062\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1688 - accuracy: 0.9336 - val_loss: 0.3095 - val_accuracy: 0.9062\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1687 - accuracy: 0.9297 - val_loss: 0.3081 - val_accuracy: 0.9062\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1686 - accuracy: 0.9336 - val_loss: 0.3095 - val_accuracy: 0.9062\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1685 - accuracy: 0.9336 - val_loss: 0.3084 - val_accuracy: 0.9062\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1684 - accuracy: 0.9336 - val_loss: 0.3091 - val_accuracy: 0.9062\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1683 - accuracy: 0.9336 - val_loss: 0.3092 - val_accuracy: 0.9062\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1683 - accuracy: 0.9336 - val_loss: 0.3091 - val_accuracy: 0.9062\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1682 - accuracy: 0.9336 - val_loss: 0.3095 - val_accuracy: 0.9062\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1681 - accuracy: 0.9336 - val_loss: 0.3096 - val_accuracy: 0.9062\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1680 - accuracy: 0.9336 - val_loss: 0.3094 - val_accuracy: 0.9062\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1680 - accuracy: 0.9336 - val_loss: 0.3105 - val_accuracy: 0.9062\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1679 - accuracy: 0.9297 - val_loss: 0.3091 - val_accuracy: 0.9062\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1679 - accuracy: 0.9336 - val_loss: 0.3109 - val_accuracy: 0.9062\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1677 - accuracy: 0.9297 - val_loss: 0.3099 - val_accuracy: 0.9062\n",
      "Epoch 971/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1677 - accuracy: 0.9336 - val_loss: 0.3107 - val_accuracy: 0.9062\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1675 - accuracy: 0.9297 - val_loss: 0.3100 - val_accuracy: 0.9062\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1675 - accuracy: 0.9336 - val_loss: 0.3107 - val_accuracy: 0.9062\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1674 - accuracy: 0.9336 - val_loss: 0.3105 - val_accuracy: 0.9062\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1673 - accuracy: 0.9336 - val_loss: 0.3112 - val_accuracy: 0.9062\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1672 - accuracy: 0.9297 - val_loss: 0.3105 - val_accuracy: 0.9062\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1672 - accuracy: 0.9336 - val_loss: 0.3113 - val_accuracy: 0.9062\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1671 - accuracy: 0.9297 - val_loss: 0.3105 - val_accuracy: 0.9062\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1670 - accuracy: 0.9336 - val_loss: 0.3117 - val_accuracy: 0.9062\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1669 - accuracy: 0.9297 - val_loss: 0.3106 - val_accuracy: 0.9062\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1669 - accuracy: 0.9336 - val_loss: 0.3120 - val_accuracy: 0.9062\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1668 - accuracy: 0.9297 - val_loss: 0.3111 - val_accuracy: 0.9062\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1667 - accuracy: 0.9336 - val_loss: 0.3119 - val_accuracy: 0.9062\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1666 - accuracy: 0.9297 - val_loss: 0.3117 - val_accuracy: 0.9062\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1666 - accuracy: 0.9336 - val_loss: 0.3118 - val_accuracy: 0.9062\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1665 - accuracy: 0.9297 - val_loss: 0.3114 - val_accuracy: 0.9062\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1664 - accuracy: 0.9336 - val_loss: 0.3121 - val_accuracy: 0.9062\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1663 - accuracy: 0.9297 - val_loss: 0.3118 - val_accuracy: 0.9062\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1663 - accuracy: 0.9336 - val_loss: 0.3126 - val_accuracy: 0.9062\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1663 - accuracy: 0.9297 - val_loss: 0.3113 - val_accuracy: 0.9062\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1662 - accuracy: 0.9336 - val_loss: 0.3129 - val_accuracy: 0.9062\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1661 - accuracy: 0.9297 - val_loss: 0.3115 - val_accuracy: 0.9062\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1660 - accuracy: 0.9336 - val_loss: 0.3129 - val_accuracy: 0.9062\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1659 - accuracy: 0.9297 - val_loss: 0.3119 - val_accuracy: 0.9062\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1658 - accuracy: 0.9336 - val_loss: 0.3133 - val_accuracy: 0.9062\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1658 - accuracy: 0.9297 - val_loss: 0.3123 - val_accuracy: 0.9062\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1657 - accuracy: 0.9336 - val_loss: 0.3129 - val_accuracy: 0.9062\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1657 - accuracy: 0.9297 - val_loss: 0.3125 - val_accuracy: 0.9062\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1656 - accuracy: 0.9336 - val_loss: 0.3131 - val_accuracy: 0.9062\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1656 - accuracy: 0.9297 - val_loss: 0.3124 - val_accuracy: 0.9062\n",
      "26.914271116256714\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "model.compile(loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train,y_train,epochs=1000,batch_size=X_train.shape[0],validation_split=0.2)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe1fa526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24ccdaef3d0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55af268d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24cd22c7f10>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhtklEQVR4nO3de3xcdZ3/8dcnk0zS3JsmadM2bVPaAuVWMJZ6weUuoAveWIHVRUVZXVHU3fUHP110+bkLu+tvXdxlXYGtVwRXVrBotYq4gojYVin2Qi+09H5JL2numZnMd/84J8nk1kySmcycyfv5eOSRc/nOzOfktO988z03c84hIiLBl5fpAkREJDUU6CIiOUKBLiKSIxToIiI5QoEuIpIj8jP1wdXV1W7BggWZ+ngRkUBav379UedczXDrMhboCxYsYN26dZn6eBGRQDKz3SOt05CLiEiOUKCLiOQIBbqISI5QoIuI5AgFuohIjlCgi4jkCAW6iEiOyNh56CISbA8+s5P1u0/QEe0hHDJmV06jtStGTVkhRfnZ31ds6+6htStKXUXRuF4fd7D21eMsm1dJYSiPprZuDrd0U1NayMGWLooLQnREe/p+Fp3RHkrC+ZxXX8mH/2ghZpbKzQEU6CIyDpsPtPB3q7eMuD4NWZVyiY+CGE+9va9/YdfxMb3uJ5sO8UdLalg6u3zsHzoKBbpIjvrYI7/nyQ0HJvQe82cUs/tYx4B5gM5Izylft+uet0zocyfDgjt+BMCue64ZV2+58Qs/42hbpO89Gu5cnfRrtx9pVaCLyEDdsR7au3uIxOJUlYR5+VALcQfOuQmHOUDFtIIB88vqK+mNvide9N7fzOut3n/TBZzsjHJGXdmEP3cyPPKhFRxo7hz30Md3PrSCv3j4d9z7jnMwM/7+7efwfx//A7e+aSE/3XSIV4919P1sBptRUjjB6odnmXoEXWNjo9O9XEQm5tZvruOnmw8D8JZz6vjRHw6m9P0f+/DreNd/PN83/+q9/T3v3h5u4jJJPzNb75xrHG6deugiKdQV7eFbz+/meEeEp7ccobQon0Mnu5hZXkhRQYglM1Pbe+0Nc4Af/eEg82cU8/k/PguAWNxRmJ9HJBYnLw8KQnl0ReOUhEPUVxXz8qFWCvPz6Ik7euKOooIQpUX5FIdDFOWHaGrr5jXzp/PcHZey+UALZ88ZOETw289cRn5e9h/8nEoU6CIp9MAzO/nnn20bsnx/cycAG/Y2E8pLzxHD8qJ83rZsDpecUZtU+/qq4lOun+ePl8+pnMacymlD1teWje/sEEkfBbpMSZ9+bANPbTkyZHlbV4xIT7xv/vIza3no5tf2zR9p6eJd//E8bd2xYd/3eHvklJ/7zKcvYUZpesZPRRToEkgn2iNsPHByXK91Dp7ccJBFtaUsq68csO5bvxl4q+mnthzh2e1NffPrXj3BnuMdvG3ZbMqKBh4w7PX7vScoCOVxpKWb5Q1VNLV2E87P44J5lQpzSSsFugTSZ5/YOOEDgB+8qIHrls0ZsKy0KJ+v/M8rA5a99z9/O2C+JBziH951LoX5oQl9vkiqKdBlUj307E5ePtQ64fd5dnsTFy2u5vbLFo/r9QWhPM6eUzFk+V9deTrXnjebSCxOKM/oig4933pmeZHCXLKSAl0mTUckxt+t3kJ5UQGlhRP7p1c+rYAbl8+jcUFViqrzhPKMM+tSf8GHyGRI6n+VmV0F3AeEgIecc/cOWj8fWAnUAMeB9zjn9qW41qnnwcvg4AbIL4T3/DfMW5HpipJy95ObWfncLgpCA8/mcA7yXA+/DX+Mwq5jkDf8GHTSHve/RILmmn+Cxven/G1HDXQzCwH3A1cA+4C1ZrbKObc5odkXgW86575hZpcC9wDvTXm1U0k8DvvXQd15Xqgf2ZwVgd7WHeNX248SP8UFaSuf2wXAJafXsqi2dMC6Kmul8Plj3sySN0P1krTVKpK1Zp2TlrdNpoe+HNjhnNsJYGaPAtcBiYG+FPiUP/0L4IkU1jg1xbzzlll8pRfokY5Tt58kDz6zk/t+vj2ptv/n6jM4rWZgoNO8F3ovPDz/PXD61aktUGQKSybQ5wB7E+b3ARcOarMBeAfesMzbgTIzm+GcO5bYyMxuBW4FmDdv3nhrnhoi7d73ktqB85Ps+7/bx5pNh/rmX9p3koU1JXzlT18z4mvMoKokTPVwp+glbke4JJWlikx5qToo+lfAv5nZ+4BngP3AkNMDnHMPAA+Ady+XFH12boq0ed8LyyC/qH9+ksTjjkhPnH97egfH2iN994yumFbAnzTWc/qscV7CrkAXSZtkAn0/UJ8wP9df1sc5dwCvh46ZlQLvdM41p6jGqak3+MIl3tck99Cv/+rzrN99AoBPXr6E2y8f3+mBQyT+YipQoIukUjKBvhZYbGYNeEF+A3BTYgMzqwaOO+fiwJ14Z7zIqWxbA22HR15/3Duw2BfohzfC776Z2hqmL4CGNw1ZvO9EB+t3n+CyM2q5aF6YdxX/Gn73/NDXj8fhTf3TeTprViSVRv0f5ZyLmdltwBq80xZXOuc2mdndwDrn3CrgYuAeM3N4Qy4fTWPNwdd6GL7zJ0k0NKiYC5Xz4dVnYe8Lqa0jrwA+exjyBl4k841fvwrAh960kBVH/gt+ckdqP7dXSXV63ldkikqqi+ScWw2sHrTsroTpx4DHUltaDuvy70Fy9T/BGdeM3K6gGIqrvHPQ25tGbjcGB5o7+f8/3cobW37E21u/wwce/CVdeQPvurftcCsN1SWsWDgD/GEXPvEHsBTdKjVcAuEyCKmHLpJK+h+VCb3jyJX1Xg98NPmFybU7hVhPnOMdEb7/yl7++xVjSY13hWUo1kE0NPA2qA3VJVz/Gv+wSaTdG+uu1FlJItlOgZ4JiQc8J8mHv/07ntrijdnXlBXy55efC4/DgzecCTNOG/mFkXadjSISEAr0TJiEQP/JxkPsO9F/MdJvdh7j9afN4Jpz6ryH07Y/59cyyumQCnSRwFCgZ0K0N9BLT91unNq6Y3zk4fVDHk5704XzeOu5s72ZV/yQHu0K1Eh72uoUkdRSoE+GeA9872bvsneAjuPe94JTPwJsvI60dOEc3POOc3jruXWAdxfB4nDC7u4N6R981Lt4aSTHXoGZS9NSp4iklgJ9MnQchy1PQu1SqKiH0plw2iVQPjvlH9UTd2w60AJA/fTiEZ+qw8ylcM710NVy6jcsnQlnvT3FVYpIOijQJ0PvOPXrPw7LbkzrR9331Da+/PQOAOoqT/EQ33AJvPOhtNYiIpNLgT4ZJvGslnW7T7CwuoS7/njp0DsdikhOS9GVInJKkxTozjm2HGxheUMVF59em9bPEpHsox76ZOgdcpnA2SLOOT7w9bXsOjryTbriDk50RPUINZEpSoE+Gfp66OM/q+V3e5r5xdYmXjN/OnOnTxux3YUNVVx99qxxf46IBJcCfTJMcMjFOcd7HvJuzPW315417NPqRUQ0hj4ZJjjk8vzOY3RGe3jbstkKcxEZkQJ9MkT9qzHH2UN/csNBAG67dFGqKhKRHKQhl8kQaQcM8kce+x7Og8/s5D9++QotXVEubKhiUe04H/smIlOCAn0y9N7gKm/0P4iOt0fY7F/p+e0XdpOXZ7z7tfX992ARERmBAn0yRNqSHm756+9t4OcvH+mbv/zMWr7wtnPSVZmI5BAFeiqs+xo0bYUL3gsvfNW7GRcQi8f5w/6T1Le+iCOff/zeBszgpgvns6y+EvCGVbYdbu17qxd2HefyM2tZMrOMf/+fV+iJu+E+UURkCAV6KvzwE9734zth+xoonwMYsVgPte0RYmY8G1rOczuO0tTWTWc0zr/eeD4tXVH+bvUWKqYVUBL2nutZWVzADa+dx5KZZfx082Gub6zP2GaJSLAo0FOp7bD34OVPbebZ7U289z9/C8CGu67k+uICrgc++I11PLnhAE9uOND3si+9+zwuPWPmkLd76lN/NFmVi0gO0GmLE+UPrwDQdgQXLuGX25p4bP0+AP7f286morj/FrafvGIxH7m4/5Fvf3zebN64qGbSyhWR3KUe+kRFEu6t0naYyLRabl7p9czLi/J574r5A5qfNbuCs2ZX0Bnp4eu/fpUvXn8u4Xz9XhWRiVOgT1RioLse9rb3h3NRQWjEl/3NW5fyySuWUJg/chsRkbFQoE/UoIcst7lCzptbgQMuP3PouHivUJ5RMW2EpwmJiIyDAn2invjIwPnCMn5w2xszU4uITGkK9Alo644Rbz5OOfDj07/ASxs30nDBW1mW6cJEZEpSoE/AIy/s4bKWdp52r+cTGxYSDi3iV5dckumyRGSK0ukV4+Sc476fbydsMaIun9kVRaz9zOXUlp3iwcwiImmkHvo47T3eSVt3jJLiODVlZdx11VkDzjcXEZlsCvRx2nzwJABlBY6Ll84BPfZNRDJMQy7jtPlgK3kGIReFUDjT5YiIKNDHa8vBFhqqS7CeKOTpDx0RyTwF+jhtPtDC0rpy6Imohy4iWSGpQDezq8xsq5ntMLM7hlk/z8x+YWa/N7OXzOya1JeaPXrijoMnO2mYUQg4BbqIZIVRA93MQsD9wNXAUuBGM1s6qNlngf9yzp0P3AD8e6oLzSbH2ruJO5hV4v/4Qjq7RUQyL5ke+nJgh3Nup3MuAjwKXDeojQPK/ekK4AA57GhrBICaYv/GWuqhi0gWSOZo3hxgb8L8PuDCQW0+D/zUzD4GlACXp6S6LHWiwwv0qt5riNRDF5EskKqDojcCX3fOzQWuAb5lZkPe28xuNbN1ZrauqakpRR89+dq7YwBUN2/wFijQRSQLJBPo+4HEB1vO9ZclugX4LwDn3PNAEVA9+I2ccw845xqdc401NcF9Sk9HxHtKUWnbbm9B/eA/WEREJl8ygb4WWGxmDWYWxjvouWpQmz3AZQBmdiZeoAe3Cz6K9ojXQy90Xd6C6iUZrEZExDNqoDvnYsBtwBpgC97ZLJvM7G4zu9Zv9pfAh8xsA/AI8D7nnEtX0ZnW+4DncE8HFBRDnp46JCKZl9Qljs651cDqQcvuSpjeDLwhtaVlJ+ccv9l5HID8nk4Il2S4IhERj64UHaODJ7v6pvOi7V4PXUQkCyjQx+iZbd6hgY+fH4LmPRAuzXBFIiIeBfoYrXxuFwCf2PMx2PM8lAb3bB0RyS0K9DGI9cTZfayDt5w9i7z2JjjvJnjnykyXJSICKNDH5NVj7XTH4lyxuBxwUHM6lMzIdFkiIoACfUxePtQKwJnV/mmKOsNFRLKIAn0Mmlq7AZhV5F0pqkAXkWyiQB+D1i7vCtES809dVKCLSBZRoI9BS2eUknCI/L2/9hYo0EUkiyjQx6ClK0r5tAI4tsNbMPPszBYkIpJAgT4GLZ0xyoryIdIOFfVQNivTJYmI9FGgj0Frd5TyogKItGm4RUSyjgJ9DFo6Y96QS6RdgS4iWUeBPgYtXVHKi/Ih0qGbcolI1lGgj0FLZ5SyogLoOKqbcolI1lGgJ6kn7mjtilEXOglHt+mhFiKSdRToSdp1tI1Y3HF6sXf5Pw1vymxBIiKDKNCTtLOpHYAFZf6T9WqXZrAaEZGhFOhJavEv+y8PRbwFOstFRLKMAj1JLZ1RAIrRfVxEJDsp0JPU0uUFepHr9BYo0EUky+RnuoCgePrlI7wz/BtCL2/xFijQRSTLKNCT0BN3bD7QzOPhf4UdDirnQ7gs02WJiAygIZck7D7WTmG8ixAOrrgbbt8AIf0uFJHsokBPwv7mzoSDoaVgltmCRESGoUBPQlNrd8JTinTJv4hkJwX6KA6d7OLuH26mBO95ojoYKiLZSoE+ih9vPEhzR5QlVf6PSoEuIllKR/ZGceHGv+XVosdxPRXeAg25iEiWUqCPYunBx72JuvNh9nlQd15mCxIRGYECPUm24sNw+tWZLkNEZEQaQ0+Wxs5FJMsp0JOlQBeRLKdAT1aBAl1EsltSY+hmdhVwHxACHnLO3Tto/ZeAS/zZYqDWOVeZwjrHLx6Hnb+AaMfw66tOg5lLYffz0HEM5r8eiquGtgsVpLdOEZEJGjXQzSwE3A9cAewD1prZKufc5t42zrlPJrT/GHB+Gmodnz2/hm+/Y+T1JbVw6//A167y5lf8BVx1z9B2w4W8iEgWSaaHvhzY4ZzbCWBmjwLXAZtHaH8j8LnUlJcCHce879d/A2acNnDdC1+FF7/T3yaxva81r4L1oXO5eNr0NBcqIjIxyQT6HGBvwvw+4MLhGprZfKABeHqE9bcCtwLMmzdvTIWOW8Qfaqk7D6oaBq6bvgBcD3SeSGjfPqBJHj20hCrTWqKISCqk+qDoDcBjzrme4VY65x5wzjU65xprampS/NEjiLR534e7wrN3WXtTQvuBgR5yUeJ54TQVJyKSOskE+n6gPmF+rr9sODcAj0y0qJTqDehw8dB1vacith32vpfUDAn0fBcjTwdERSQAkgn0tcBiM2swszBeaK8a3MjMzgCmA8+ntsQJirQDBvnThq4bHOilMwcGejxOPj1YSD10Ecl+o46hO+diZnYbsAbvtMWVzrlNZnY3sM451xvuNwCPOudc+sodZMOj8Ow/Q/nsoeumVULjLfDMP0J+EeQN87urd8jlpe9530trvdMXv/k2b/74TgDyChToIpL9kjoP3Tm3Glg9aNldg+Y/n7qykvT4n3vfj26Fucv7l3c1e+eed7V48423DP/62ctg4SVer3zeCjjr7d50by+9eTcAJ4vnp6V8EZFUyp2bc33wZ/3Tu56Fb7wV2o9AYTlc9ffDv6a0Fv7siYHLll7bP/1575a5R6pek9paRUTSIDcv/e8bGz8CBcMcDB2jUKHugS4i2S/HA/1wSm6qVVqqQBeR7JfbgT54epxOr6uY8HuIiKTbFAj0ifeul9aVT/g9RETSLbiBHov0T9ecOXBduBTy/IuBJnAPlh5CAFQW67RFEcl+wT3LJeqfWrj4zfCWLw5cFyqAm5+E5j3e6Yjj9LG6b2Pdrdw/gTJFRCZLcAO996ZbZ1wDlcPc6Gv+67yvCdjRUUJDde2E3kNEZLIEd8il7x4t6TkD5W+e2Mi2w21Ulxam5f1FRFItwD303rsopvbRcPG44+VDrTy6dg8A1zfWj/IKEZHsEOBA7+2hpzbQf7BhP5/87gYA7r/pApbVV6b0/UVE0kWBPsjv9zRTWpjPV95zAa9bOCOl7y0ikk4BDvRTPLhiArYcbOHMujIuWjxJD+AQEUmR4B4UjfpnuaTgXi29Hn5hN2tfPcGZupBIRAIouIGehiGXzzy+EYCF1akdxhERmQwBDvT0DLkAnD1H924RkeAJ8Bh6u3d5f/7ol+Wv/NUuth5qZXblND5+2SLMbNh282cUM704TOOCqlRXKyKSdsEO9CSGW+Jxxxd+tJk8M2Jxx3XLZrNghCGVo63dXHbGzFRXKiIyKYI75PLbByCJhze3dsWIO7jmnDrAO4tlOO3dMdojPdSU6cpQEQmm4AZ6KAzldaM2O9kZBWB5QxV5Bj/ZdIg1mw6x51jHgHZH27oBFOgiEljBHXJxDk67dNRmzZ3ebXZnlRexdHY5P3jxAD948QBL68pZfftFfe0ONHcBMLNcgS4iwRTMQHcO4tGkhlyaO7weemVxAQ/fsoJ9zR08/MIevrt2L3/x8Pq+dvtOdAJw+syy9NQsIpJmwQz0Hi+kCRWM2rTZH3KpmFZARXEBFcUVvLuxnt/vaWb74bYBba85Z5aGXEQksAIa6P7TipLoofeOoVcU94f/efWV/DhhuEVEJBcE86BovLeHnkSgd3jhXzFt9N68iEiQBTPQxzLk0hGlOByiMD+U5qJERDIroIGe/JBLc2eUSvXORWQKyPlAP9kZpVyBLiJTQEADPfkhl5MdUSqLFegikvsCGuhjGXKJUDlt9HYiIkGX04HunONwSzczShXoIpL7AhroyQ25HDzZxcnOKGfM0tWfIpL7Ahrow/fQu6I9OOcAOHSyi62HWwGYM33apJYnIpIJSV0pamZXAfcBIeAh59y9w7T5E+DzgAM2OOduSmGdA/UGel5/D70jEmPpXWv4+KWLeP2iam544Dd964rDwbwgVkRkLEZNOjMLAfcDVwD7gLVmtso5tzmhzWLgTuANzrkTZlabroKBYYdcjrd7If/lp3cws6JoQPMSBbqITAHJDLksB3Y453Y65yLAo8B1g9p8CLjfOXcCwDl3JLVlDjLMkEtrV6xvuqm1e0Dz4kJdJSoiuS+ZQJ8D7E2Y3+cvS7QEWGJmz5nZb/whmiHM7FYzW2dm65qamsZXMST00PsDvcW/CRfAvzy1fUBz9dBFZCpI1UHRfGAxcDFwI/CgmVUObuSce8A51+ica6ypqRn/p3We8L4nDLkk9tABLlpc3TetHrqITAXJBPp+oD5hfq6/LNE+YJVzLuqc2wVswwv49Fj9V973hB567xh6r3vfeW7fdHGBAl1Ecl8yYxFrgcVm1oAX5DcAg89geQKvZ/41M6vGG4LZmcI6h+cHent3jHt+vIVwfh4/vv0ioj1x5lRO44mPvoHicIj8UDDPzhQRGYtRA905FzOz24A1eKctrnTObTKzu4F1zrlV/rorzWwz0AP8tXPuWDoLB/qGXJ7acpgTHVHeuKia02pK+1Yvq69MewkiItkiqaOFzrnVwOpBy+5KmHbAp/yv9PIvHAL6euj/+JOt5BmsfN9r0/7xIiLZKnhjEbGu/ulQmK5oD/ubO7lg3nTC+cHbHBGRVAleAkY6+qfzQrzS5D3o+f1vaMhQQSIi2SGAgd7WP23GyQ7v/HPdUVFEprrgBXq0c8BsS5cX6GVFunhIRKa24AV672X/7/42AC2d3gVF5UV6KpGITG0BDPSBl/339tD13FARmeqCF+jxgXdaPNoWIT/PKC3UkIuITG3BC/RBd1rceqiFRbWlhPIsg0WJiGRe4AN974lOFswoyWBBIiLZIYCBPnDIpbkjwvQSnbIoIhLAQO/voTvnaO6IMr1YB0RFRAIY6P1nubR2x4jFHdOL1UMXEQlgoPc+IDqf5nYv3CvVQxcRCXCgh8Kc6PCm1UMXEQlkoPcPuTT7zxGdXqIeuohIgAO9gHWvHgegUj10EZEgBnr/kMsvtzUBMKu8KIMFiYhkh+BdL3/hh+GCPyMeKmJnUzvvbqynRJf9i4gEMNALiqCgiN1H22nrjrFsXmWmKxIRyQrBG3Lx/ctT2wA4e3ZFhisREckOgQ30jkgPAGfPKc9wJSIi2SGwgd7SGWX5girMdJdFEREIcqB3xSifFrxDACIi6RLYQG/tiuqxcyIiCQIZ6M45TrRH9Ng5EZEEgQz0fSc6aY/0sKi2NNOliIhkjUAG+p7jHQAsrNGTikREegUy0Fv8m3JVTtM9XEREegUy0Fu7YgA6y0VEJEEgA72ly+uh66CoiEi/YAZ6ZxQzKA2rhy4i0iuQgb6/uYvq0kLy8nSVqIhIr0AG+tbDLZwxqyzTZYiIZJWkAt3MrjKzrWa2w8zuGGb9+8ysycxe9L8+mPpS+zV3RKkuLUznR4iIBM6og9BmFgLuB64A9gFrzWyVc27zoKbfdc7dloYah4jE4oRDgfzjQkQkbZJJxeXADufcTudcBHgUuC69ZZ1atCdOOF+BLiKSKJlUnAPsTZjf5y8b7J1m9pKZPWZm9cO9kZndambrzGxdU1PTOMr1RGIKdBGRwVKVik8CC5xz5wI/A74xXCPn3APOuUbnXGNNTc24PyyiHrqIyBDJpOJ+ILHHPddf1sc5d8w51+3PPgS8JjXlDRWPO6I9jgKNoYuIDJBMKq4FFptZg5mFgRuAVYkNzKwuYfZaYEvqShwoGo8DUKgeuojIAKOe5eKci5nZbcAaIASsdM5tMrO7gXXOuVXAx83sWiAGHAfel66CIzEv0HWWi4jIQEldO++cWw2sHrTsroTpO4E7U1va8PoCXT10EZEBApeKkR4v0DWGLiIyUOBSMRpzgHroIiKDBS4Vu2M9gA6KiogMFrhUbI94gV5SGMpwJSIi2SVwgd7R7T2tqFj3QhcRGSBwgd7XQ1egi4gMELhA74j4PXQNuYiIDBDAQPd66MVhBbqISKLABXq7xtBFRIYVuECfV1XMVWfNUg9dRGSQwHVzrzxrFleeNSvTZYiIZJ3A9dBFRGR4CnQRkRyhQBcRyREKdBGRHKFAFxHJEQp0EZEcoUAXEckRCnQRkRxhzrnMfLBZE7B7nC+vBo6msJwg0DZPDdrmqWEi2zzfOVcz3IqMBfpEmNk651xjpuuYTNrmqUHbPDWka5s15CIikiMU6CIiOSKogf5ApgvIAG3z1KBtnhrSss2BHEMXEZGhgtpDFxGRQRToIiI5InCBbmZXmdlWM9thZndkup5UMbN6M/uFmW02s01mdru/vMrMfmZm2/3v0/3lZmZf9n8OL5nZBZndgvExs5CZ/d7MfujPN5jZC/52fdfMwv7yQn9+h79+QUYLHyczqzSzx8zsZTPbYmavmwL7+JP+v+mNZvaImRXl4n42s5VmdsTMNiYsG/O+NbOb/fbbzezmsdQQqEA3sxBwP3A1sBS40cyWZraqlIkBf+mcWwqsAD7qb9sdwM+dc4uBn/vz4P0MFvtftwJfmfySU+J2YEvC/D8AX3LOLQJOALf4y28BTvjLv+S3C6L7gJ84584AzsPb9pzdx2Y2B/g40OicOxsIATeQm/v568BVg5aNad+aWRXwOeBCYDnwud5fAklxzgXmC3gdsCZh/k7gzkzXlaZt/QFwBbAVqPOX1QFb/emvAjcmtO9rF5QvYK7/j/xS4IeA4V09lz94fwNrgNf50/l+O8v0NoxxeyuAXYPrzvF9PAfYC1T5++2HwJtzdT8DC4CN4923wI3AVxOWD2g32legeuj0/+Potc9fllP8PzPPB14AZjrnDvqrDgEz/elc+Fn8C/BpIO7PzwCanXMxfz5xm/q2119/0m8fJA1AE/A1f5jpITMrIYf3sXNuP/BFYA9wEG+/rSe393Oise7bCe3zoAV6zjOzUuC/gU8451oS1znvV3ZOnGdqZm8Fjjjn1me6lkmUD1wAfMU5dz7QTv+f4EBu7WMAf7jgOrxfZrOBEoYOS0wJk7Fvgxbo+4H6hPm5/rKcYGYFeGH+sHPu+/7iw2ZW56+vA474y4P+s3gDcK2ZvQo8ijfsch9QaWb5fpvEberbXn99BXBsMgtOgX3APufcC/78Y3gBn6v7GOByYJdzrsk5FwW+j7fvc3k/Jxrrvp3QPg9aoK8FFvtHyMN4B1dWZbimlDAzA/4T2OKc++eEVauA3iPdN+ONrfcu/zP/aPkK4GTCn3ZZzzl3p3NurnNuAd5+fNo596fAL4B3+c0Gb2/vz+FdfvtA9WSdc4eAvWZ2ur/oMmAzObqPfXuAFWZW7P8b793mnN3Pg4x1364BrjSz6f5fN1f6y5KT6YMI4zjocA2wDXgF+Eym60nhdr0R78+xl4AX/a9r8MYPfw5sB54Cqvz2hnfGzyvAH/DOIsj4doxz2y8GfuhPLwR+C+wAvgcU+suL/Pkd/vqFma57nNu6DFjn7+cngOm5vo+BvwVeBjYC3wIKc3E/A4/gHSeI4v01dst49i3wAX/7dwDvH0sNuvRfRCRHBG3IRURERqBAFxHJEQp0EZEcoUAXEckRCnQRkRyhQBcRyREKdBGRHPG/scYqv3EppQ0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e73503e",
   "metadata": {},
   "source": [
    "###  when make a model with a batch size of Xtrain data is called batch gradient descent That means it will made one batch per epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ada574",
   "metadata": {},
   "source": [
    "#  Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "357a5a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.6283 - accuracy: 0.7305 - val_loss: 0.5554 - val_accuracy: 0.7656\n",
      "Epoch 2/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.5282 - accuracy: 0.7266 - val_loss: 0.4529 - val_accuracy: 0.7969\n",
      "Epoch 3/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.3721 - val_accuracy: 0.8750\n",
      "Epoch 4/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3717 - accuracy: 0.8594 - val_loss: 0.3237 - val_accuracy: 0.8594\n",
      "Epoch 5/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3302 - accuracy: 0.8750 - val_loss: 0.2972 - val_accuracy: 0.8750\n",
      "Epoch 6/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3018 - accuracy: 0.8789 - val_loss: 0.2810 - val_accuracy: 0.8750\n",
      "Epoch 7/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2864 - accuracy: 0.8789 - val_loss: 0.2768 - val_accuracy: 0.8750\n",
      "Epoch 8/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2784 - accuracy: 0.8789 - val_loss: 0.2759 - val_accuracy: 0.8750\n",
      "Epoch 9/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2680 - accuracy: 0.8906 - val_loss: 0.2830 - val_accuracy: 0.8750\n",
      "Epoch 10/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2678 - accuracy: 0.8867 - val_loss: 0.2825 - val_accuracy: 0.8750\n",
      "Epoch 11/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2657 - accuracy: 0.8945 - val_loss: 0.2805 - val_accuracy: 0.8750\n",
      "Epoch 12/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2629 - accuracy: 0.8906 - val_loss: 0.2865 - val_accuracy: 0.8750\n",
      "Epoch 13/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2613 - accuracy: 0.8945 - val_loss: 0.2903 - val_accuracy: 0.8750\n",
      "Epoch 14/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2562 - accuracy: 0.8984 - val_loss: 0.2952 - val_accuracy: 0.8906\n",
      "Epoch 15/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2570 - accuracy: 0.9062 - val_loss: 0.2919 - val_accuracy: 0.8750\n",
      "Epoch 16/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2582 - accuracy: 0.8945 - val_loss: 0.2977 - val_accuracy: 0.8906\n",
      "Epoch 17/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2522 - accuracy: 0.9102 - val_loss: 0.2984 - val_accuracy: 0.8906\n",
      "Epoch 18/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2559 - accuracy: 0.9023 - val_loss: 0.3012 - val_accuracy: 0.8906\n",
      "Epoch 19/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2507 - accuracy: 0.9062 - val_loss: 0.3016 - val_accuracy: 0.8906\n",
      "Epoch 20/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2515 - accuracy: 0.9023 - val_loss: 0.3055 - val_accuracy: 0.8906\n",
      "Epoch 21/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2527 - accuracy: 0.9023 - val_loss: 0.3113 - val_accuracy: 0.9062\n",
      "Epoch 22/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2560 - accuracy: 0.9102 - val_loss: 0.3167 - val_accuracy: 0.9062\n",
      "Epoch 23/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2514 - accuracy: 0.9141 - val_loss: 0.3190 - val_accuracy: 0.9062\n",
      "Epoch 24/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2508 - accuracy: 0.9062 - val_loss: 0.3268 - val_accuracy: 0.9062\n",
      "Epoch 25/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2506 - accuracy: 0.9102 - val_loss: 0.3296 - val_accuracy: 0.9062\n",
      "Epoch 26/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2507 - accuracy: 0.9102 - val_loss: 0.3264 - val_accuracy: 0.9062\n",
      "Epoch 27/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2530 - accuracy: 0.9102 - val_loss: 0.3317 - val_accuracy: 0.9062\n",
      "Epoch 28/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2512 - accuracy: 0.9102 - val_loss: 0.3367 - val_accuracy: 0.9062\n",
      "Epoch 29/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2528 - accuracy: 0.9141 - val_loss: 0.3339 - val_accuracy: 0.9062\n",
      "Epoch 30/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2502 - accuracy: 0.9141 - val_loss: 0.3375 - val_accuracy: 0.9062\n",
      "Epoch 31/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2521 - accuracy: 0.9180 - val_loss: 0.3408 - val_accuracy: 0.9062\n",
      "Epoch 32/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2579 - accuracy: 0.9141 - val_loss: 0.3465 - val_accuracy: 0.9062\n",
      "Epoch 33/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2569 - accuracy: 0.9141 - val_loss: 0.3479 - val_accuracy: 0.9062\n",
      "Epoch 34/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2488 - accuracy: 0.9180 - val_loss: 0.3513 - val_accuracy: 0.9062\n",
      "Epoch 35/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2499 - accuracy: 0.9180 - val_loss: 0.3460 - val_accuracy: 0.9062\n",
      "Epoch 36/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2512 - accuracy: 0.9141 - val_loss: 0.3536 - val_accuracy: 0.9062\n",
      "Epoch 37/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2571 - accuracy: 0.9141 - val_loss: 0.3568 - val_accuracy: 0.9062\n",
      "Epoch 38/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2514 - accuracy: 0.9180 - val_loss: 0.3497 - val_accuracy: 0.9062\n",
      "Epoch 39/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2573 - accuracy: 0.9141 - val_loss: 0.3484 - val_accuracy: 0.9062\n",
      "Epoch 40/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2530 - accuracy: 0.9141 - val_loss: 0.3481 - val_accuracy: 0.9062\n",
      "Epoch 41/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2559 - accuracy: 0.9219 - val_loss: 0.3516 - val_accuracy: 0.9062\n",
      "Epoch 42/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2518 - accuracy: 0.9180 - val_loss: 0.3578 - val_accuracy: 0.9062\n",
      "Epoch 43/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2547 - accuracy: 0.9219 - val_loss: 0.3600 - val_accuracy: 0.9062\n",
      "Epoch 44/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2544 - accuracy: 0.9141 - val_loss: 0.3555 - val_accuracy: 0.9062\n",
      "Epoch 45/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2503 - accuracy: 0.9219 - val_loss: 0.3599 - val_accuracy: 0.9062\n",
      "Epoch 46/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2528 - accuracy: 0.9180 - val_loss: 0.3553 - val_accuracy: 0.9062\n",
      "Epoch 47/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2503 - accuracy: 0.9180 - val_loss: 0.3603 - val_accuracy: 0.9062\n",
      "Epoch 48/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2483 - accuracy: 0.9180 - val_loss: 0.3557 - val_accuracy: 0.9062\n",
      "Epoch 49/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2512 - accuracy: 0.9219 - val_loss: 0.3567 - val_accuracy: 0.9062\n",
      "Epoch 50/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2517 - accuracy: 0.9219 - val_loss: 0.3567 - val_accuracy: 0.9062\n",
      "Epoch 51/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2503 - accuracy: 0.9219 - val_loss: 0.3548 - val_accuracy: 0.9062\n",
      "Epoch 52/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2542 - accuracy: 0.9219 - val_loss: 0.3561 - val_accuracy: 0.9062\n",
      "Epoch 53/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2502 - accuracy: 0.9180 - val_loss: 0.3635 - val_accuracy: 0.9062\n",
      "Epoch 54/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2508 - accuracy: 0.9219 - val_loss: 0.3637 - val_accuracy: 0.9062\n",
      "Epoch 55/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2480 - accuracy: 0.9219 - val_loss: 0.3643 - val_accuracy: 0.9062\n",
      "Epoch 56/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2475 - accuracy: 0.9219 - val_loss: 0.3736 - val_accuracy: 0.9062\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2525 - accuracy: 0.9180 - val_loss: 0.3723 - val_accuracy: 0.9062\n",
      "Epoch 58/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2489 - accuracy: 0.9219 - val_loss: 0.3716 - val_accuracy: 0.9062\n",
      "Epoch 59/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2504 - accuracy: 0.9180 - val_loss: 0.3713 - val_accuracy: 0.9062\n",
      "Epoch 60/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2505 - accuracy: 0.9258 - val_loss: 0.3728 - val_accuracy: 0.9062\n",
      "Epoch 61/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2479 - accuracy: 0.9258 - val_loss: 0.3779 - val_accuracy: 0.9062\n",
      "Epoch 62/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2521 - accuracy: 0.9180 - val_loss: 0.3812 - val_accuracy: 0.9062\n",
      "Epoch 63/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2521 - accuracy: 0.9180 - val_loss: 0.3821 - val_accuracy: 0.9062\n",
      "Epoch 64/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2479 - accuracy: 0.9180 - val_loss: 0.3775 - val_accuracy: 0.9062\n",
      "Epoch 65/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2511 - accuracy: 0.9141 - val_loss: 0.3831 - val_accuracy: 0.9062\n",
      "Epoch 66/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2520 - accuracy: 0.9258 - val_loss: 0.3829 - val_accuracy: 0.9062\n",
      "Epoch 67/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2488 - accuracy: 0.9297 - val_loss: 0.3813 - val_accuracy: 0.9062\n",
      "Epoch 68/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2528 - accuracy: 0.9297 - val_loss: 0.3837 - val_accuracy: 0.9062\n",
      "Epoch 69/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2537 - accuracy: 0.9258 - val_loss: 0.3897 - val_accuracy: 0.9062\n",
      "Epoch 70/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2520 - accuracy: 0.9258 - val_loss: 0.3863 - val_accuracy: 0.9062\n",
      "Epoch 71/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2517 - accuracy: 0.9219 - val_loss: 0.3936 - val_accuracy: 0.9062\n",
      "Epoch 72/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2517 - accuracy: 0.9297 - val_loss: 0.3932 - val_accuracy: 0.9062\n",
      "Epoch 73/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2537 - accuracy: 0.9297 - val_loss: 0.3968 - val_accuracy: 0.9062\n",
      "Epoch 74/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2550 - accuracy: 0.9297 - val_loss: 0.3937 - val_accuracy: 0.9062\n",
      "Epoch 75/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2467 - accuracy: 0.9219 - val_loss: 0.3915 - val_accuracy: 0.9062\n",
      "Epoch 76/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2453 - accuracy: 0.9258 - val_loss: 0.3902 - val_accuracy: 0.9062\n",
      "Epoch 77/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2483 - accuracy: 0.9141 - val_loss: 0.3868 - val_accuracy: 0.9062\n",
      "Epoch 78/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2499 - accuracy: 0.9258 - val_loss: 0.3848 - val_accuracy: 0.9062\n",
      "Epoch 79/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2490 - accuracy: 0.9297 - val_loss: 0.3978 - val_accuracy: 0.9062\n",
      "Epoch 80/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2511 - accuracy: 0.9219 - val_loss: 0.3994 - val_accuracy: 0.9062\n",
      "Epoch 81/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2555 - accuracy: 0.9258 - val_loss: 0.4011 - val_accuracy: 0.9062\n",
      "Epoch 82/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2538 - accuracy: 0.9180 - val_loss: 0.4000 - val_accuracy: 0.9062\n",
      "Epoch 83/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2540 - accuracy: 0.9219 - val_loss: 0.3995 - val_accuracy: 0.9062\n",
      "Epoch 84/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2495 - accuracy: 0.9258 - val_loss: 0.3917 - val_accuracy: 0.9062\n",
      "Epoch 85/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2479 - accuracy: 0.9219 - val_loss: 0.3944 - val_accuracy: 0.9062\n",
      "Epoch 86/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2495 - accuracy: 0.9219 - val_loss: 0.3923 - val_accuracy: 0.9062\n",
      "Epoch 87/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2523 - accuracy: 0.9258 - val_loss: 0.3962 - val_accuracy: 0.9062\n",
      "Epoch 88/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2524 - accuracy: 0.9219 - val_loss: 0.3930 - val_accuracy: 0.9062\n",
      "Epoch 89/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2622 - accuracy: 0.9258 - val_loss: 0.4104 - val_accuracy: 0.9062\n",
      "Epoch 90/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2561 - accuracy: 0.9258 - val_loss: 0.4021 - val_accuracy: 0.9062\n",
      "Epoch 91/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2581 - accuracy: 0.9219 - val_loss: 0.4060 - val_accuracy: 0.9062\n",
      "Epoch 92/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2544 - accuracy: 0.9219 - val_loss: 0.4005 - val_accuracy: 0.9062\n",
      "Epoch 93/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2527 - accuracy: 0.9219 - val_loss: 0.4039 - val_accuracy: 0.9062\n",
      "Epoch 94/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2515 - accuracy: 0.9258 - val_loss: 0.4021 - val_accuracy: 0.9062\n",
      "Epoch 95/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2522 - accuracy: 0.9219 - val_loss: 0.4012 - val_accuracy: 0.9062\n",
      "Epoch 96/1000\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2514 - accuracy: 0.9219 - val_loss: 0.3917 - val_accuracy: 0.9062\n",
      "Epoch 97/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2566 - accuracy: 0.9258 - val_loss: 0.3959 - val_accuracy: 0.9062\n",
      "Epoch 98/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2508 - accuracy: 0.9219 - val_loss: 0.4014 - val_accuracy: 0.9062\n",
      "Epoch 99/1000\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2550 - accuracy: 0.9258 - val_loss: 0.3964 - val_accuracy: 0.9062\n",
      "Epoch 100/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2541 - accuracy: 0.9219 - val_loss: 0.3975 - val_accuracy: 0.9062\n",
      "Epoch 101/1000\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2554 - accuracy: 0.9219 - val_loss: 0.3943 - val_accuracy: 0.9062\n",
      "Epoch 102/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2558 - accuracy: 0.9219 - val_loss: 0.3944 - val_accuracy: 0.9062\n",
      "Epoch 103/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2600 - accuracy: 0.9219 - val_loss: 0.3976 - val_accuracy: 0.9062\n",
      "Epoch 104/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2532 - accuracy: 0.9219 - val_loss: 0.3967 - val_accuracy: 0.9062\n",
      "Epoch 105/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2535 - accuracy: 0.9219 - val_loss: 0.3963 - val_accuracy: 0.9062\n",
      "Epoch 106/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2553 - accuracy: 0.9219 - val_loss: 0.3977 - val_accuracy: 0.9062\n",
      "Epoch 107/1000\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2551 - accuracy: 0.9219 - val_loss: 0.3942 - val_accuracy: 0.9062\n",
      "Epoch 108/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2572 - accuracy: 0.9219 - val_loss: 0.3956 - val_accuracy: 0.9062\n",
      "Epoch 109/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2521 - accuracy: 0.9219 - val_loss: 0.3901 - val_accuracy: 0.9062\n",
      "Epoch 110/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2494 - accuracy: 0.9258 - val_loss: 0.3884 - val_accuracy: 0.9062\n",
      "Epoch 111/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2528 - accuracy: 0.9219 - val_loss: 0.3864 - val_accuracy: 0.9062\n",
      "Epoch 112/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2541 - accuracy: 0.9258 - val_loss: 0.3902 - val_accuracy: 0.9062\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2537 - accuracy: 0.9219 - val_loss: 0.3915 - val_accuracy: 0.9062\n",
      "Epoch 114/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2484 - accuracy: 0.9219 - val_loss: 0.3958 - val_accuracy: 0.9062\n",
      "Epoch 115/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2495 - accuracy: 0.9219 - val_loss: 0.3889 - val_accuracy: 0.9062\n",
      "Epoch 116/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2506 - accuracy: 0.9219 - val_loss: 0.3918 - val_accuracy: 0.9062\n",
      "Epoch 117/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2540 - accuracy: 0.9219 - val_loss: 0.3924 - val_accuracy: 0.9062\n",
      "Epoch 118/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2528 - accuracy: 0.9219 - val_loss: 0.3923 - val_accuracy: 0.9062\n",
      "Epoch 119/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2528 - accuracy: 0.9219 - val_loss: 0.3932 - val_accuracy: 0.9062\n",
      "Epoch 120/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2567 - accuracy: 0.9219 - val_loss: 0.4007 - val_accuracy: 0.9062\n",
      "Epoch 121/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2546 - accuracy: 0.9258 - val_loss: 0.3936 - val_accuracy: 0.9062\n",
      "Epoch 122/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2490 - accuracy: 0.9219 - val_loss: 0.3919 - val_accuracy: 0.9062\n",
      "Epoch 123/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2488 - accuracy: 0.9141 - val_loss: 0.3885 - val_accuracy: 0.9062\n",
      "Epoch 124/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2468 - accuracy: 0.9258 - val_loss: 0.3953 - val_accuracy: 0.9062\n",
      "Epoch 125/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2530 - accuracy: 0.9258 - val_loss: 0.3938 - val_accuracy: 0.9062\n",
      "Epoch 126/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2484 - accuracy: 0.9219 - val_loss: 0.3904 - val_accuracy: 0.9062\n",
      "Epoch 127/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2488 - accuracy: 0.9219 - val_loss: 0.3817 - val_accuracy: 0.9062\n",
      "Epoch 128/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2441 - accuracy: 0.9180 - val_loss: 0.3923 - val_accuracy: 0.9062\n",
      "Epoch 129/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2447 - accuracy: 0.9258 - val_loss: 0.3934 - val_accuracy: 0.9062\n",
      "Epoch 130/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2537 - accuracy: 0.9219 - val_loss: 0.3983 - val_accuracy: 0.9062\n",
      "Epoch 131/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2523 - accuracy: 0.9258 - val_loss: 0.3950 - val_accuracy: 0.9062\n",
      "Epoch 132/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2580 - accuracy: 0.9258 - val_loss: 0.4013 - val_accuracy: 0.9062\n",
      "Epoch 133/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2495 - accuracy: 0.9258 - val_loss: 0.4023 - val_accuracy: 0.9062\n",
      "Epoch 134/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2610 - accuracy: 0.9258 - val_loss: 0.4050 - val_accuracy: 0.9062\n",
      "Epoch 135/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2560 - accuracy: 0.9297 - val_loss: 0.4003 - val_accuracy: 0.9062\n",
      "Epoch 136/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2498 - accuracy: 0.9297 - val_loss: 0.4076 - val_accuracy: 0.9062\n",
      "Epoch 137/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2605 - accuracy: 0.9219 - val_loss: 0.4077 - val_accuracy: 0.9062\n",
      "Epoch 138/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2541 - accuracy: 0.9258 - val_loss: 0.4001 - val_accuracy: 0.9062\n",
      "Epoch 139/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2543 - accuracy: 0.9258 - val_loss: 0.4033 - val_accuracy: 0.9062\n",
      "Epoch 140/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2565 - accuracy: 0.9258 - val_loss: 0.4049 - val_accuracy: 0.9062\n",
      "Epoch 141/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2503 - accuracy: 0.9258 - val_loss: 0.4013 - val_accuracy: 0.9062\n",
      "Epoch 142/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2546 - accuracy: 0.9258 - val_loss: 0.4043 - val_accuracy: 0.9062\n",
      "Epoch 143/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2489 - accuracy: 0.9219 - val_loss: 0.4023 - val_accuracy: 0.9062\n",
      "Epoch 144/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2499 - accuracy: 0.9219 - val_loss: 0.4089 - val_accuracy: 0.9062\n",
      "Epoch 145/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2508 - accuracy: 0.9258 - val_loss: 0.4070 - val_accuracy: 0.9062\n",
      "Epoch 146/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2552 - accuracy: 0.9219 - val_loss: 0.4001 - val_accuracy: 0.9062\n",
      "Epoch 147/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2507 - accuracy: 0.9258 - val_loss: 0.4037 - val_accuracy: 0.9062\n",
      "Epoch 148/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2542 - accuracy: 0.9258 - val_loss: 0.3971 - val_accuracy: 0.9062\n",
      "Epoch 149/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2504 - accuracy: 0.9258 - val_loss: 0.3981 - val_accuracy: 0.9062\n",
      "Epoch 150/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2505 - accuracy: 0.9258 - val_loss: 0.3983 - val_accuracy: 0.9062\n",
      "Epoch 151/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2545 - accuracy: 0.9258 - val_loss: 0.4070 - val_accuracy: 0.9062\n",
      "Epoch 152/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2604 - accuracy: 0.9297 - val_loss: 0.4111 - val_accuracy: 0.9062\n",
      "Epoch 153/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2507 - accuracy: 0.9258 - val_loss: 0.4001 - val_accuracy: 0.9062\n",
      "Epoch 154/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2493 - accuracy: 0.9258 - val_loss: 0.3985 - val_accuracy: 0.9062\n",
      "Epoch 155/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2485 - accuracy: 0.9258 - val_loss: 0.4076 - val_accuracy: 0.9062\n",
      "Epoch 156/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2580 - accuracy: 0.9219 - val_loss: 0.4095 - val_accuracy: 0.9062\n",
      "Epoch 157/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2543 - accuracy: 0.9219 - val_loss: 0.4010 - val_accuracy: 0.9062\n",
      "Epoch 158/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2547 - accuracy: 0.9219 - val_loss: 0.4058 - val_accuracy: 0.9062\n",
      "Epoch 159/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2518 - accuracy: 0.9258 - val_loss: 0.4041 - val_accuracy: 0.9062\n",
      "Epoch 160/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2535 - accuracy: 0.9258 - val_loss: 0.4030 - val_accuracy: 0.9062\n",
      "Epoch 161/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2519 - accuracy: 0.9258 - val_loss: 0.4051 - val_accuracy: 0.9062\n",
      "Epoch 162/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2477 - accuracy: 0.9297 - val_loss: 0.4117 - val_accuracy: 0.9062\n",
      "Epoch 163/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2512 - accuracy: 0.9258 - val_loss: 0.4216 - val_accuracy: 0.9062\n",
      "Epoch 164/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2563 - accuracy: 0.9258 - val_loss: 0.4166 - val_accuracy: 0.9062\n",
      "Epoch 165/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2494 - accuracy: 0.9258 - val_loss: 0.4319 - val_accuracy: 0.9062\n",
      "Epoch 166/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2571 - accuracy: 0.9258 - val_loss: 0.4209 - val_accuracy: 0.9062\n",
      "Epoch 167/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2596 - accuracy: 0.9258 - val_loss: 0.4234 - val_accuracy: 0.9062\n",
      "Epoch 168/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2603 - accuracy: 0.9258 - val_loss: 0.4242 - val_accuracy: 0.9062\n",
      "Epoch 169/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2606 - accuracy: 0.9258 - val_loss: 0.4172 - val_accuracy: 0.9062\n",
      "Epoch 170/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2567 - accuracy: 0.9258 - val_loss: 0.4203 - val_accuracy: 0.9062\n",
      "Epoch 171/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2540 - accuracy: 0.9219 - val_loss: 0.4221 - val_accuracy: 0.9062\n",
      "Epoch 172/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2614 - accuracy: 0.9258 - val_loss: 0.4238 - val_accuracy: 0.9062\n",
      "Epoch 173/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2548 - accuracy: 0.9258 - val_loss: 0.4279 - val_accuracy: 0.9062\n",
      "Epoch 174/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2555 - accuracy: 0.9258 - val_loss: 0.4287 - val_accuracy: 0.9062\n",
      "Epoch 175/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2564 - accuracy: 0.9219 - val_loss: 0.4376 - val_accuracy: 0.9062\n",
      "Epoch 176/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2599 - accuracy: 0.9258 - val_loss: 0.4323 - val_accuracy: 0.9062\n",
      "Epoch 177/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2589 - accuracy: 0.9258 - val_loss: 0.4330 - val_accuracy: 0.9062\n",
      "Epoch 178/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2509 - accuracy: 0.9258 - val_loss: 0.4231 - val_accuracy: 0.9062\n",
      "Epoch 179/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2605 - accuracy: 0.9258 - val_loss: 0.4259 - val_accuracy: 0.9062\n",
      "Epoch 180/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2531 - accuracy: 0.9297 - val_loss: 0.4273 - val_accuracy: 0.9062\n",
      "Epoch 181/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2626 - accuracy: 0.9219 - val_loss: 0.4215 - val_accuracy: 0.9062\n",
      "Epoch 182/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2557 - accuracy: 0.9297 - val_loss: 0.4242 - val_accuracy: 0.9062\n",
      "Epoch 183/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2484 - accuracy: 0.9219 - val_loss: 0.4198 - val_accuracy: 0.9062\n",
      "Epoch 184/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2522 - accuracy: 0.9258 - val_loss: 0.4210 - val_accuracy: 0.9062\n",
      "Epoch 185/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2539 - accuracy: 0.9297 - val_loss: 0.4285 - val_accuracy: 0.9062\n",
      "Epoch 186/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2517 - accuracy: 0.9258 - val_loss: 0.4193 - val_accuracy: 0.9062\n",
      "Epoch 187/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2467 - accuracy: 0.9297 - val_loss: 0.4250 - val_accuracy: 0.9062\n",
      "Epoch 188/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2518 - accuracy: 0.9219 - val_loss: 0.4219 - val_accuracy: 0.9062\n",
      "Epoch 189/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2509 - accuracy: 0.9258 - val_loss: 0.4252 - val_accuracy: 0.9062\n",
      "Epoch 190/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2489 - accuracy: 0.9258 - val_loss: 0.4252 - val_accuracy: 0.9062\n",
      "Epoch 191/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2478 - accuracy: 0.9258 - val_loss: 0.4277 - val_accuracy: 0.9062\n",
      "Epoch 192/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2540 - accuracy: 0.9258 - val_loss: 0.4177 - val_accuracy: 0.9062\n",
      "Epoch 193/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2476 - accuracy: 0.9258 - val_loss: 0.4202 - val_accuracy: 0.9062\n",
      "Epoch 194/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2505 - accuracy: 0.9258 - val_loss: 0.4233 - val_accuracy: 0.9062\n",
      "Epoch 195/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2511 - accuracy: 0.9258 - val_loss: 0.4242 - val_accuracy: 0.9062\n",
      "Epoch 196/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2525 - accuracy: 0.9297 - val_loss: 0.4160 - val_accuracy: 0.9062\n",
      "Epoch 197/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2440 - accuracy: 0.9219 - val_loss: 0.4259 - val_accuracy: 0.9062\n",
      "Epoch 198/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2450 - accuracy: 0.9297 - val_loss: 0.4257 - val_accuracy: 0.9062\n",
      "Epoch 199/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2485 - accuracy: 0.9297 - val_loss: 0.4169 - val_accuracy: 0.9062\n",
      "Epoch 200/1000\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2468 - accuracy: 0.9297 - val_loss: 0.4117 - val_accuracy: 0.9062\n",
      "Epoch 201/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2450 - accuracy: 0.9258 - val_loss: 0.4248 - val_accuracy: 0.9062\n",
      "Epoch 202/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2466 - accuracy: 0.9258 - val_loss: 0.4280 - val_accuracy: 0.9062\n",
      "Epoch 203/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2568 - accuracy: 0.9258 - val_loss: 0.4293 - val_accuracy: 0.9062\n",
      "Epoch 204/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2556 - accuracy: 0.9297 - val_loss: 0.4344 - val_accuracy: 0.9062\n",
      "Epoch 205/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2475 - accuracy: 0.9258 - val_loss: 0.4277 - val_accuracy: 0.9062\n",
      "Epoch 206/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2530 - accuracy: 0.9297 - val_loss: 0.4253 - val_accuracy: 0.9062\n",
      "Epoch 207/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2567 - accuracy: 0.9258 - val_loss: 0.4262 - val_accuracy: 0.9062\n",
      "Epoch 208/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2509 - accuracy: 0.9297 - val_loss: 0.4311 - val_accuracy: 0.9062\n",
      "Epoch 209/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2471 - accuracy: 0.9258 - val_loss: 0.4310 - val_accuracy: 0.9062\n",
      "Epoch 210/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2506 - accuracy: 0.9258 - val_loss: 0.4290 - val_accuracy: 0.9062\n",
      "Epoch 211/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2534 - accuracy: 0.9258 - val_loss: 0.4301 - val_accuracy: 0.9062\n",
      "Epoch 212/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2516 - accuracy: 0.9258 - val_loss: 0.4327 - val_accuracy: 0.9062\n",
      "Epoch 213/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2542 - accuracy: 0.9258 - val_loss: 0.4423 - val_accuracy: 0.9062\n",
      "Epoch 214/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2506 - accuracy: 0.9258 - val_loss: 0.4357 - val_accuracy: 0.9062\n",
      "Epoch 215/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2459 - accuracy: 0.9258 - val_loss: 0.4285 - val_accuracy: 0.9062\n",
      "Epoch 216/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2478 - accuracy: 0.9258 - val_loss: 0.4309 - val_accuracy: 0.9062\n",
      "Epoch 217/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2573 - accuracy: 0.9258 - val_loss: 0.4365 - val_accuracy: 0.9062\n",
      "Epoch 218/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2479 - accuracy: 0.9297 - val_loss: 0.4299 - val_accuracy: 0.9062\n",
      "Epoch 219/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2492 - accuracy: 0.9258 - val_loss: 0.4271 - val_accuracy: 0.9062\n",
      "Epoch 220/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2512 - accuracy: 0.9258 - val_loss: 0.4241 - val_accuracy: 0.9062\n",
      "Epoch 221/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2473 - accuracy: 0.9297 - val_loss: 0.4236 - val_accuracy: 0.9062\n",
      "Epoch 222/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2505 - accuracy: 0.9258 - val_loss: 0.4303 - val_accuracy: 0.9062\n",
      "Epoch 223/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2481 - accuracy: 0.9258 - val_loss: 0.4343 - val_accuracy: 0.9062\n",
      "Epoch 224/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2531 - accuracy: 0.9297 - val_loss: 0.4369 - val_accuracy: 0.9062\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2557 - accuracy: 0.9258 - val_loss: 0.4276 - val_accuracy: 0.9062\n",
      "Epoch 226/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2527 - accuracy: 0.9297 - val_loss: 0.4294 - val_accuracy: 0.9062\n",
      "Epoch 227/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2506 - accuracy: 0.9258 - val_loss: 0.4304 - val_accuracy: 0.9062\n",
      "Epoch 228/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2535 - accuracy: 0.9297 - val_loss: 0.4363 - val_accuracy: 0.9062\n",
      "Epoch 229/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2511 - accuracy: 0.9258 - val_loss: 0.4279 - val_accuracy: 0.9062\n",
      "Epoch 230/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2483 - accuracy: 0.9219 - val_loss: 0.4298 - val_accuracy: 0.9062\n",
      "Epoch 231/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2499 - accuracy: 0.9219 - val_loss: 0.4279 - val_accuracy: 0.9062\n",
      "Epoch 232/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2467 - accuracy: 0.9297 - val_loss: 0.4324 - val_accuracy: 0.9062\n",
      "Epoch 233/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2573 - accuracy: 0.9258 - val_loss: 0.4342 - val_accuracy: 0.9062\n",
      "Epoch 234/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2481 - accuracy: 0.9258 - val_loss: 0.4303 - val_accuracy: 0.9062\n",
      "Epoch 235/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2594 - accuracy: 0.9258 - val_loss: 0.4261 - val_accuracy: 0.9062\n",
      "Epoch 236/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2524 - accuracy: 0.9297 - val_loss: 0.4323 - val_accuracy: 0.9062\n",
      "Epoch 237/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2557 - accuracy: 0.9297 - val_loss: 0.4289 - val_accuracy: 0.9062\n",
      "Epoch 238/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2523 - accuracy: 0.9297 - val_loss: 0.4328 - val_accuracy: 0.9062\n",
      "Epoch 239/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2484 - accuracy: 0.9297 - val_loss: 0.4300 - val_accuracy: 0.9062\n",
      "Epoch 240/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2479 - accuracy: 0.9219 - val_loss: 0.4359 - val_accuracy: 0.9062\n",
      "Epoch 241/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2410 - accuracy: 0.9258 - val_loss: 0.4423 - val_accuracy: 0.8906\n",
      "Epoch 242/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2536 - accuracy: 0.9219 - val_loss: 0.4379 - val_accuracy: 0.8906\n",
      "Epoch 243/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2499 - accuracy: 0.9219 - val_loss: 0.4362 - val_accuracy: 0.9062\n",
      "Epoch 244/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2527 - accuracy: 0.9180 - val_loss: 0.4418 - val_accuracy: 0.9062\n",
      "Epoch 245/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2605 - accuracy: 0.9258 - val_loss: 0.4396 - val_accuracy: 0.9062\n",
      "Epoch 246/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2537 - accuracy: 0.9258 - val_loss: 0.4472 - val_accuracy: 0.9062\n",
      "Epoch 247/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2547 - accuracy: 0.9258 - val_loss: 0.4499 - val_accuracy: 0.9062\n",
      "Epoch 248/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2621 - accuracy: 0.9258 - val_loss: 0.4442 - val_accuracy: 0.8906\n",
      "Epoch 249/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2529 - accuracy: 0.9219 - val_loss: 0.4445 - val_accuracy: 0.9062\n",
      "Epoch 250/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2554 - accuracy: 0.9219 - val_loss: 0.4382 - val_accuracy: 0.8906\n",
      "Epoch 251/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2526 - accuracy: 0.9219 - val_loss: 0.4359 - val_accuracy: 0.8906\n",
      "Epoch 252/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2462 - accuracy: 0.9258 - val_loss: 0.4301 - val_accuracy: 0.8906\n",
      "Epoch 253/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2467 - accuracy: 0.9219 - val_loss: 0.4407 - val_accuracy: 0.8906\n",
      "Epoch 254/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2469 - accuracy: 0.9219 - val_loss: 0.4532 - val_accuracy: 0.9062\n",
      "Epoch 255/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2554 - accuracy: 0.9258 - val_loss: 0.4506 - val_accuracy: 0.8906\n",
      "Epoch 256/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2583 - accuracy: 0.9258 - val_loss: 0.4535 - val_accuracy: 0.9062\n",
      "Epoch 257/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2569 - accuracy: 0.9219 - val_loss: 0.4443 - val_accuracy: 0.9062\n",
      "Epoch 258/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2525 - accuracy: 0.9219 - val_loss: 0.4359 - val_accuracy: 0.9062\n",
      "Epoch 259/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2468 - accuracy: 0.9258 - val_loss: 0.4335 - val_accuracy: 0.8906\n",
      "Epoch 260/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2513 - accuracy: 0.9258 - val_loss: 0.4338 - val_accuracy: 0.8906\n",
      "Epoch 261/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2464 - accuracy: 0.9258 - val_loss: 0.4446 - val_accuracy: 0.9062\n",
      "Epoch 262/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2520 - accuracy: 0.9219 - val_loss: 0.4464 - val_accuracy: 0.9062\n",
      "Epoch 263/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2448 - accuracy: 0.9219 - val_loss: 0.4514 - val_accuracy: 0.9062\n",
      "Epoch 264/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2528 - accuracy: 0.9258 - val_loss: 0.4508 - val_accuracy: 0.8906\n",
      "Epoch 265/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2593 - accuracy: 0.9219 - val_loss: 0.4527 - val_accuracy: 0.9062\n",
      "Epoch 266/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2467 - accuracy: 0.9180 - val_loss: 0.4436 - val_accuracy: 0.8906\n",
      "Epoch 267/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2499 - accuracy: 0.9258 - val_loss: 0.4514 - val_accuracy: 0.9062\n",
      "Epoch 268/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2444 - accuracy: 0.9297 - val_loss: 0.4605 - val_accuracy: 0.8906\n",
      "Epoch 269/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2628 - accuracy: 0.9258 - val_loss: 0.4484 - val_accuracy: 0.8906\n",
      "Epoch 270/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2540 - accuracy: 0.9219 - val_loss: 0.4409 - val_accuracy: 0.8906\n",
      "Epoch 271/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2543 - accuracy: 0.9219 - val_loss: 0.4448 - val_accuracy: 0.9062\n",
      "Epoch 272/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2441 - accuracy: 0.9219 - val_loss: 0.4661 - val_accuracy: 0.8750\n",
      "Epoch 273/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2603 - accuracy: 0.9258 - val_loss: 0.4540 - val_accuracy: 0.8906\n",
      "Epoch 274/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2521 - accuracy: 0.9219 - val_loss: 0.4867 - val_accuracy: 0.9062\n",
      "Epoch 275/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2653 - accuracy: 0.9219 - val_loss: 0.4672 - val_accuracy: 0.9062\n",
      "Epoch 276/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2578 - accuracy: 0.9258 - val_loss: 0.4772 - val_accuracy: 0.9062\n",
      "Epoch 277/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2593 - accuracy: 0.9258 - val_loss: 0.4746 - val_accuracy: 0.9062\n",
      "Epoch 278/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2578 - accuracy: 0.9258 - val_loss: 0.4658 - val_accuracy: 0.9062\n",
      "Epoch 279/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2579 - accuracy: 0.9258 - val_loss: 0.4570 - val_accuracy: 0.9062\n",
      "Epoch 280/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2547 - accuracy: 0.9258 - val_loss: 0.4622 - val_accuracy: 0.8906\n",
      "Epoch 281/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2521 - accuracy: 0.9258 - val_loss: 0.4672 - val_accuracy: 0.9062\n",
      "Epoch 282/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2620 - accuracy: 0.9258 - val_loss: 0.4714 - val_accuracy: 0.9062\n",
      "Epoch 283/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2507 - accuracy: 0.9297 - val_loss: 0.4667 - val_accuracy: 0.9062\n",
      "Epoch 284/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2506 - accuracy: 0.9258 - val_loss: 0.4586 - val_accuracy: 0.8906\n",
      "Epoch 285/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2548 - accuracy: 0.9219 - val_loss: 0.4638 - val_accuracy: 0.8906\n",
      "Epoch 286/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2609 - accuracy: 0.9219 - val_loss: 0.4551 - val_accuracy: 0.8906\n",
      "Epoch 287/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2531 - accuracy: 0.9219 - val_loss: 0.4565 - val_accuracy: 0.8906\n",
      "Epoch 288/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2517 - accuracy: 0.9258 - val_loss: 0.4665 - val_accuracy: 0.9062\n",
      "Epoch 289/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2429 - accuracy: 0.9297 - val_loss: 0.4724 - val_accuracy: 0.8906\n",
      "Epoch 290/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2637 - accuracy: 0.9219 - val_loss: 0.4780 - val_accuracy: 0.8906\n",
      "Epoch 291/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2519 - accuracy: 0.9219 - val_loss: 0.4764 - val_accuracy: 0.8906\n",
      "Epoch 292/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2538 - accuracy: 0.9219 - val_loss: 0.4707 - val_accuracy: 0.8906\n",
      "Epoch 293/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2500 - accuracy: 0.9258 - val_loss: 0.4732 - val_accuracy: 0.8906\n",
      "Epoch 294/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2509 - accuracy: 0.9219 - val_loss: 0.4797 - val_accuracy: 0.9062\n",
      "Epoch 295/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2529 - accuracy: 0.9219 - val_loss: 0.4852 - val_accuracy: 0.8906\n",
      "Epoch 296/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2510 - accuracy: 0.9258 - val_loss: 0.4800 - val_accuracy: 0.8906\n",
      "Epoch 297/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2562 - accuracy: 0.9219 - val_loss: 0.4789 - val_accuracy: 0.8906\n",
      "Epoch 298/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2490 - accuracy: 0.9219 - val_loss: 0.4809 - val_accuracy: 0.9062\n",
      "Epoch 299/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2495 - accuracy: 0.9258 - val_loss: 0.4707 - val_accuracy: 0.8906\n",
      "Epoch 300/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2518 - accuracy: 0.9219 - val_loss: 0.4799 - val_accuracy: 0.8906\n",
      "Epoch 301/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2595 - accuracy: 0.9219 - val_loss: 0.4788 - val_accuracy: 0.8906\n",
      "Epoch 302/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2525 - accuracy: 0.9219 - val_loss: 0.4840 - val_accuracy: 0.8906\n",
      "Epoch 303/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2533 - accuracy: 0.9258 - val_loss: 0.4921 - val_accuracy: 0.8906\n",
      "Epoch 304/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2654 - accuracy: 0.9258 - val_loss: 0.4895 - val_accuracy: 0.8906\n",
      "Epoch 305/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2637 - accuracy: 0.9297 - val_loss: 0.4858 - val_accuracy: 0.8906\n",
      "Epoch 306/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2575 - accuracy: 0.9258 - val_loss: 0.4800 - val_accuracy: 0.8906\n",
      "Epoch 307/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2621 - accuracy: 0.9180 - val_loss: 0.4912 - val_accuracy: 0.8906\n",
      "Epoch 308/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2584 - accuracy: 0.9219 - val_loss: 0.4863 - val_accuracy: 0.8906\n",
      "Epoch 309/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2565 - accuracy: 0.9219 - val_loss: 0.4918 - val_accuracy: 0.8906\n",
      "Epoch 310/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2634 - accuracy: 0.9258 - val_loss: 0.4996 - val_accuracy: 0.8906\n",
      "Epoch 311/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2671 - accuracy: 0.9258 - val_loss: 0.5048 - val_accuracy: 0.9062\n",
      "Epoch 312/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2636 - accuracy: 0.9219 - val_loss: 0.4984 - val_accuracy: 0.9062\n",
      "Epoch 313/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2517 - accuracy: 0.9258 - val_loss: 0.4855 - val_accuracy: 0.8906\n",
      "Epoch 314/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2494 - accuracy: 0.9258 - val_loss: 0.5007 - val_accuracy: 0.8750\n",
      "Epoch 315/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2559 - accuracy: 0.9180 - val_loss: 0.5018 - val_accuracy: 0.8906\n",
      "Epoch 316/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2505 - accuracy: 0.9258 - val_loss: 0.4859 - val_accuracy: 0.8906\n",
      "Epoch 317/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2604 - accuracy: 0.9258 - val_loss: 0.4915 - val_accuracy: 0.8906\n",
      "Epoch 318/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2558 - accuracy: 0.9258 - val_loss: 0.4958 - val_accuracy: 0.8906\n",
      "Epoch 319/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2450 - accuracy: 0.9297 - val_loss: 0.4893 - val_accuracy: 0.8750\n",
      "Epoch 320/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2524 - accuracy: 0.9258 - val_loss: 0.4974 - val_accuracy: 0.8906\n",
      "Epoch 321/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2526 - accuracy: 0.9336 - val_loss: 0.5071 - val_accuracy: 0.8750\n",
      "Epoch 322/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2419 - accuracy: 0.9336 - val_loss: 0.4975 - val_accuracy: 0.8906\n",
      "Epoch 323/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2702 - accuracy: 0.9297 - val_loss: 0.5019 - val_accuracy: 0.8906\n",
      "Epoch 324/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2655 - accuracy: 0.9258 - val_loss: 0.5151 - val_accuracy: 0.8750\n",
      "Epoch 325/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2546 - accuracy: 0.9258 - val_loss: 0.5280 - val_accuracy: 0.8906\n",
      "Epoch 326/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2633 - accuracy: 0.9219 - val_loss: 0.5187 - val_accuracy: 0.8750\n",
      "Epoch 327/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2611 - accuracy: 0.9297 - val_loss: 0.5170 - val_accuracy: 0.8750\n",
      "Epoch 328/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2676 - accuracy: 0.9219 - val_loss: 0.5175 - val_accuracy: 0.8750\n",
      "Epoch 329/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2468 - accuracy: 0.9180 - val_loss: 0.5115 - val_accuracy: 0.8750\n",
      "Epoch 330/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2652 - accuracy: 0.9219 - val_loss: 0.5280 - val_accuracy: 0.8750\n",
      "Epoch 331/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2600 - accuracy: 0.9180 - val_loss: 0.5218 - val_accuracy: 0.8750\n",
      "Epoch 332/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2649 - accuracy: 0.9297 - val_loss: 0.5349 - val_accuracy: 0.8750\n",
      "Epoch 333/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2636 - accuracy: 0.9141 - val_loss: 0.5154 - val_accuracy: 0.8750\n",
      "Epoch 334/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2529 - accuracy: 0.9219 - val_loss: 0.5193 - val_accuracy: 0.8750\n",
      "Epoch 335/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2731 - accuracy: 0.9258 - val_loss: 0.5294 - val_accuracy: 0.8750\n",
      "Epoch 336/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2643 - accuracy: 0.9258 - val_loss: 0.5379 - val_accuracy: 0.8750\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2695 - accuracy: 0.9258 - val_loss: 0.5256 - val_accuracy: 0.8750\n",
      "Epoch 338/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2578 - accuracy: 0.9297 - val_loss: 0.5499 - val_accuracy: 0.8750\n",
      "Epoch 339/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2633 - accuracy: 0.9297 - val_loss: 0.5449 - val_accuracy: 0.8750\n",
      "Epoch 340/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2639 - accuracy: 0.9297 - val_loss: 0.5415 - val_accuracy: 0.8750\n",
      "Epoch 341/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2758 - accuracy: 0.9297 - val_loss: 0.5307 - val_accuracy: 0.8750\n",
      "Epoch 342/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2648 - accuracy: 0.9258 - val_loss: 0.5292 - val_accuracy: 0.8750\n",
      "Epoch 343/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2577 - accuracy: 0.9297 - val_loss: 0.5534 - val_accuracy: 0.8750\n",
      "Epoch 344/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2617 - accuracy: 0.9258 - val_loss: 0.5314 - val_accuracy: 0.8750\n",
      "Epoch 345/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2766 - accuracy: 0.9219 - val_loss: 0.5328 - val_accuracy: 0.8750\n",
      "Epoch 346/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2635 - accuracy: 0.9219 - val_loss: 0.5270 - val_accuracy: 0.8594\n",
      "Epoch 347/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2583 - accuracy: 0.9219 - val_loss: 0.5268 - val_accuracy: 0.8594\n",
      "Epoch 348/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2562 - accuracy: 0.9219 - val_loss: 0.5040 - val_accuracy: 0.8594\n",
      "Epoch 349/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2523 - accuracy: 0.9336 - val_loss: 0.5165 - val_accuracy: 0.8594\n",
      "Epoch 350/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2615 - accuracy: 0.9219 - val_loss: 0.5257 - val_accuracy: 0.8594\n",
      "Epoch 351/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2636 - accuracy: 0.9258 - val_loss: 0.5400 - val_accuracy: 0.8750\n",
      "Epoch 352/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2566 - accuracy: 0.9219 - val_loss: 0.5451 - val_accuracy: 0.8594\n",
      "Epoch 353/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2618 - accuracy: 0.9258 - val_loss: 0.5320 - val_accuracy: 0.8750\n",
      "Epoch 354/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2663 - accuracy: 0.9258 - val_loss: 0.5407 - val_accuracy: 0.8594\n",
      "Epoch 355/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2532 - accuracy: 0.9219 - val_loss: 0.5368 - val_accuracy: 0.8594\n",
      "Epoch 356/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2626 - accuracy: 0.9297 - val_loss: 0.5461 - val_accuracy: 0.8594\n",
      "Epoch 357/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2656 - accuracy: 0.9258 - val_loss: 0.5561 - val_accuracy: 0.8594\n",
      "Epoch 358/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2567 - accuracy: 0.9219 - val_loss: 0.5449 - val_accuracy: 0.8594\n",
      "Epoch 359/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2625 - accuracy: 0.9219 - val_loss: 0.5413 - val_accuracy: 0.8594\n",
      "Epoch 360/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2528 - accuracy: 0.9258 - val_loss: 0.5653 - val_accuracy: 0.8750\n",
      "Epoch 361/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2618 - accuracy: 0.9258 - val_loss: 0.5644 - val_accuracy: 0.8594\n",
      "Epoch 362/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2763 - accuracy: 0.9219 - val_loss: 0.5632 - val_accuracy: 0.8594\n",
      "Epoch 363/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2688 - accuracy: 0.9258 - val_loss: 0.5571 - val_accuracy: 0.8594\n",
      "Epoch 364/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2643 - accuracy: 0.9258 - val_loss: 0.5521 - val_accuracy: 0.8594\n",
      "Epoch 365/1000\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2682 - accuracy: 0.9219 - val_loss: 0.5431 - val_accuracy: 0.8594\n",
      "Epoch 366/1000\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2683 - accuracy: 0.9258 - val_loss: 0.5410 - val_accuracy: 0.8594\n",
      "Epoch 367/1000\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2640 - accuracy: 0.9219 - val_loss: 0.5640 - val_accuracy: 0.8750\n",
      "Epoch 368/1000\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2732 - accuracy: 0.9180 - val_loss: 0.5556 - val_accuracy: 0.8594\n",
      "Epoch 369/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2710 - accuracy: 0.9258 - val_loss: 0.5558 - val_accuracy: 0.8594\n",
      "Epoch 370/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2660 - accuracy: 0.9258 - val_loss: 0.5589 - val_accuracy: 0.8594\n",
      "Epoch 371/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2687 - accuracy: 0.9180 - val_loss: 0.5582 - val_accuracy: 0.8594\n",
      "Epoch 372/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2759 - accuracy: 0.9258 - val_loss: 0.5688 - val_accuracy: 0.8594\n",
      "Epoch 373/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2785 - accuracy: 0.9258 - val_loss: 0.5632 - val_accuracy: 0.8594\n",
      "Epoch 374/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2761 - accuracy: 0.9258 - val_loss: 0.5634 - val_accuracy: 0.8594\n",
      "Epoch 375/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2651 - accuracy: 0.9258 - val_loss: 0.5757 - val_accuracy: 0.8594\n",
      "Epoch 376/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2722 - accuracy: 0.9219 - val_loss: 0.5609 - val_accuracy: 0.8594\n",
      "Epoch 377/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2699 - accuracy: 0.9258 - val_loss: 0.5595 - val_accuracy: 0.8594\n",
      "Epoch 378/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2589 - accuracy: 0.9258 - val_loss: 0.5716 - val_accuracy: 0.8594\n",
      "Epoch 379/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2733 - accuracy: 0.9219 - val_loss: 0.5892 - val_accuracy: 0.8594\n",
      "Epoch 380/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2693 - accuracy: 0.9258 - val_loss: 0.5658 - val_accuracy: 0.8594\n",
      "Epoch 381/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2872 - accuracy: 0.9258 - val_loss: 0.5674 - val_accuracy: 0.8594\n",
      "Epoch 382/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2751 - accuracy: 0.9258 - val_loss: 0.5692 - val_accuracy: 0.8594\n",
      "Epoch 383/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2793 - accuracy: 0.9258 - val_loss: 0.5578 - val_accuracy: 0.8594\n",
      "Epoch 384/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2736 - accuracy: 0.9297 - val_loss: 0.5544 - val_accuracy: 0.8750\n",
      "Epoch 385/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2731 - accuracy: 0.9258 - val_loss: 0.5525 - val_accuracy: 0.8750\n",
      "Epoch 386/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2784 - accuracy: 0.9219 - val_loss: 0.5510 - val_accuracy: 0.8594\n",
      "Epoch 387/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2632 - accuracy: 0.9258 - val_loss: 0.5480 - val_accuracy: 0.8594\n",
      "Epoch 388/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2666 - accuracy: 0.9297 - val_loss: 0.5524 - val_accuracy: 0.8594\n",
      "Epoch 389/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2652 - accuracy: 0.9219 - val_loss: 0.5619 - val_accuracy: 0.8594\n",
      "Epoch 390/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2830 - accuracy: 0.9219 - val_loss: 0.5561 - val_accuracy: 0.8594\n",
      "Epoch 391/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2761 - accuracy: 0.9297 - val_loss: 0.5586 - val_accuracy: 0.8594\n",
      "Epoch 392/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2779 - accuracy: 0.9219 - val_loss: 0.5683 - val_accuracy: 0.8594\n",
      "Epoch 393/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2837 - accuracy: 0.9219 - val_loss: 0.5856 - val_accuracy: 0.8594\n",
      "Epoch 394/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2784 - accuracy: 0.9219 - val_loss: 0.5718 - val_accuracy: 0.8594\n",
      "Epoch 395/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2767 - accuracy: 0.9258 - val_loss: 0.5639 - val_accuracy: 0.8594\n",
      "Epoch 396/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2742 - accuracy: 0.9219 - val_loss: 0.5598 - val_accuracy: 0.8594\n",
      "Epoch 397/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2828 - accuracy: 0.9297 - val_loss: 0.5702 - val_accuracy: 0.8594\n",
      "Epoch 398/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2685 - accuracy: 0.9219 - val_loss: 0.5503 - val_accuracy: 0.8594\n",
      "Epoch 399/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2804 - accuracy: 0.9219 - val_loss: 0.5515 - val_accuracy: 0.8594\n",
      "Epoch 400/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2796 - accuracy: 0.9219 - val_loss: 0.5501 - val_accuracy: 0.8594\n",
      "Epoch 401/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2783 - accuracy: 0.9297 - val_loss: 0.5709 - val_accuracy: 0.8594\n",
      "Epoch 402/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2777 - accuracy: 0.9258 - val_loss: 0.5535 - val_accuracy: 0.8594\n",
      "Epoch 403/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2702 - accuracy: 0.9297 - val_loss: 0.5690 - val_accuracy: 0.8594\n",
      "Epoch 404/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2703 - accuracy: 0.9180 - val_loss: 0.5521 - val_accuracy: 0.8594\n",
      "Epoch 405/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2851 - accuracy: 0.9258 - val_loss: 0.5599 - val_accuracy: 0.8594\n",
      "Epoch 406/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2750 - accuracy: 0.9258 - val_loss: 0.5552 - val_accuracy: 0.8594\n",
      "Epoch 407/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2632 - accuracy: 0.9258 - val_loss: 0.5419 - val_accuracy: 0.8594\n",
      "Epoch 408/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2556 - accuracy: 0.9297 - val_loss: 0.5298 - val_accuracy: 0.8594\n",
      "Epoch 409/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2666 - accuracy: 0.9219 - val_loss: 0.5102 - val_accuracy: 0.8750\n",
      "Epoch 410/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2590 - accuracy: 0.9258 - val_loss: 0.5374 - val_accuracy: 0.8750\n",
      "Epoch 411/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2678 - accuracy: 0.9258 - val_loss: 0.5286 - val_accuracy: 0.8594\n",
      "Epoch 412/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2834 - accuracy: 0.9258 - val_loss: 0.5160 - val_accuracy: 0.8594\n",
      "Epoch 413/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2845 - accuracy: 0.9258 - val_loss: 0.5118 - val_accuracy: 0.8594\n",
      "Epoch 414/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2676 - accuracy: 0.9297 - val_loss: 0.5058 - val_accuracy: 0.8594\n",
      "Epoch 415/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2711 - accuracy: 0.9258 - val_loss: 0.4741 - val_accuracy: 0.8750\n",
      "Epoch 416/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2521 - accuracy: 0.9297 - val_loss: 0.4839 - val_accuracy: 0.8750\n",
      "Epoch 417/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2666 - accuracy: 0.9336 - val_loss: 0.5168 - val_accuracy: 0.8750\n",
      "Epoch 418/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2620 - accuracy: 0.9297 - val_loss: 0.5067 - val_accuracy: 0.8750\n",
      "Epoch 419/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2627 - accuracy: 0.9180 - val_loss: 0.4850 - val_accuracy: 0.8750\n",
      "Epoch 420/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2723 - accuracy: 0.9258 - val_loss: 0.5234 - val_accuracy: 0.8594\n",
      "Epoch 421/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2704 - accuracy: 0.9258 - val_loss: 0.5356 - val_accuracy: 0.8594\n",
      "Epoch 422/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2737 - accuracy: 0.9297 - val_loss: 0.4845 - val_accuracy: 0.8750\n",
      "Epoch 423/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2550 - accuracy: 0.9258 - val_loss: 0.5150 - val_accuracy: 0.8750\n",
      "Epoch 424/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2841 - accuracy: 0.9219 - val_loss: 0.5307 - val_accuracy: 0.8594\n",
      "Epoch 425/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2633 - accuracy: 0.9297 - val_loss: 0.4801 - val_accuracy: 0.8750\n",
      "Epoch 426/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2655 - accuracy: 0.9336 - val_loss: 0.5001 - val_accuracy: 0.8750\n",
      "Epoch 427/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2544 - accuracy: 0.9219 - val_loss: 0.4928 - val_accuracy: 0.8750\n",
      "Epoch 428/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2649 - accuracy: 0.9297 - val_loss: 0.5262 - val_accuracy: 0.8750\n",
      "Epoch 429/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2932 - accuracy: 0.9258 - val_loss: 0.5348 - val_accuracy: 0.8750\n",
      "Epoch 430/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2789 - accuracy: 0.9219 - val_loss: 0.5321 - val_accuracy: 0.8750\n",
      "Epoch 431/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2640 - accuracy: 0.9219 - val_loss: 0.4990 - val_accuracy: 0.8750\n",
      "Epoch 432/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2665 - accuracy: 0.9336 - val_loss: 0.5288 - val_accuracy: 0.8750\n",
      "Epoch 433/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2500 - accuracy: 0.9219 - val_loss: 0.5279 - val_accuracy: 0.8750\n",
      "Epoch 434/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2520 - accuracy: 0.9141 - val_loss: 0.5008 - val_accuracy: 0.8750\n",
      "Epoch 435/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2660 - accuracy: 0.9297 - val_loss: 0.5432 - val_accuracy: 0.8750\n",
      "Epoch 436/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2765 - accuracy: 0.9219 - val_loss: 0.5182 - val_accuracy: 0.8750\n",
      "Epoch 437/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2532 - accuracy: 0.9258 - val_loss: 0.5172 - val_accuracy: 0.8750\n",
      "Epoch 438/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2670 - accuracy: 0.9219 - val_loss: 0.4904 - val_accuracy: 0.8750\n",
      "Epoch 439/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2477 - accuracy: 0.9219 - val_loss: 0.5110 - val_accuracy: 0.8750\n",
      "Epoch 440/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2648 - accuracy: 0.9297 - val_loss: 0.5357 - val_accuracy: 0.8750\n",
      "Epoch 441/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2739 - accuracy: 0.9219 - val_loss: 0.5053 - val_accuracy: 0.8750\n",
      "Epoch 442/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2771 - accuracy: 0.9258 - val_loss: 0.4972 - val_accuracy: 0.8750\n",
      "Epoch 443/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2635 - accuracy: 0.9258 - val_loss: 0.5314 - val_accuracy: 0.8750\n",
      "Epoch 444/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2606 - accuracy: 0.9258 - val_loss: 0.5247 - val_accuracy: 0.8750\n",
      "Epoch 445/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2615 - accuracy: 0.9219 - val_loss: 0.5697 - val_accuracy: 0.8594\n",
      "Epoch 446/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2837 - accuracy: 0.9258 - val_loss: 0.5368 - val_accuracy: 0.8750\n",
      "Epoch 447/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2411 - accuracy: 0.9219 - val_loss: 0.4738 - val_accuracy: 0.8750\n",
      "Epoch 448/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2565 - accuracy: 0.9297 - val_loss: 0.5096 - val_accuracy: 0.8750\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2469 - accuracy: 0.9297 - val_loss: 0.4987 - val_accuracy: 0.8750\n",
      "Epoch 450/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2475 - accuracy: 0.9297 - val_loss: 0.5296 - val_accuracy: 0.8750\n",
      "Epoch 451/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2418 - accuracy: 0.9297 - val_loss: 0.5375 - val_accuracy: 0.8906\n",
      "Epoch 452/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2555 - accuracy: 0.9297 - val_loss: 0.5115 - val_accuracy: 0.8750\n",
      "Epoch 453/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2587 - accuracy: 0.9297 - val_loss: 0.5280 - val_accuracy: 0.8750\n",
      "Epoch 454/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2539 - accuracy: 0.9297 - val_loss: 0.5443 - val_accuracy: 0.8750\n",
      "Epoch 455/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2573 - accuracy: 0.9297 - val_loss: 0.5449 - val_accuracy: 0.8750\n",
      "Epoch 456/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2560 - accuracy: 0.9258 - val_loss: 0.5086 - val_accuracy: 0.8750\n",
      "Epoch 457/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2451 - accuracy: 0.9336 - val_loss: 0.5444 - val_accuracy: 0.8750\n",
      "Epoch 458/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2691 - accuracy: 0.9297 - val_loss: 0.5302 - val_accuracy: 0.8750\n",
      "Epoch 459/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2574 - accuracy: 0.9180 - val_loss: 0.5019 - val_accuracy: 0.8750\n",
      "Epoch 460/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2642 - accuracy: 0.9297 - val_loss: 0.5333 - val_accuracy: 0.8750\n",
      "Epoch 461/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2572 - accuracy: 0.9336 - val_loss: 0.5237 - val_accuracy: 0.8750\n",
      "Epoch 462/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2527 - accuracy: 0.9336 - val_loss: 0.5340 - val_accuracy: 0.8906\n",
      "Epoch 463/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2536 - accuracy: 0.9375 - val_loss: 0.5481 - val_accuracy: 0.8750\n",
      "Epoch 464/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2570 - accuracy: 0.9297 - val_loss: 0.5299 - val_accuracy: 0.8750\n",
      "Epoch 465/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2577 - accuracy: 0.9219 - val_loss: 0.5161 - val_accuracy: 0.8750\n",
      "Epoch 466/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2551 - accuracy: 0.9336 - val_loss: 0.5016 - val_accuracy: 0.8750\n",
      "Epoch 467/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2424 - accuracy: 0.9297 - val_loss: 0.5116 - val_accuracy: 0.8750\n",
      "Epoch 468/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2508 - accuracy: 0.9297 - val_loss: 0.5513 - val_accuracy: 0.8750\n",
      "Epoch 469/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2650 - accuracy: 0.9258 - val_loss: 0.5601 - val_accuracy: 0.8906\n",
      "Epoch 470/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2579 - accuracy: 0.9297 - val_loss: 0.5504 - val_accuracy: 0.8906\n",
      "Epoch 471/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2525 - accuracy: 0.9258 - val_loss: 0.5262 - val_accuracy: 0.8906\n",
      "Epoch 472/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2537 - accuracy: 0.9336 - val_loss: 0.5090 - val_accuracy: 0.8750\n",
      "Epoch 473/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2549 - accuracy: 0.9297 - val_loss: 0.5203 - val_accuracy: 0.8750\n",
      "Epoch 474/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2476 - accuracy: 0.9336 - val_loss: 0.5551 - val_accuracy: 0.8906\n",
      "Epoch 475/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2427 - accuracy: 0.9258 - val_loss: 0.5422 - val_accuracy: 0.8750\n",
      "Epoch 476/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2608 - accuracy: 0.9297 - val_loss: 0.5493 - val_accuracy: 0.8906\n",
      "Epoch 477/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2461 - accuracy: 0.9375 - val_loss: 0.5741 - val_accuracy: 0.8906\n",
      "Epoch 478/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2546 - accuracy: 0.9258 - val_loss: 0.5650 - val_accuracy: 0.8750\n",
      "Epoch 479/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2466 - accuracy: 0.9336 - val_loss: 0.5467 - val_accuracy: 0.8750\n",
      "Epoch 480/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2537 - accuracy: 0.9258 - val_loss: 0.5515 - val_accuracy: 0.8750\n",
      "Epoch 481/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2601 - accuracy: 0.9297 - val_loss: 0.5506 - val_accuracy: 0.8750\n",
      "Epoch 482/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2540 - accuracy: 0.9258 - val_loss: 0.5626 - val_accuracy: 0.8906\n",
      "Epoch 483/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2497 - accuracy: 0.9258 - val_loss: 0.5466 - val_accuracy: 0.8750\n",
      "Epoch 484/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2481 - accuracy: 0.9336 - val_loss: 0.5427 - val_accuracy: 0.8750\n",
      "Epoch 485/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2523 - accuracy: 0.9297 - val_loss: 0.5342 - val_accuracy: 0.8750\n",
      "Epoch 486/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2630 - accuracy: 0.9297 - val_loss: 0.5857 - val_accuracy: 0.8906\n",
      "Epoch 487/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2621 - accuracy: 0.9258 - val_loss: 0.5410 - val_accuracy: 0.8750\n",
      "Epoch 488/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2517 - accuracy: 0.9297 - val_loss: 0.5404 - val_accuracy: 0.8750\n",
      "Epoch 489/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2604 - accuracy: 0.9297 - val_loss: 0.5546 - val_accuracy: 0.8906\n",
      "Epoch 490/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2650 - accuracy: 0.9258 - val_loss: 0.5397 - val_accuracy: 0.8750\n",
      "Epoch 491/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2496 - accuracy: 0.9336 - val_loss: 0.5593 - val_accuracy: 0.8750\n",
      "Epoch 492/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2530 - accuracy: 0.9297 - val_loss: 0.5354 - val_accuracy: 0.8750\n",
      "Epoch 493/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2507 - accuracy: 0.9297 - val_loss: 0.5622 - val_accuracy: 0.8750\n",
      "Epoch 494/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2582 - accuracy: 0.9336 - val_loss: 0.5717 - val_accuracy: 0.8750\n",
      "Epoch 495/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2568 - accuracy: 0.9297 - val_loss: 0.5825 - val_accuracy: 0.8750\n",
      "Epoch 496/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2909 - accuracy: 0.9375 - val_loss: 0.6235 - val_accuracy: 0.8906\n",
      "Epoch 497/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2733 - accuracy: 0.9336 - val_loss: 0.5990 - val_accuracy: 0.8750\n",
      "Epoch 498/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2665 - accuracy: 0.9336 - val_loss: 0.5764 - val_accuracy: 0.8750\n",
      "Epoch 499/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2647 - accuracy: 0.9180 - val_loss: 0.5628 - val_accuracy: 0.8750\n",
      "Epoch 500/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2546 - accuracy: 0.9258 - val_loss: 0.5997 - val_accuracy: 0.8906\n",
      "Epoch 501/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2720 - accuracy: 0.9336 - val_loss: 0.5806 - val_accuracy: 0.8750\n",
      "Epoch 502/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2627 - accuracy: 0.9297 - val_loss: 0.5828 - val_accuracy: 0.8906\n",
      "Epoch 503/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2762 - accuracy: 0.9297 - val_loss: 0.5792 - val_accuracy: 0.8750\n",
      "Epoch 504/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2519 - accuracy: 0.9297 - val_loss: 0.6087 - val_accuracy: 0.8750\n",
      "Epoch 505/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2668 - accuracy: 0.9336 - val_loss: 0.5994 - val_accuracy: 0.8906\n",
      "Epoch 506/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2581 - accuracy: 0.9336 - val_loss: 0.5684 - val_accuracy: 0.8750\n",
      "Epoch 507/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2491 - accuracy: 0.9258 - val_loss: 0.6004 - val_accuracy: 0.8906\n",
      "Epoch 508/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2687 - accuracy: 0.9297 - val_loss: 0.5831 - val_accuracy: 0.8750\n",
      "Epoch 509/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2669 - accuracy: 0.9375 - val_loss: 0.5972 - val_accuracy: 0.8750\n",
      "Epoch 510/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2641 - accuracy: 0.9375 - val_loss: 0.6102 - val_accuracy: 0.8906\n",
      "Epoch 511/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2780 - accuracy: 0.9297 - val_loss: 0.5723 - val_accuracy: 0.8750\n",
      "Epoch 512/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2512 - accuracy: 0.9336 - val_loss: 0.5862 - val_accuracy: 0.8750\n",
      "Epoch 513/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2770 - accuracy: 0.9336 - val_loss: 0.6080 - val_accuracy: 0.8750\n",
      "Epoch 514/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2657 - accuracy: 0.9258 - val_loss: 0.6031 - val_accuracy: 0.8750\n",
      "Epoch 515/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2503 - accuracy: 0.9375 - val_loss: 0.5952 - val_accuracy: 0.8750\n",
      "Epoch 516/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2600 - accuracy: 0.9297 - val_loss: 0.5944 - val_accuracy: 0.8750\n",
      "Epoch 517/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2725 - accuracy: 0.9219 - val_loss: 0.6066 - val_accuracy: 0.8750\n",
      "Epoch 518/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2565 - accuracy: 0.9297 - val_loss: 0.5980 - val_accuracy: 0.8750\n",
      "Epoch 519/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2636 - accuracy: 0.9297 - val_loss: 0.5993 - val_accuracy: 0.8750\n",
      "Epoch 520/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2573 - accuracy: 0.9258 - val_loss: 0.5978 - val_accuracy: 0.8750\n",
      "Epoch 521/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2667 - accuracy: 0.9219 - val_loss: 0.5810 - val_accuracy: 0.8750\n",
      "Epoch 522/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2576 - accuracy: 0.9258 - val_loss: 0.5460 - val_accuracy: 0.8750\n",
      "Epoch 523/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2483 - accuracy: 0.9297 - val_loss: 0.6049 - val_accuracy: 0.8750\n",
      "Epoch 524/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2677 - accuracy: 0.9258 - val_loss: 0.6008 - val_accuracy: 0.8750\n",
      "Epoch 525/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2902 - accuracy: 0.9219 - val_loss: 0.5755 - val_accuracy: 0.8750\n",
      "Epoch 526/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2781 - accuracy: 0.9297 - val_loss: 0.6041 - val_accuracy: 0.8906\n",
      "Epoch 527/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2677 - accuracy: 0.9258 - val_loss: 0.5635 - val_accuracy: 0.8750\n",
      "Epoch 528/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2619 - accuracy: 0.9336 - val_loss: 0.5555 - val_accuracy: 0.8750\n",
      "Epoch 529/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2574 - accuracy: 0.9336 - val_loss: 0.5718 - val_accuracy: 0.8750\n",
      "Epoch 530/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2724 - accuracy: 0.9414 - val_loss: 0.5846 - val_accuracy: 0.8906\n",
      "Epoch 531/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2503 - accuracy: 0.9219 - val_loss: 0.5728 - val_accuracy: 0.8750\n",
      "Epoch 532/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2717 - accuracy: 0.9297 - val_loss: 0.5640 - val_accuracy: 0.8750\n",
      "Epoch 533/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2696 - accuracy: 0.9297 - val_loss: 0.5545 - val_accuracy: 0.8750\n",
      "Epoch 534/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2539 - accuracy: 0.9297 - val_loss: 0.5759 - val_accuracy: 0.8750\n",
      "Epoch 535/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2703 - accuracy: 0.9219 - val_loss: 0.5431 - val_accuracy: 0.8750\n",
      "Epoch 536/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2794 - accuracy: 0.9258 - val_loss: 0.5518 - val_accuracy: 0.8750\n",
      "Epoch 537/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2568 - accuracy: 0.9336 - val_loss: 0.5397 - val_accuracy: 0.8750\n",
      "Epoch 538/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2599 - accuracy: 0.9375 - val_loss: 0.5897 - val_accuracy: 0.8906\n",
      "Epoch 539/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2693 - accuracy: 0.9219 - val_loss: 0.5647 - val_accuracy: 0.8750\n",
      "Epoch 540/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2757 - accuracy: 0.9336 - val_loss: 0.5739 - val_accuracy: 0.8750\n",
      "Epoch 541/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2585 - accuracy: 0.9336 - val_loss: 0.5944 - val_accuracy: 0.8750\n",
      "Epoch 542/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2721 - accuracy: 0.9297 - val_loss: 0.5783 - val_accuracy: 0.8750\n",
      "Epoch 543/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2692 - accuracy: 0.9258 - val_loss: 0.5971 - val_accuracy: 0.8750\n",
      "Epoch 544/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2757 - accuracy: 0.9258 - val_loss: 0.5964 - val_accuracy: 0.8750\n",
      "Epoch 545/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2579 - accuracy: 0.9336 - val_loss: 0.6107 - val_accuracy: 0.8906\n",
      "Epoch 546/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2782 - accuracy: 0.9297 - val_loss: 0.6086 - val_accuracy: 0.8750\n",
      "Epoch 547/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2678 - accuracy: 0.9297 - val_loss: 0.5909 - val_accuracy: 0.8750\n",
      "Epoch 548/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2658 - accuracy: 0.9297 - val_loss: 0.6209 - val_accuracy: 0.8906\n",
      "Epoch 549/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2871 - accuracy: 0.9219 - val_loss: 0.5864 - val_accuracy: 0.8750\n",
      "Epoch 550/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2831 - accuracy: 0.9258 - val_loss: 0.5994 - val_accuracy: 0.8750\n",
      "Epoch 551/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2649 - accuracy: 0.9258 - val_loss: 0.5722 - val_accuracy: 0.8750\n",
      "Epoch 552/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2762 - accuracy: 0.9219 - val_loss: 0.5729 - val_accuracy: 0.8750\n",
      "Epoch 553/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2743 - accuracy: 0.9297 - val_loss: 0.5937 - val_accuracy: 0.8750\n",
      "Epoch 554/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2608 - accuracy: 0.9297 - val_loss: 0.5847 - val_accuracy: 0.8750\n",
      "Epoch 555/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2741 - accuracy: 0.9258 - val_loss: 0.5841 - val_accuracy: 0.8750\n",
      "Epoch 556/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2670 - accuracy: 0.9336 - val_loss: 0.6161 - val_accuracy: 0.8906\n",
      "Epoch 557/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2792 - accuracy: 0.9336 - val_loss: 0.6024 - val_accuracy: 0.8750\n",
      "Epoch 558/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2679 - accuracy: 0.9297 - val_loss: 0.6607 - val_accuracy: 0.8906\n",
      "Epoch 559/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2826 - accuracy: 0.9258 - val_loss: 0.5935 - val_accuracy: 0.8750\n",
      "Epoch 560/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2742 - accuracy: 0.9258 - val_loss: 0.5763 - val_accuracy: 0.8750\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2448 - accuracy: 0.9375 - val_loss: 0.6375 - val_accuracy: 0.8906\n",
      "Epoch 562/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2765 - accuracy: 0.9297 - val_loss: 0.6276 - val_accuracy: 0.8750\n",
      "Epoch 563/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2806 - accuracy: 0.9258 - val_loss: 0.6143 - val_accuracy: 0.8750\n",
      "Epoch 564/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2967 - accuracy: 0.9336 - val_loss: 0.6108 - val_accuracy: 0.8750\n",
      "Epoch 565/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2769 - accuracy: 0.9375 - val_loss: 0.6105 - val_accuracy: 0.8750\n",
      "Epoch 566/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2915 - accuracy: 0.9336 - val_loss: 0.6299 - val_accuracy: 0.8750\n",
      "Epoch 567/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2797 - accuracy: 0.9258 - val_loss: 0.6184 - val_accuracy: 0.8750\n",
      "Epoch 568/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2588 - accuracy: 0.9375 - val_loss: 0.6884 - val_accuracy: 0.8906\n",
      "Epoch 569/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2887 - accuracy: 0.9297 - val_loss: 0.6244 - val_accuracy: 0.8750\n",
      "Epoch 570/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2641 - accuracy: 0.9336 - val_loss: 0.6540 - val_accuracy: 0.8750\n",
      "Epoch 571/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2888 - accuracy: 0.9297 - val_loss: 0.6445 - val_accuracy: 0.8750\n",
      "Epoch 572/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3086 - accuracy: 0.9297 - val_loss: 0.6487 - val_accuracy: 0.8750\n",
      "Epoch 573/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2810 - accuracy: 0.9297 - val_loss: 0.6205 - val_accuracy: 0.8750\n",
      "Epoch 574/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2901 - accuracy: 0.9258 - val_loss: 0.6532 - val_accuracy: 0.8906\n",
      "Epoch 575/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2758 - accuracy: 0.9297 - val_loss: 0.5883 - val_accuracy: 0.8750\n",
      "Epoch 576/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2600 - accuracy: 0.9375 - val_loss: 0.5894 - val_accuracy: 0.8750\n",
      "Epoch 577/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2720 - accuracy: 0.9297 - val_loss: 0.6153 - val_accuracy: 0.8906\n",
      "Epoch 578/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2677 - accuracy: 0.9297 - val_loss: 0.6121 - val_accuracy: 0.8906\n",
      "Epoch 579/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2623 - accuracy: 0.9336 - val_loss: 0.6348 - val_accuracy: 0.8906\n",
      "Epoch 580/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2786 - accuracy: 0.9258 - val_loss: 0.5824 - val_accuracy: 0.8750\n",
      "Epoch 581/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2655 - accuracy: 0.9297 - val_loss: 0.5468 - val_accuracy: 0.8750\n",
      "Epoch 582/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2721 - accuracy: 0.9297 - val_loss: 0.5741 - val_accuracy: 0.8750\n",
      "Epoch 583/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2727 - accuracy: 0.9297 - val_loss: 0.5844 - val_accuracy: 0.8750\n",
      "Epoch 584/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2830 - accuracy: 0.9297 - val_loss: 0.5691 - val_accuracy: 0.8750\n",
      "Epoch 585/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2777 - accuracy: 0.9336 - val_loss: 0.5854 - val_accuracy: 0.8750\n",
      "Epoch 586/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2634 - accuracy: 0.9336 - val_loss: 0.5686 - val_accuracy: 0.8750\n",
      "Epoch 587/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2683 - accuracy: 0.9336 - val_loss: 0.5597 - val_accuracy: 0.8750\n",
      "Epoch 588/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2481 - accuracy: 0.9336 - val_loss: 0.6152 - val_accuracy: 0.8906\n",
      "Epoch 589/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2572 - accuracy: 0.9375 - val_loss: 0.5258 - val_accuracy: 0.8750\n",
      "Epoch 590/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2638 - accuracy: 0.9297 - val_loss: 0.5566 - val_accuracy: 0.8750\n",
      "Epoch 591/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2600 - accuracy: 0.9297 - val_loss: 0.6036 - val_accuracy: 0.8906\n",
      "Epoch 592/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2672 - accuracy: 0.9336 - val_loss: 0.5759 - val_accuracy: 0.8906\n",
      "Epoch 593/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2759 - accuracy: 0.9258 - val_loss: 0.5394 - val_accuracy: 0.8750\n",
      "Epoch 594/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2759 - accuracy: 0.9297 - val_loss: 0.5505 - val_accuracy: 0.8750\n",
      "Epoch 595/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2713 - accuracy: 0.9297 - val_loss: 0.5782 - val_accuracy: 0.8750\n",
      "Epoch 596/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2749 - accuracy: 0.9297 - val_loss: 0.5708 - val_accuracy: 0.8750\n",
      "Epoch 597/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2706 - accuracy: 0.9375 - val_loss: 0.5911 - val_accuracy: 0.8906\n",
      "Epoch 598/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2820 - accuracy: 0.9375 - val_loss: 0.5776 - val_accuracy: 0.8750\n",
      "Epoch 599/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2691 - accuracy: 0.9336 - val_loss: 0.5774 - val_accuracy: 0.8750\n",
      "Epoch 600/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2633 - accuracy: 0.9297 - val_loss: 0.6072 - val_accuracy: 0.8906\n",
      "Epoch 601/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2692 - accuracy: 0.9297 - val_loss: 0.5637 - val_accuracy: 0.8750\n",
      "Epoch 602/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2631 - accuracy: 0.9297 - val_loss: 0.5928 - val_accuracy: 0.8750\n",
      "Epoch 603/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2929 - accuracy: 0.9297 - val_loss: 0.5594 - val_accuracy: 0.8750\n",
      "Epoch 604/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2699 - accuracy: 0.9258 - val_loss: 0.5372 - val_accuracy: 0.8750\n",
      "Epoch 605/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2425 - accuracy: 0.9336 - val_loss: 0.5735 - val_accuracy: 0.8750\n",
      "Epoch 606/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2822 - accuracy: 0.9375 - val_loss: 0.5563 - val_accuracy: 0.8750\n",
      "Epoch 607/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2702 - accuracy: 0.9414 - val_loss: 0.5606 - val_accuracy: 0.8750\n",
      "Epoch 608/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2697 - accuracy: 0.9258 - val_loss: 0.5484 - val_accuracy: 0.8750\n",
      "Epoch 609/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2728 - accuracy: 0.9375 - val_loss: 0.5760 - val_accuracy: 0.8750\n",
      "Epoch 610/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2783 - accuracy: 0.9375 - val_loss: 0.5566 - val_accuracy: 0.8750\n",
      "Epoch 611/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2639 - accuracy: 0.9336 - val_loss: 0.6062 - val_accuracy: 0.8906\n",
      "Epoch 612/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2894 - accuracy: 0.9336 - val_loss: 0.5685 - val_accuracy: 0.8906\n",
      "Epoch 613/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2825 - accuracy: 0.9375 - val_loss: 0.5454 - val_accuracy: 0.8750\n",
      "Epoch 614/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2554 - accuracy: 0.9297 - val_loss: 0.5877 - val_accuracy: 0.8906\n",
      "Epoch 615/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2947 - accuracy: 0.9219 - val_loss: 0.5762 - val_accuracy: 0.8906\n",
      "Epoch 616/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2663 - accuracy: 0.9375 - val_loss: 0.5315 - val_accuracy: 0.8750\n",
      "Epoch 617/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2646 - accuracy: 0.9258 - val_loss: 0.5739 - val_accuracy: 0.8750\n",
      "Epoch 618/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2621 - accuracy: 0.9258 - val_loss: 0.5721 - val_accuracy: 0.8750\n",
      "Epoch 619/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2600 - accuracy: 0.9375 - val_loss: 0.5737 - val_accuracy: 0.8906\n",
      "Epoch 620/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2680 - accuracy: 0.9336 - val_loss: 0.5602 - val_accuracy: 0.8750\n",
      "Epoch 621/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2538 - accuracy: 0.9297 - val_loss: 0.5977 - val_accuracy: 0.8750\n",
      "Epoch 622/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2786 - accuracy: 0.9297 - val_loss: 0.5299 - val_accuracy: 0.8750\n",
      "Epoch 623/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2757 - accuracy: 0.9297 - val_loss: 0.5276 - val_accuracy: 0.8750\n",
      "Epoch 624/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2625 - accuracy: 0.9453 - val_loss: 0.5897 - val_accuracy: 0.8750\n",
      "Epoch 625/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2763 - accuracy: 0.9297 - val_loss: 0.5752 - val_accuracy: 0.8750\n",
      "Epoch 626/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2731 - accuracy: 0.9297 - val_loss: 0.5633 - val_accuracy: 0.8750\n",
      "Epoch 627/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2717 - accuracy: 0.9336 - val_loss: 0.5946 - val_accuracy: 0.8906\n",
      "Epoch 628/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2812 - accuracy: 0.9297 - val_loss: 0.5445 - val_accuracy: 0.8906\n",
      "Epoch 629/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2533 - accuracy: 0.9375 - val_loss: 0.5447 - val_accuracy: 0.8750\n",
      "Epoch 630/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2637 - accuracy: 0.9375 - val_loss: 0.5515 - val_accuracy: 0.8750\n",
      "Epoch 631/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2614 - accuracy: 0.9297 - val_loss: 0.5690 - val_accuracy: 0.8750\n",
      "Epoch 632/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2665 - accuracy: 0.9336 - val_loss: 0.5867 - val_accuracy: 0.8750\n",
      "Epoch 633/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2773 - accuracy: 0.9375 - val_loss: 0.5417 - val_accuracy: 0.8750\n",
      "Epoch 634/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2820 - accuracy: 0.9297 - val_loss: 0.5297 - val_accuracy: 0.8750\n",
      "Epoch 635/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2850 - accuracy: 0.9375 - val_loss: 0.5430 - val_accuracy: 0.8750\n",
      "Epoch 636/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2681 - accuracy: 0.9297 - val_loss: 0.5201 - val_accuracy: 0.8750\n",
      "Epoch 637/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2830 - accuracy: 0.9375 - val_loss: 0.5468 - val_accuracy: 0.8750\n",
      "Epoch 638/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2722 - accuracy: 0.9297 - val_loss: 0.5167 - val_accuracy: 0.8750\n",
      "Epoch 639/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2637 - accuracy: 0.9336 - val_loss: 0.5573 - val_accuracy: 0.8750\n",
      "Epoch 640/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2679 - accuracy: 0.9336 - val_loss: 0.5506 - val_accuracy: 0.8750\n",
      "Epoch 641/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2628 - accuracy: 0.9375 - val_loss: 0.5483 - val_accuracy: 0.8750\n",
      "Epoch 642/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2623 - accuracy: 0.9375 - val_loss: 0.5596 - val_accuracy: 0.8906\n",
      "Epoch 643/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2625 - accuracy: 0.9258 - val_loss: 0.4997 - val_accuracy: 0.8750\n",
      "Epoch 644/1000\n",
      "256/256 [==============================] - 1s 3ms/step - loss: 0.2764 - accuracy: 0.9375 - val_loss: 0.5255 - val_accuracy: 0.8750\n",
      "Epoch 645/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2547 - accuracy: 0.9336 - val_loss: 0.5712 - val_accuracy: 0.8906\n",
      "Epoch 646/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2760 - accuracy: 0.9375 - val_loss: 0.5469 - val_accuracy: 0.8750\n",
      "Epoch 647/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2504 - accuracy: 0.9336 - val_loss: 0.5095 - val_accuracy: 0.8750\n",
      "Epoch 648/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2628 - accuracy: 0.9375 - val_loss: 0.5266 - val_accuracy: 0.8750\n",
      "Epoch 649/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2809 - accuracy: 0.9336 - val_loss: 0.5462 - val_accuracy: 0.8750\n",
      "Epoch 650/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2713 - accuracy: 0.9336 - val_loss: 0.5647 - val_accuracy: 0.8906\n",
      "Epoch 651/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2564 - accuracy: 0.9336 - val_loss: 0.5316 - val_accuracy: 0.8750\n",
      "Epoch 652/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2667 - accuracy: 0.9375 - val_loss: 0.5394 - val_accuracy: 0.8750\n",
      "Epoch 653/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2723 - accuracy: 0.9336 - val_loss: 0.5498 - val_accuracy: 0.8750\n",
      "Epoch 654/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2578 - accuracy: 0.9297 - val_loss: 0.5793 - val_accuracy: 0.8750\n",
      "Epoch 655/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2585 - accuracy: 0.9336 - val_loss: 0.5766 - val_accuracy: 0.8750\n",
      "Epoch 656/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2737 - accuracy: 0.9336 - val_loss: 0.6041 - val_accuracy: 0.8750\n",
      "Epoch 657/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2724 - accuracy: 0.9336 - val_loss: 0.5936 - val_accuracy: 0.8906\n",
      "Epoch 658/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2834 - accuracy: 0.9336 - val_loss: 0.5694 - val_accuracy: 0.8750\n",
      "Epoch 659/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2804 - accuracy: 0.9297 - val_loss: 0.5338 - val_accuracy: 0.8750\n",
      "Epoch 660/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2612 - accuracy: 0.9336 - val_loss: 0.6120 - val_accuracy: 0.8906\n",
      "Epoch 661/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2874 - accuracy: 0.9336 - val_loss: 0.5600 - val_accuracy: 0.8750\n",
      "Epoch 662/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2848 - accuracy: 0.9336 - val_loss: 0.5445 - val_accuracy: 0.8750\n",
      "Epoch 663/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2614 - accuracy: 0.9375 - val_loss: 0.5322 - val_accuracy: 0.8750\n",
      "Epoch 664/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2571 - accuracy: 0.9297 - val_loss: 0.5375 - val_accuracy: 0.8750\n",
      "Epoch 665/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2852 - accuracy: 0.9336 - val_loss: 0.5523 - val_accuracy: 0.8750\n",
      "Epoch 666/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2773 - accuracy: 0.9375 - val_loss: 0.5405 - val_accuracy: 0.8750\n",
      "Epoch 667/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2687 - accuracy: 0.9297 - val_loss: 0.5248 - val_accuracy: 0.8750\n",
      "Epoch 668/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2603 - accuracy: 0.9336 - val_loss: 0.5784 - val_accuracy: 0.8750\n",
      "Epoch 669/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2840 - accuracy: 0.9336 - val_loss: 0.5436 - val_accuracy: 0.8750\n",
      "Epoch 670/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2716 - accuracy: 0.9375 - val_loss: 0.5769 - val_accuracy: 0.8750\n",
      "Epoch 671/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2786 - accuracy: 0.9336 - val_loss: 0.5537 - val_accuracy: 0.8750\n",
      "Epoch 672/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2796 - accuracy: 0.9375 - val_loss: 0.5403 - val_accuracy: 0.8750\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2719 - accuracy: 0.9336 - val_loss: 0.5485 - val_accuracy: 0.8750\n",
      "Epoch 674/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2709 - accuracy: 0.9375 - val_loss: 0.5489 - val_accuracy: 0.8750\n",
      "Epoch 675/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2652 - accuracy: 0.9336 - val_loss: 0.5393 - val_accuracy: 0.8750\n",
      "Epoch 676/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2791 - accuracy: 0.9258 - val_loss: 0.5505 - val_accuracy: 0.8750\n",
      "Epoch 677/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2699 - accuracy: 0.9375 - val_loss: 0.5687 - val_accuracy: 0.8906\n",
      "Epoch 678/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2802 - accuracy: 0.9375 - val_loss: 0.5922 - val_accuracy: 0.8906\n",
      "Epoch 679/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2994 - accuracy: 0.9336 - val_loss: 0.5491 - val_accuracy: 0.8750\n",
      "Epoch 680/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2586 - accuracy: 0.9336 - val_loss: 0.5650 - val_accuracy: 0.8906\n",
      "Epoch 681/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2553 - accuracy: 0.9375 - val_loss: 0.5231 - val_accuracy: 0.8906\n",
      "Epoch 682/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2856 - accuracy: 0.9258 - val_loss: 0.5081 - val_accuracy: 0.8750\n",
      "Epoch 683/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2568 - accuracy: 0.9375 - val_loss: 0.5509 - val_accuracy: 0.8906\n",
      "Epoch 684/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2707 - accuracy: 0.9336 - val_loss: 0.5739 - val_accuracy: 0.8906\n",
      "Epoch 685/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2682 - accuracy: 0.9336 - val_loss: 0.5406 - val_accuracy: 0.8750\n",
      "Epoch 686/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2625 - accuracy: 0.9297 - val_loss: 0.5493 - val_accuracy: 0.8750\n",
      "Epoch 687/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2894 - accuracy: 0.9336 - val_loss: 0.5378 - val_accuracy: 0.8750\n",
      "Epoch 688/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2960 - accuracy: 0.9375 - val_loss: 0.5486 - val_accuracy: 0.8906\n",
      "Epoch 689/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2771 - accuracy: 0.9414 - val_loss: 0.5317 - val_accuracy: 0.8750\n",
      "Epoch 690/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2929 - accuracy: 0.9336 - val_loss: 0.5638 - val_accuracy: 0.8750\n",
      "Epoch 691/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2891 - accuracy: 0.9375 - val_loss: 0.5802 - val_accuracy: 0.8750\n",
      "Epoch 692/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2749 - accuracy: 0.9375 - val_loss: 0.5537 - val_accuracy: 0.8750\n",
      "Epoch 693/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2766 - accuracy: 0.9336 - val_loss: 0.5554 - val_accuracy: 0.8906\n",
      "Epoch 694/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2822 - accuracy: 0.9336 - val_loss: 0.5329 - val_accuracy: 0.8750\n",
      "Epoch 695/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2845 - accuracy: 0.9375 - val_loss: 0.5127 - val_accuracy: 0.8906\n",
      "Epoch 696/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2534 - accuracy: 0.9336 - val_loss: 0.5235 - val_accuracy: 0.8750\n",
      "Epoch 697/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2816 - accuracy: 0.9336 - val_loss: 0.5142 - val_accuracy: 0.8906\n",
      "Epoch 698/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2627 - accuracy: 0.9375 - val_loss: 0.5197 - val_accuracy: 0.8906\n",
      "Epoch 699/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2669 - accuracy: 0.9297 - val_loss: 0.5406 - val_accuracy: 0.8750\n",
      "Epoch 700/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2704 - accuracy: 0.9375 - val_loss: 0.5568 - val_accuracy: 0.8906\n",
      "Epoch 701/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2865 - accuracy: 0.9336 - val_loss: 0.5262 - val_accuracy: 0.8750\n",
      "Epoch 702/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2733 - accuracy: 0.9336 - val_loss: 0.5324 - val_accuracy: 0.8906\n",
      "Epoch 703/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2642 - accuracy: 0.9375 - val_loss: 0.5324 - val_accuracy: 0.8906\n",
      "Epoch 704/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2576 - accuracy: 0.9375 - val_loss: 0.5148 - val_accuracy: 0.8906\n",
      "Epoch 705/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2723 - accuracy: 0.9375 - val_loss: 0.5386 - val_accuracy: 0.8906\n",
      "Epoch 706/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2629 - accuracy: 0.9375 - val_loss: 0.5509 - val_accuracy: 0.8906\n",
      "Epoch 707/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2643 - accuracy: 0.9336 - val_loss: 0.5569 - val_accuracy: 0.8750\n",
      "Epoch 708/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2589 - accuracy: 0.9336 - val_loss: 0.5847 - val_accuracy: 0.8906\n",
      "Epoch 709/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2741 - accuracy: 0.9414 - val_loss: 0.5447 - val_accuracy: 0.8750\n",
      "Epoch 710/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2982 - accuracy: 0.9375 - val_loss: 0.5623 - val_accuracy: 0.8750\n",
      "Epoch 711/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2490 - accuracy: 0.9336 - val_loss: 0.6017 - val_accuracy: 0.8906\n",
      "Epoch 712/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2571 - accuracy: 0.9375 - val_loss: 0.5722 - val_accuracy: 0.8750\n",
      "Epoch 713/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2770 - accuracy: 0.9414 - val_loss: 0.5552 - val_accuracy: 0.8750\n",
      "Epoch 714/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2517 - accuracy: 0.9414 - val_loss: 0.5639 - val_accuracy: 0.8906\n",
      "Epoch 715/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2921 - accuracy: 0.9375 - val_loss: 0.5387 - val_accuracy: 0.8750\n",
      "Epoch 716/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2713 - accuracy: 0.9336 - val_loss: 0.5651 - val_accuracy: 0.8906\n",
      "Epoch 717/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2600 - accuracy: 0.9336 - val_loss: 0.5821 - val_accuracy: 0.8906\n",
      "Epoch 718/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2586 - accuracy: 0.9453 - val_loss: 0.5014 - val_accuracy: 0.8750\n",
      "Epoch 719/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2678 - accuracy: 0.9336 - val_loss: 0.5284 - val_accuracy: 0.8750\n",
      "Epoch 720/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2909 - accuracy: 0.9453 - val_loss: 0.5698 - val_accuracy: 0.8906\n",
      "Epoch 721/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2597 - accuracy: 0.9336 - val_loss: 0.5191 - val_accuracy: 0.8750\n",
      "Epoch 722/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2740 - accuracy: 0.9414 - val_loss: 0.5250 - val_accuracy: 0.8906\n",
      "Epoch 723/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2780 - accuracy: 0.9375 - val_loss: 0.5090 - val_accuracy: 0.8750\n",
      "Epoch 724/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2505 - accuracy: 0.9414 - val_loss: 0.5063 - val_accuracy: 0.8750\n",
      "Epoch 725/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2504 - accuracy: 0.9414 - val_loss: 0.5216 - val_accuracy: 0.8750\n",
      "Epoch 726/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2486 - accuracy: 0.9375 - val_loss: 0.5385 - val_accuracy: 0.8750\n",
      "Epoch 727/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2537 - accuracy: 0.9336 - val_loss: 0.5666 - val_accuracy: 0.8750\n",
      "Epoch 728/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2620 - accuracy: 0.9375 - val_loss: 0.5446 - val_accuracy: 0.8750\n",
      "Epoch 729/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2521 - accuracy: 0.9375 - val_loss: 0.5517 - val_accuracy: 0.8906\n",
      "Epoch 730/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2754 - accuracy: 0.9414 - val_loss: 0.5391 - val_accuracy: 0.8750\n",
      "Epoch 731/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2449 - accuracy: 0.9336 - val_loss: 0.5389 - val_accuracy: 0.8750\n",
      "Epoch 732/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2725 - accuracy: 0.9414 - val_loss: 0.5367 - val_accuracy: 0.8750\n",
      "Epoch 733/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2526 - accuracy: 0.9414 - val_loss: 0.5529 - val_accuracy: 0.8594\n",
      "Epoch 734/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2532 - accuracy: 0.9375 - val_loss: 0.5655 - val_accuracy: 0.8906\n",
      "Epoch 735/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2789 - accuracy: 0.9336 - val_loss: 0.5262 - val_accuracy: 0.8750\n",
      "Epoch 736/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3052 - accuracy: 0.9414 - val_loss: 0.5562 - val_accuracy: 0.8750\n",
      "Epoch 737/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2855 - accuracy: 0.9336 - val_loss: 0.5461 - val_accuracy: 0.8906\n",
      "Epoch 738/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2542 - accuracy: 0.9375 - val_loss: 0.4763 - val_accuracy: 0.8750\n",
      "Epoch 739/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2484 - accuracy: 0.9375 - val_loss: 0.5676 - val_accuracy: 0.8906\n",
      "Epoch 740/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2421 - accuracy: 0.9336 - val_loss: 0.5179 - val_accuracy: 0.8906\n",
      "Epoch 741/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2629 - accuracy: 0.9375 - val_loss: 0.5094 - val_accuracy: 0.8906\n",
      "Epoch 742/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2366 - accuracy: 0.9414 - val_loss: 0.5188 - val_accuracy: 0.8906\n",
      "Epoch 743/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2682 - accuracy: 0.9336 - val_loss: 0.5333 - val_accuracy: 0.8906\n",
      "Epoch 744/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2369 - accuracy: 0.9414 - val_loss: 0.5820 - val_accuracy: 0.8750\n",
      "Epoch 745/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2699 - accuracy: 0.9375 - val_loss: 0.5234 - val_accuracy: 0.8906\n",
      "Epoch 746/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2709 - accuracy: 0.9336 - val_loss: 0.5155 - val_accuracy: 0.8906\n",
      "Epoch 747/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2474 - accuracy: 0.9414 - val_loss: 0.5642 - val_accuracy: 0.8906\n",
      "Epoch 748/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2730 - accuracy: 0.9258 - val_loss: 0.5344 - val_accuracy: 0.8906\n",
      "Epoch 749/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2847 - accuracy: 0.9336 - val_loss: 0.5926 - val_accuracy: 0.8906\n",
      "Epoch 750/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2857 - accuracy: 0.9414 - val_loss: 0.5313 - val_accuracy: 0.8906\n",
      "Epoch 751/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2869 - accuracy: 0.9336 - val_loss: 0.5392 - val_accuracy: 0.8906\n",
      "Epoch 752/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2895 - accuracy: 0.9414 - val_loss: 0.5711 - val_accuracy: 0.8906\n",
      "Epoch 753/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2483 - accuracy: 0.9336 - val_loss: 0.5183 - val_accuracy: 0.8594\n",
      "Epoch 754/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2648 - accuracy: 0.9375 - val_loss: 0.5273 - val_accuracy: 0.8594\n",
      "Epoch 755/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2699 - accuracy: 0.9375 - val_loss: 0.5217 - val_accuracy: 0.8750\n",
      "Epoch 756/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2449 - accuracy: 0.9375 - val_loss: 0.5979 - val_accuracy: 0.8750\n",
      "Epoch 757/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2741 - accuracy: 0.9414 - val_loss: 0.5016 - val_accuracy: 0.8750\n",
      "Epoch 758/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3005 - accuracy: 0.9375 - val_loss: 0.4901 - val_accuracy: 0.8594\n",
      "Epoch 759/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2740 - accuracy: 0.9375 - val_loss: 0.5198 - val_accuracy: 0.8750\n",
      "Epoch 760/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2947 - accuracy: 0.9414 - val_loss: 0.5266 - val_accuracy: 0.8906\n",
      "Epoch 761/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2810 - accuracy: 0.9297 - val_loss: 0.5075 - val_accuracy: 0.8906\n",
      "Epoch 762/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2884 - accuracy: 0.9453 - val_loss: 0.5131 - val_accuracy: 0.8906\n",
      "Epoch 763/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2783 - accuracy: 0.9375 - val_loss: 0.4899 - val_accuracy: 0.8750\n",
      "Epoch 764/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2442 - accuracy: 0.9375 - val_loss: 0.5026 - val_accuracy: 0.8906\n",
      "Epoch 765/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2892 - accuracy: 0.9414 - val_loss: 0.4634 - val_accuracy: 0.8906\n",
      "Epoch 766/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2732 - accuracy: 0.9297 - val_loss: 0.4718 - val_accuracy: 0.8750\n",
      "Epoch 767/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2858 - accuracy: 0.9375 - val_loss: 0.4661 - val_accuracy: 0.8906\n",
      "Epoch 768/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2457 - accuracy: 0.9336 - val_loss: 0.5273 - val_accuracy: 0.8906\n",
      "Epoch 769/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2590 - accuracy: 0.9414 - val_loss: 0.4963 - val_accuracy: 0.8906\n",
      "Epoch 770/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2710 - accuracy: 0.9336 - val_loss: 0.5450 - val_accuracy: 0.8906\n",
      "Epoch 771/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2634 - accuracy: 0.9375 - val_loss: 0.5014 - val_accuracy: 0.8906\n",
      "Epoch 772/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3158 - accuracy: 0.9336 - val_loss: 0.4916 - val_accuracy: 0.8906\n",
      "Epoch 773/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2602 - accuracy: 0.9414 - val_loss: 0.5395 - val_accuracy: 0.8906\n",
      "Epoch 774/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2797 - accuracy: 0.9336 - val_loss: 0.4952 - val_accuracy: 0.8906\n",
      "Epoch 775/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2958 - accuracy: 0.9375 - val_loss: 0.5156 - val_accuracy: 0.8906\n",
      "Epoch 776/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2621 - accuracy: 0.9414 - val_loss: 0.5683 - val_accuracy: 0.8906\n",
      "Epoch 777/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2725 - accuracy: 0.9336 - val_loss: 0.5700 - val_accuracy: 0.8906\n",
      "Epoch 778/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2959 - accuracy: 0.9297 - val_loss: 0.5539 - val_accuracy: 0.8906\n",
      "Epoch 779/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2679 - accuracy: 0.9453 - val_loss: 0.5098 - val_accuracy: 0.8906\n",
      "Epoch 780/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2785 - accuracy: 0.9297 - val_loss: 0.4884 - val_accuracy: 0.8906\n",
      "Epoch 781/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2651 - accuracy: 0.9336 - val_loss: 0.5209 - val_accuracy: 0.8906\n",
      "Epoch 782/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2820 - accuracy: 0.9297 - val_loss: 0.5144 - val_accuracy: 0.8906\n",
      "Epoch 783/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2796 - accuracy: 0.9336 - val_loss: 0.4880 - val_accuracy: 0.8906\n",
      "Epoch 784/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2875 - accuracy: 0.9453 - val_loss: 0.5312 - val_accuracy: 0.8906\n",
      "Epoch 785/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3217 - accuracy: 0.9375 - val_loss: 0.5189 - val_accuracy: 0.8906\n",
      "Epoch 786/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2780 - accuracy: 0.9375 - val_loss: 0.6194 - val_accuracy: 0.8906\n",
      "Epoch 787/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3001 - accuracy: 0.9297 - val_loss: 0.5011 - val_accuracy: 0.8906\n",
      "Epoch 788/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2923 - accuracy: 0.9336 - val_loss: 0.4839 - val_accuracy: 0.8906\n",
      "Epoch 789/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2750 - accuracy: 0.9375 - val_loss: 0.4739 - val_accuracy: 0.8750\n",
      "Epoch 790/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2928 - accuracy: 0.9336 - val_loss: 0.5283 - val_accuracy: 0.8906\n",
      "Epoch 791/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2479 - accuracy: 0.9375 - val_loss: 0.4876 - val_accuracy: 0.8906\n",
      "Epoch 792/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2529 - accuracy: 0.9297 - val_loss: 0.5581 - val_accuracy: 0.8750\n",
      "Epoch 793/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2927 - accuracy: 0.9414 - val_loss: 0.5320 - val_accuracy: 0.8906\n",
      "Epoch 794/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2878 - accuracy: 0.9336 - val_loss: 0.4942 - val_accuracy: 0.8906\n",
      "Epoch 795/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2661 - accuracy: 0.9414 - val_loss: 0.4972 - val_accuracy: 0.8906\n",
      "Epoch 796/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2738 - accuracy: 0.9375 - val_loss: 0.4705 - val_accuracy: 0.8906\n",
      "Epoch 797/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2444 - accuracy: 0.9375 - val_loss: 0.5922 - val_accuracy: 0.8750\n",
      "Epoch 798/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2728 - accuracy: 0.9375 - val_loss: 0.4680 - val_accuracy: 0.8906\n",
      "Epoch 799/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2758 - accuracy: 0.9375 - val_loss: 0.4947 - val_accuracy: 0.8906\n",
      "Epoch 800/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2597 - accuracy: 0.9297 - val_loss: 0.4566 - val_accuracy: 0.8594\n",
      "Epoch 801/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2926 - accuracy: 0.9375 - val_loss: 0.4536 - val_accuracy: 0.8750\n",
      "Epoch 802/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2731 - accuracy: 0.9336 - val_loss: 0.5012 - val_accuracy: 0.8906\n",
      "Epoch 803/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2663 - accuracy: 0.9375 - val_loss: 0.5042 - val_accuracy: 0.8906\n",
      "Epoch 804/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2787 - accuracy: 0.9375 - val_loss: 0.4845 - val_accuracy: 0.8750\n",
      "Epoch 805/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2630 - accuracy: 0.9414 - val_loss: 0.5125 - val_accuracy: 0.8750\n",
      "Epoch 806/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2436 - accuracy: 0.9375 - val_loss: 0.5215 - val_accuracy: 0.8750\n",
      "Epoch 807/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2803 - accuracy: 0.9297 - val_loss: 0.4857 - val_accuracy: 0.8750\n",
      "Epoch 808/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2996 - accuracy: 0.9375 - val_loss: 0.4865 - val_accuracy: 0.8750\n",
      "Epoch 809/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2429 - accuracy: 0.9414 - val_loss: 0.5090 - val_accuracy: 0.8906\n",
      "Epoch 810/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2743 - accuracy: 0.9297 - val_loss: 0.4945 - val_accuracy: 0.8750\n",
      "Epoch 811/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3353 - accuracy: 0.9336 - val_loss: 0.5023 - val_accuracy: 0.8906\n",
      "Epoch 812/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2922 - accuracy: 0.9375 - val_loss: 0.4697 - val_accuracy: 0.8594\n",
      "Epoch 813/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2659 - accuracy: 0.9375 - val_loss: 0.5206 - val_accuracy: 0.8906\n",
      "Epoch 814/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3147 - accuracy: 0.9414 - val_loss: 0.5107 - val_accuracy: 0.8906\n",
      "Epoch 815/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2767 - accuracy: 0.9414 - val_loss: 0.4800 - val_accuracy: 0.8750\n",
      "Epoch 816/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2821 - accuracy: 0.9336 - val_loss: 0.4710 - val_accuracy: 0.8594\n",
      "Epoch 817/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2613 - accuracy: 0.9375 - val_loss: 0.5197 - val_accuracy: 0.8906\n",
      "Epoch 818/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3029 - accuracy: 0.9375 - val_loss: 0.4848 - val_accuracy: 0.8750\n",
      "Epoch 819/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2874 - accuracy: 0.9453 - val_loss: 0.5020 - val_accuracy: 0.8906\n",
      "Epoch 820/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3103 - accuracy: 0.9297 - val_loss: 0.4993 - val_accuracy: 0.8906\n",
      "Epoch 821/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2858 - accuracy: 0.9297 - val_loss: 0.4745 - val_accuracy: 0.8750\n",
      "Epoch 822/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2885 - accuracy: 0.9414 - val_loss: 0.4916 - val_accuracy: 0.8750\n",
      "Epoch 823/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2814 - accuracy: 0.9297 - val_loss: 0.4944 - val_accuracy: 0.8750\n",
      "Epoch 824/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2880 - accuracy: 0.9375 - val_loss: 0.4727 - val_accuracy: 0.8750\n",
      "Epoch 825/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2880 - accuracy: 0.9375 - val_loss: 0.4745 - val_accuracy: 0.8750\n",
      "Epoch 826/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3088 - accuracy: 0.9336 - val_loss: 0.4569 - val_accuracy: 0.8750\n",
      "Epoch 827/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2980 - accuracy: 0.9336 - val_loss: 0.4830 - val_accuracy: 0.8750\n",
      "Epoch 828/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2931 - accuracy: 0.9414 - val_loss: 0.4713 - val_accuracy: 0.8750\n",
      "Epoch 829/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2873 - accuracy: 0.9336 - val_loss: 0.4390 - val_accuracy: 0.8750\n",
      "Epoch 830/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2943 - accuracy: 0.9336 - val_loss: 0.4792 - val_accuracy: 0.8750\n",
      "Epoch 831/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2834 - accuracy: 0.9375 - val_loss: 0.4997 - val_accuracy: 0.8750\n",
      "Epoch 832/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2864 - accuracy: 0.9336 - val_loss: 0.4904 - val_accuracy: 0.8750\n",
      "Epoch 833/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3331 - accuracy: 0.9414 - val_loss: 0.4819 - val_accuracy: 0.8750\n",
      "Epoch 834/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3142 - accuracy: 0.9375 - val_loss: 0.4609 - val_accuracy: 0.8750\n",
      "Epoch 835/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3186 - accuracy: 0.9414 - val_loss: 0.4579 - val_accuracy: 0.8750\n",
      "Epoch 836/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2751 - accuracy: 0.9375 - val_loss: 0.4742 - val_accuracy: 0.8906\n",
      "Epoch 837/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3150 - accuracy: 0.9336 - val_loss: 0.4503 - val_accuracy: 0.8750\n",
      "Epoch 838/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3069 - accuracy: 0.9375 - val_loss: 0.4513 - val_accuracy: 0.8750\n",
      "Epoch 839/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3104 - accuracy: 0.9297 - val_loss: 0.5554 - val_accuracy: 0.8594\n",
      "Epoch 840/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3240 - accuracy: 0.9297 - val_loss: 0.4872 - val_accuracy: 0.8906\n",
      "Epoch 841/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2965 - accuracy: 0.9336 - val_loss: 0.4966 - val_accuracy: 0.8906\n",
      "Epoch 842/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3206 - accuracy: 0.9375 - val_loss: 0.4804 - val_accuracy: 0.8594\n",
      "Epoch 843/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2824 - accuracy: 0.9414 - val_loss: 0.5421 - val_accuracy: 0.8594\n",
      "Epoch 844/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3183 - accuracy: 0.9336 - val_loss: 0.5476 - val_accuracy: 0.8750\n",
      "Epoch 845/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3301 - accuracy: 0.9336 - val_loss: 0.4671 - val_accuracy: 0.8281\n",
      "Epoch 846/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3133 - accuracy: 0.9453 - val_loss: 0.4917 - val_accuracy: 0.8594\n",
      "Epoch 847/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3217 - accuracy: 0.9297 - val_loss: 0.5405 - val_accuracy: 0.8750\n",
      "Epoch 848/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3113 - accuracy: 0.9414 - val_loss: 0.6021 - val_accuracy: 0.8594\n",
      "Epoch 849/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3583 - accuracy: 0.9336 - val_loss: 0.4936 - val_accuracy: 0.8594\n",
      "Epoch 850/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3287 - accuracy: 0.9375 - val_loss: 0.5033 - val_accuracy: 0.8594\n",
      "Epoch 851/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.2933 - accuracy: 0.9375 - val_loss: 0.5221 - val_accuracy: 0.8906\n",
      "Epoch 852/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3327 - accuracy: 0.9414 - val_loss: 0.4799 - val_accuracy: 0.8594\n",
      "Epoch 853/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3561 - accuracy: 0.9375 - val_loss: 0.5044 - val_accuracy: 0.8906\n",
      "Epoch 854/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3270 - accuracy: 0.9414 - val_loss: 0.4924 - val_accuracy: 0.8750\n",
      "Epoch 855/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3513 - accuracy: 0.9375 - val_loss: 0.5564 - val_accuracy: 0.8438\n",
      "Epoch 856/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3525 - accuracy: 0.9414 - val_loss: 0.5169 - val_accuracy: 0.8438\n",
      "Epoch 857/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3379 - accuracy: 0.9375 - val_loss: 0.4809 - val_accuracy: 0.8750\n",
      "Epoch 858/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3368 - accuracy: 0.9336 - val_loss: 0.4818 - val_accuracy: 0.8594\n",
      "Epoch 859/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3349 - accuracy: 0.9375 - val_loss: 0.4650 - val_accuracy: 0.8594\n",
      "Epoch 860/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3111 - accuracy: 0.9375 - val_loss: 0.5031 - val_accuracy: 0.8750\n",
      "Epoch 861/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3442 - accuracy: 0.9297 - val_loss: 0.4866 - val_accuracy: 0.8750\n",
      "Epoch 862/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3329 - accuracy: 0.9414 - val_loss: 0.4801 - val_accuracy: 0.8438\n",
      "Epoch 863/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3040 - accuracy: 0.9297 - val_loss: 0.5791 - val_accuracy: 0.8906\n",
      "Epoch 864/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3516 - accuracy: 0.9336 - val_loss: 0.5717 - val_accuracy: 0.8594\n",
      "Epoch 865/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3291 - accuracy: 0.9258 - val_loss: 0.5048 - val_accuracy: 0.8594\n",
      "Epoch 866/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3286 - accuracy: 0.9336 - val_loss: 0.5024 - val_accuracy: 0.8438\n",
      "Epoch 867/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3180 - accuracy: 0.9258 - val_loss: 0.5635 - val_accuracy: 0.8594\n",
      "Epoch 868/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3127 - accuracy: 0.9297 - val_loss: 0.5061 - val_accuracy: 0.8750\n",
      "Epoch 869/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3158 - accuracy: 0.9219 - val_loss: 0.5740 - val_accuracy: 0.8594\n",
      "Epoch 870/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3275 - accuracy: 0.9297 - val_loss: 0.5499 - val_accuracy: 0.8750\n",
      "Epoch 871/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3308 - accuracy: 0.9297 - val_loss: 0.5834 - val_accuracy: 0.8438\n",
      "Epoch 872/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3291 - accuracy: 0.9297 - val_loss: 0.5803 - val_accuracy: 0.8281\n",
      "Epoch 873/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3157 - accuracy: 0.9258 - val_loss: 0.5651 - val_accuracy: 0.8438\n",
      "Epoch 874/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3347 - accuracy: 0.9297 - val_loss: 0.5453 - val_accuracy: 0.8906\n",
      "Epoch 875/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3076 - accuracy: 0.9258 - val_loss: 0.5888 - val_accuracy: 0.8594\n",
      "Epoch 876/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3462 - accuracy: 0.9297 - val_loss: 0.5237 - val_accuracy: 0.8594\n",
      "Epoch 877/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3395 - accuracy: 0.9336 - val_loss: 0.6129 - val_accuracy: 0.8906\n",
      "Epoch 878/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3261 - accuracy: 0.9297 - val_loss: 0.6555 - val_accuracy: 0.7969\n",
      "Epoch 879/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3369 - accuracy: 0.9258 - val_loss: 0.6104 - val_accuracy: 0.8438\n",
      "Epoch 880/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3424 - accuracy: 0.9258 - val_loss: 0.6287 - val_accuracy: 0.8281\n",
      "Epoch 881/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3347 - accuracy: 0.9258 - val_loss: 0.5907 - val_accuracy: 0.8281\n",
      "Epoch 882/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3425 - accuracy: 0.9336 - val_loss: 0.6019 - val_accuracy: 0.8750\n",
      "Epoch 883/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3256 - accuracy: 0.9336 - val_loss: 0.5990 - val_accuracy: 0.8750\n",
      "Epoch 884/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3214 - accuracy: 0.9258 - val_loss: 0.5172 - val_accuracy: 0.8906\n",
      "Epoch 885/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3378 - accuracy: 0.9375 - val_loss: 0.6082 - val_accuracy: 0.8594\n",
      "Epoch 886/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3340 - accuracy: 0.9375 - val_loss: 0.5681 - val_accuracy: 0.8438\n",
      "Epoch 887/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3239 - accuracy: 0.9375 - val_loss: 0.5954 - val_accuracy: 0.8438\n",
      "Epoch 888/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3376 - accuracy: 0.9258 - val_loss: 0.6218 - val_accuracy: 0.8438\n",
      "Epoch 889/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3376 - accuracy: 0.9297 - val_loss: 0.5887 - val_accuracy: 0.8906\n",
      "Epoch 890/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3411 - accuracy: 0.9258 - val_loss: 0.6386 - val_accuracy: 0.8594\n",
      "Epoch 891/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3263 - accuracy: 0.9375 - val_loss: 0.6089 - val_accuracy: 0.8750\n",
      "Epoch 892/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3612 - accuracy: 0.9258 - val_loss: 0.5846 - val_accuracy: 0.8750\n",
      "Epoch 893/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3082 - accuracy: 0.9258 - val_loss: 0.6268 - val_accuracy: 0.8750\n",
      "Epoch 894/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3496 - accuracy: 0.9336 - val_loss: 0.6172 - val_accuracy: 0.8750\n",
      "Epoch 895/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3165 - accuracy: 0.9375 - val_loss: 0.5018 - val_accuracy: 0.8594\n",
      "Epoch 896/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3492 - accuracy: 0.9219 - val_loss: 0.6438 - val_accuracy: 0.8594\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3192 - accuracy: 0.9297 - val_loss: 0.5319 - val_accuracy: 0.8750\n",
      "Epoch 898/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3337 - accuracy: 0.9336 - val_loss: 0.6215 - val_accuracy: 0.8906\n",
      "Epoch 899/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3557 - accuracy: 0.9258 - val_loss: 0.6430 - val_accuracy: 0.8750\n",
      "Epoch 900/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3340 - accuracy: 0.9297 - val_loss: 0.6406 - val_accuracy: 0.8438\n",
      "Epoch 901/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3256 - accuracy: 0.9258 - val_loss: 0.5881 - val_accuracy: 0.8281\n",
      "Epoch 902/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3183 - accuracy: 0.9297 - val_loss: 0.5746 - val_accuracy: 0.8750\n",
      "Epoch 903/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3261 - accuracy: 0.9453 - val_loss: 0.5246 - val_accuracy: 0.8750\n",
      "Epoch 904/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3192 - accuracy: 0.9375 - val_loss: 0.6571 - val_accuracy: 0.8750\n",
      "Epoch 905/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3513 - accuracy: 0.9375 - val_loss: 0.6099 - val_accuracy: 0.8594\n",
      "Epoch 906/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3436 - accuracy: 0.9414 - val_loss: 0.6065 - val_accuracy: 0.8438\n",
      "Epoch 907/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3416 - accuracy: 0.9336 - val_loss: 0.5361 - val_accuracy: 0.8750\n",
      "Epoch 908/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3353 - accuracy: 0.9414 - val_loss: 0.6178 - val_accuracy: 0.8594\n",
      "Epoch 909/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3335 - accuracy: 0.9414 - val_loss: 0.6330 - val_accuracy: 0.8750\n",
      "Epoch 910/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3261 - accuracy: 0.9414 - val_loss: 0.5595 - val_accuracy: 0.8750\n",
      "Epoch 911/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3421 - accuracy: 0.9453 - val_loss: 0.5870 - val_accuracy: 0.8750\n",
      "Epoch 912/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3487 - accuracy: 0.9414 - val_loss: 0.6374 - val_accuracy: 0.8750\n",
      "Epoch 913/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3837 - accuracy: 0.9336 - val_loss: 0.5794 - val_accuracy: 0.8750\n",
      "Epoch 914/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3157 - accuracy: 0.9453 - val_loss: 0.5845 - val_accuracy: 0.8750\n",
      "Epoch 915/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3595 - accuracy: 0.9375 - val_loss: 0.5549 - val_accuracy: 0.8750\n",
      "Epoch 916/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3389 - accuracy: 0.9453 - val_loss: 0.6165 - val_accuracy: 0.8750\n",
      "Epoch 917/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3440 - accuracy: 0.9453 - val_loss: 0.6340 - val_accuracy: 0.8750\n",
      "Epoch 918/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3897 - accuracy: 0.9453 - val_loss: 0.6538 - val_accuracy: 0.8750\n",
      "Epoch 919/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3353 - accuracy: 0.9453 - val_loss: 0.5682 - val_accuracy: 0.8750\n",
      "Epoch 920/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3334 - accuracy: 0.9336 - val_loss: 0.6246 - val_accuracy: 0.8750\n",
      "Epoch 921/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3344 - accuracy: 0.9375 - val_loss: 0.5616 - val_accuracy: 0.8750\n",
      "Epoch 922/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3543 - accuracy: 0.9453 - val_loss: 0.5811 - val_accuracy: 0.8750\n",
      "Epoch 923/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3342 - accuracy: 0.9414 - val_loss: 0.5898 - val_accuracy: 0.8750\n",
      "Epoch 924/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3505 - accuracy: 0.9414 - val_loss: 0.5581 - val_accuracy: 0.8750\n",
      "Epoch 925/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3859 - accuracy: 0.9375 - val_loss: 0.6776 - val_accuracy: 0.8750\n",
      "Epoch 926/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3358 - accuracy: 0.9414 - val_loss: 0.6108 - val_accuracy: 0.8750\n",
      "Epoch 927/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3498 - accuracy: 0.9375 - val_loss: 0.6333 - val_accuracy: 0.8750\n",
      "Epoch 928/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3589 - accuracy: 0.9414 - val_loss: 0.6650 - val_accuracy: 0.8594\n",
      "Epoch 929/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3410 - accuracy: 0.9375 - val_loss: 0.6529 - val_accuracy: 0.8594\n",
      "Epoch 930/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3315 - accuracy: 0.9453 - val_loss: 0.6003 - val_accuracy: 0.8750\n",
      "Epoch 931/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3533 - accuracy: 0.9414 - val_loss: 0.6185 - val_accuracy: 0.8750\n",
      "Epoch 932/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3393 - accuracy: 0.9453 - val_loss: 0.5549 - val_accuracy: 0.8750\n",
      "Epoch 933/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3342 - accuracy: 0.9414 - val_loss: 0.6491 - val_accuracy: 0.8750\n",
      "Epoch 934/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3341 - accuracy: 0.9453 - val_loss: 0.6008 - val_accuracy: 0.8750\n",
      "Epoch 935/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3408 - accuracy: 0.9414 - val_loss: 0.5597 - val_accuracy: 0.8750\n",
      "Epoch 936/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3607 - accuracy: 0.9453 - val_loss: 0.5769 - val_accuracy: 0.8750\n",
      "Epoch 937/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3363 - accuracy: 0.9336 - val_loss: 0.5967 - val_accuracy: 0.8906\n",
      "Epoch 938/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3243 - accuracy: 0.9414 - val_loss: 0.5767 - val_accuracy: 0.8750\n",
      "Epoch 939/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3602 - accuracy: 0.9375 - val_loss: 0.6383 - val_accuracy: 0.8906\n",
      "Epoch 940/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3250 - accuracy: 0.9414 - val_loss: 0.6005 - val_accuracy: 0.8750\n",
      "Epoch 941/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3018 - accuracy: 0.9414 - val_loss: 0.6475 - val_accuracy: 0.8750\n",
      "Epoch 942/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.9453 - val_loss: 0.6119 - val_accuracy: 0.8750\n",
      "Epoch 943/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3247 - accuracy: 0.9453 - val_loss: 0.6354 - val_accuracy: 0.8750\n",
      "Epoch 944/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3492 - accuracy: 0.9414 - val_loss: 0.6249 - val_accuracy: 0.8594\n",
      "Epoch 945/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3229 - accuracy: 0.9453 - val_loss: 0.6546 - val_accuracy: 0.8750\n",
      "Epoch 946/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3569 - accuracy: 0.9375 - val_loss: 0.6111 - val_accuracy: 0.8750\n",
      "Epoch 947/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3247 - accuracy: 0.9375 - val_loss: 0.6122 - val_accuracy: 0.8906\n",
      "Epoch 948/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3294 - accuracy: 0.9375 - val_loss: 0.6136 - val_accuracy: 0.8750\n",
      "Epoch 949/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3306 - accuracy: 0.9414 - val_loss: 0.6097 - val_accuracy: 0.8906\n",
      "Epoch 950/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3305 - accuracy: 0.9375 - val_loss: 0.5778 - val_accuracy: 0.9062\n",
      "Epoch 951/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3175 - accuracy: 0.9336 - val_loss: 0.5656 - val_accuracy: 0.9062\n",
      "Epoch 952/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3126 - accuracy: 0.9375 - val_loss: 0.6086 - val_accuracy: 0.9062\n",
      "Epoch 953/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3578 - accuracy: 0.9414 - val_loss: 0.5972 - val_accuracy: 0.9062\n",
      "Epoch 954/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3429 - accuracy: 0.9336 - val_loss: 0.5674 - val_accuracy: 0.8906\n",
      "Epoch 955/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3393 - accuracy: 0.9414 - val_loss: 0.5245 - val_accuracy: 0.8906\n",
      "Epoch 956/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3532 - accuracy: 0.9375 - val_loss: 0.6155 - val_accuracy: 0.8906\n",
      "Epoch 957/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3256 - accuracy: 0.9414 - val_loss: 0.6127 - val_accuracy: 0.9062\n",
      "Epoch 958/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3353 - accuracy: 0.9453 - val_loss: 0.5529 - val_accuracy: 0.9062\n",
      "Epoch 959/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3330 - accuracy: 0.9453 - val_loss: 0.5567 - val_accuracy: 0.8906\n",
      "Epoch 960/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3348 - accuracy: 0.9375 - val_loss: 0.6005 - val_accuracy: 0.8906\n",
      "Epoch 961/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3614 - accuracy: 0.9453 - val_loss: 0.5895 - val_accuracy: 0.8750\n",
      "Epoch 962/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3669 - accuracy: 0.9336 - val_loss: 0.5887 - val_accuracy: 0.9062\n",
      "Epoch 963/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3430 - accuracy: 0.9414 - val_loss: 0.5779 - val_accuracy: 0.9062\n",
      "Epoch 964/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3289 - accuracy: 0.9414 - val_loss: 0.5910 - val_accuracy: 0.9062\n",
      "Epoch 965/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3348 - accuracy: 0.9375 - val_loss: 0.5924 - val_accuracy: 0.9062\n",
      "Epoch 966/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3270 - accuracy: 0.9414 - val_loss: 0.6256 - val_accuracy: 0.8750\n",
      "Epoch 967/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3648 - accuracy: 0.9453 - val_loss: 0.6335 - val_accuracy: 0.8906\n",
      "Epoch 968/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3382 - accuracy: 0.9414 - val_loss: 0.5745 - val_accuracy: 0.8906\n",
      "Epoch 969/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3350 - accuracy: 0.9453 - val_loss: 0.5903 - val_accuracy: 0.8750\n",
      "Epoch 970/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3393 - accuracy: 0.9414 - val_loss: 0.5446 - val_accuracy: 0.8906\n",
      "Epoch 971/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3329 - accuracy: 0.9414 - val_loss: 0.5799 - val_accuracy: 0.8906\n",
      "Epoch 972/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3482 - accuracy: 0.9414 - val_loss: 0.5628 - val_accuracy: 0.9062\n",
      "Epoch 973/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3354 - accuracy: 0.9414 - val_loss: 0.6126 - val_accuracy: 0.8750\n",
      "Epoch 974/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3504 - accuracy: 0.9453 - val_loss: 0.5309 - val_accuracy: 0.8750\n",
      "Epoch 975/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3382 - accuracy: 0.9414 - val_loss: 0.5963 - val_accuracy: 0.8750\n",
      "Epoch 976/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3446 - accuracy: 0.9414 - val_loss: 0.5761 - val_accuracy: 0.8750\n",
      "Epoch 977/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3153 - accuracy: 0.9414 - val_loss: 0.6223 - val_accuracy: 0.8594\n",
      "Epoch 978/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3440 - accuracy: 0.9453 - val_loss: 0.6212 - val_accuracy: 0.8594\n",
      "Epoch 979/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3363 - accuracy: 0.9414 - val_loss: 0.5735 - val_accuracy: 0.8906\n",
      "Epoch 980/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3581 - accuracy: 0.9375 - val_loss: 0.5508 - val_accuracy: 0.8906\n",
      "Epoch 981/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3426 - accuracy: 0.9336 - val_loss: 0.5937 - val_accuracy: 0.8906\n",
      "Epoch 982/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3459 - accuracy: 0.9414 - val_loss: 0.5933 - val_accuracy: 0.8906\n",
      "Epoch 983/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3464 - accuracy: 0.9414 - val_loss: 0.4971 - val_accuracy: 0.8906\n",
      "Epoch 984/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3522 - accuracy: 0.9414 - val_loss: 0.6377 - val_accuracy: 0.8750\n",
      "Epoch 985/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3285 - accuracy: 0.9453 - val_loss: 0.5773 - val_accuracy: 0.8750\n",
      "Epoch 986/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3180 - accuracy: 0.9414 - val_loss: 0.6386 - val_accuracy: 0.9062\n",
      "Epoch 987/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3246 - accuracy: 0.9453 - val_loss: 0.5321 - val_accuracy: 0.8906\n",
      "Epoch 988/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3874 - accuracy: 0.9414 - val_loss: 0.5851 - val_accuracy: 0.8906\n",
      "Epoch 989/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3632 - accuracy: 0.9414 - val_loss: 0.5303 - val_accuracy: 0.8750\n",
      "Epoch 990/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3690 - accuracy: 0.9414 - val_loss: 0.6203 - val_accuracy: 0.8906\n",
      "Epoch 991/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3363 - accuracy: 0.9453 - val_loss: 0.5267 - val_accuracy: 0.8906\n",
      "Epoch 992/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3605 - accuracy: 0.9414 - val_loss: 0.5839 - val_accuracy: 0.8906\n",
      "Epoch 993/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3514 - accuracy: 0.9414 - val_loss: 0.6060 - val_accuracy: 0.8750\n",
      "Epoch 994/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3396 - accuracy: 0.9453 - val_loss: 0.5480 - val_accuracy: 0.8906\n",
      "Epoch 995/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3599 - accuracy: 0.9336 - val_loss: 0.5883 - val_accuracy: 0.8906\n",
      "Epoch 996/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3701 - accuracy: 0.9375 - val_loss: 0.5940 - val_accuracy: 0.9062\n",
      "Epoch 997/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3211 - accuracy: 0.9375 - val_loss: 0.6344 - val_accuracy: 0.8750\n",
      "Epoch 998/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3337 - accuracy: 0.9414 - val_loss: 0.6359 - val_accuracy: 0.8906\n",
      "Epoch 999/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3683 - accuracy: 0.9414 - val_loss: 0.5903 - val_accuracy: 0.8906\n",
      "Epoch 1000/1000\n",
      "256/256 [==============================] - 1s 2ms/step - loss: 0.3733 - accuracy: 0.9375 - val_loss: 0.6505 - val_accuracy: 0.8906\n",
      "558.8057968616486\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10,activation='relu',input_dim=3))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "start = time.time()\n",
    "model.compile(loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train,y_train,epochs=1000,batch_size=1,validation_split=0.2)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ee70f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24d06e98e80>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5e5cead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24d06eee1f0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74804107",
   "metadata": {},
   "source": [
    "# Comparision between BGD Vs SGD\n",
    "\n",
    "- Batch Gradient Descent is faster in same number of epochs\n",
    "- Stochastic Gradient Descent convergence faster\n",
    "\n",
    "\n",
    " ### Spiky Stochastic Gradient Descent is useful ?\n",
    "\n",
    "    - yes: batch gradient descent can stop in local minima, where SGD not.\n",
    "    - No: Not convergence at exact point but it is aproximation\n",
    "\n",
    " ### Vectorization:\n",
    "    - we are smartly applying dot product instead of loop which is faster.\n",
    "    - downside of vectorization is it will consume high ram during big datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0e5cd4",
   "metadata": {},
   "source": [
    "# Mini Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a8afdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7124 - accuracy: 0.4969 - val_loss: 0.7059 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6980 - accuracy: 0.5125 - val_loss: 0.7026 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6883 - accuracy: 0.5125 - val_loss: 0.7017 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6809 - accuracy: 0.5125 - val_loss: 0.7011 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6745 - accuracy: 0.5219 - val_loss: 0.6982 - val_accuracy: 0.4875\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6692 - accuracy: 0.5312 - val_loss: 0.6973 - val_accuracy: 0.4875\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6635 - accuracy: 0.5375 - val_loss: 0.6954 - val_accuracy: 0.4875\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6584 - accuracy: 0.5688 - val_loss: 0.6918 - val_accuracy: 0.4875\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6536 - accuracy: 0.5813 - val_loss: 0.6880 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6490 - accuracy: 0.6156 - val_loss: 0.6883 - val_accuracy: 0.4625\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6441 - accuracy: 0.6406 - val_loss: 0.6861 - val_accuracy: 0.4875\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6389 - accuracy: 0.6969 - val_loss: 0.6854 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6343 - accuracy: 0.7344 - val_loss: 0.6847 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6294 - accuracy: 0.7500 - val_loss: 0.6850 - val_accuracy: 0.4750\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6242 - accuracy: 0.7531 - val_loss: 0.6841 - val_accuracy: 0.4750\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6201 - accuracy: 0.7656 - val_loss: 0.6811 - val_accuracy: 0.4750\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6153 - accuracy: 0.7656 - val_loss: 0.6810 - val_accuracy: 0.4625\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6101 - accuracy: 0.7719 - val_loss: 0.6806 - val_accuracy: 0.4750\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6056 - accuracy: 0.7750 - val_loss: 0.6782 - val_accuracy: 0.5125\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6010 - accuracy: 0.7750 - val_loss: 0.6759 - val_accuracy: 0.5250\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5962 - accuracy: 0.7875 - val_loss: 0.6745 - val_accuracy: 0.5375\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5913 - accuracy: 0.7937 - val_loss: 0.6699 - val_accuracy: 0.5500\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5865 - accuracy: 0.7937 - val_loss: 0.6686 - val_accuracy: 0.5500\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5817 - accuracy: 0.8000 - val_loss: 0.6663 - val_accuracy: 0.5500\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5772 - accuracy: 0.8000 - val_loss: 0.6635 - val_accuracy: 0.5375\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5724 - accuracy: 0.7937 - val_loss: 0.6577 - val_accuracy: 0.5875\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5680 - accuracy: 0.8094 - val_loss: 0.6562 - val_accuracy: 0.5750\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5638 - accuracy: 0.8156 - val_loss: 0.6553 - val_accuracy: 0.5625\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5588 - accuracy: 0.8125 - val_loss: 0.6530 - val_accuracy: 0.5625\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5541 - accuracy: 0.8156 - val_loss: 0.6507 - val_accuracy: 0.5750\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5493 - accuracy: 0.8156 - val_loss: 0.6465 - val_accuracy: 0.6000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5440 - accuracy: 0.8188 - val_loss: 0.6431 - val_accuracy: 0.6125\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5397 - accuracy: 0.8156 - val_loss: 0.6425 - val_accuracy: 0.6250\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5348 - accuracy: 0.8125 - val_loss: 0.6396 - val_accuracy: 0.6375\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5304 - accuracy: 0.8125 - val_loss: 0.6362 - val_accuracy: 0.6375\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5259 - accuracy: 0.8125 - val_loss: 0.6322 - val_accuracy: 0.6375\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5212 - accuracy: 0.8188 - val_loss: 0.6283 - val_accuracy: 0.6375\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5165 - accuracy: 0.8156 - val_loss: 0.6288 - val_accuracy: 0.6375\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5119 - accuracy: 0.8188 - val_loss: 0.6269 - val_accuracy: 0.6375\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5077 - accuracy: 0.8156 - val_loss: 0.6247 - val_accuracy: 0.6375\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5027 - accuracy: 0.8156 - val_loss: 0.6228 - val_accuracy: 0.6375\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4980 - accuracy: 0.8156 - val_loss: 0.6214 - val_accuracy: 0.6375\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4937 - accuracy: 0.8156 - val_loss: 0.6195 - val_accuracy: 0.6375\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4894 - accuracy: 0.8188 - val_loss: 0.6195 - val_accuracy: 0.6500\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4855 - accuracy: 0.8188 - val_loss: 0.6191 - val_accuracy: 0.6500\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4810 - accuracy: 0.8188 - val_loss: 0.6140 - val_accuracy: 0.6500\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4765 - accuracy: 0.8219 - val_loss: 0.6116 - val_accuracy: 0.6625\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4721 - accuracy: 0.8281 - val_loss: 0.6085 - val_accuracy: 0.6625\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4683 - accuracy: 0.8344 - val_loss: 0.6096 - val_accuracy: 0.6625\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4642 - accuracy: 0.8281 - val_loss: 0.6080 - val_accuracy: 0.6625\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4600 - accuracy: 0.8313 - val_loss: 0.6067 - val_accuracy: 0.6625\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4563 - accuracy: 0.8313 - val_loss: 0.6052 - val_accuracy: 0.6625\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4523 - accuracy: 0.8313 - val_loss: 0.6026 - val_accuracy: 0.6625\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4481 - accuracy: 0.8313 - val_loss: 0.6010 - val_accuracy: 0.6625\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4442 - accuracy: 0.8344 - val_loss: 0.5993 - val_accuracy: 0.6625\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4407 - accuracy: 0.8344 - val_loss: 0.5994 - val_accuracy: 0.6750\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4372 - accuracy: 0.8344 - val_loss: 0.5992 - val_accuracy: 0.6750\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4337 - accuracy: 0.8313 - val_loss: 0.5917 - val_accuracy: 0.6750\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4301 - accuracy: 0.8344 - val_loss: 0.5872 - val_accuracy: 0.6750\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4265 - accuracy: 0.8313 - val_loss: 0.5844 - val_accuracy: 0.6750\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4239 - accuracy: 0.8313 - val_loss: 0.5809 - val_accuracy: 0.6750\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4203 - accuracy: 0.8313 - val_loss: 0.5786 - val_accuracy: 0.6750\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4165 - accuracy: 0.8313 - val_loss: 0.5753 - val_accuracy: 0.6750\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4129 - accuracy: 0.8344 - val_loss: 0.5779 - val_accuracy: 0.6750\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4100 - accuracy: 0.8313 - val_loss: 0.5779 - val_accuracy: 0.6750\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4072 - accuracy: 0.8313 - val_loss: 0.5780 - val_accuracy: 0.6750\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4042 - accuracy: 0.8344 - val_loss: 0.5760 - val_accuracy: 0.6750\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4015 - accuracy: 0.8375 - val_loss: 0.5717 - val_accuracy: 0.6750\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3986 - accuracy: 0.8375 - val_loss: 0.5670 - val_accuracy: 0.6750\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3957 - accuracy: 0.8406 - val_loss: 0.5687 - val_accuracy: 0.6750\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3930 - accuracy: 0.8406 - val_loss: 0.5669 - val_accuracy: 0.6750\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3907 - accuracy: 0.8406 - val_loss: 0.5621 - val_accuracy: 0.6875\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3876 - accuracy: 0.8406 - val_loss: 0.5621 - val_accuracy: 0.6875\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3849 - accuracy: 0.8375 - val_loss: 0.5608 - val_accuracy: 0.6750\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3824 - accuracy: 0.8375 - val_loss: 0.5562 - val_accuracy: 0.7000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3797 - accuracy: 0.8375 - val_loss: 0.5473 - val_accuracy: 0.7000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3770 - accuracy: 0.8375 - val_loss: 0.5424 - val_accuracy: 0.7125\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3740 - accuracy: 0.8406 - val_loss: 0.5376 - val_accuracy: 0.7125\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3715 - accuracy: 0.8438 - val_loss: 0.5305 - val_accuracy: 0.7250\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3691 - accuracy: 0.8500 - val_loss: 0.5275 - val_accuracy: 0.7250\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3666 - accuracy: 0.8500 - val_loss: 0.5238 - val_accuracy: 0.7250\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3643 - accuracy: 0.8500 - val_loss: 0.5207 - val_accuracy: 0.7250\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3622 - accuracy: 0.8500 - val_loss: 0.5171 - val_accuracy: 0.7250\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3598 - accuracy: 0.8438 - val_loss: 0.5174 - val_accuracy: 0.7250\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3577 - accuracy: 0.8469 - val_loss: 0.5153 - val_accuracy: 0.7250\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3553 - accuracy: 0.8469 - val_loss: 0.5167 - val_accuracy: 0.7250\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3536 - accuracy: 0.8500 - val_loss: 0.5117 - val_accuracy: 0.7250\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3513 - accuracy: 0.8469 - val_loss: 0.5059 - val_accuracy: 0.7250\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3492 - accuracy: 0.8469 - val_loss: 0.5033 - val_accuracy: 0.7375\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3472 - accuracy: 0.8500 - val_loss: 0.4978 - val_accuracy: 0.7375\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3455 - accuracy: 0.8469 - val_loss: 0.4954 - val_accuracy: 0.7375\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3438 - accuracy: 0.8469 - val_loss: 0.4876 - val_accuracy: 0.7500\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3419 - accuracy: 0.8500 - val_loss: 0.4817 - val_accuracy: 0.7500\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3404 - accuracy: 0.8500 - val_loss: 0.4762 - val_accuracy: 0.7500\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3386 - accuracy: 0.8500 - val_loss: 0.4749 - val_accuracy: 0.7500\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3369 - accuracy: 0.8500 - val_loss: 0.4758 - val_accuracy: 0.7500\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3352 - accuracy: 0.8500 - val_loss: 0.4743 - val_accuracy: 0.7500\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3340 - accuracy: 0.8469 - val_loss: 0.4715 - val_accuracy: 0.7500\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3327 - accuracy: 0.8500 - val_loss: 0.4648 - val_accuracy: 0.7625\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3310 - accuracy: 0.8500 - val_loss: 0.4632 - val_accuracy: 0.7625\n",
      "4.060720682144165\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10,activation='relu',input_dim=3))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "start = time.time()\n",
    "model.compile(loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_scaled,y,epochs=100,batch_size=150,validation_split=0.2)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a215cf",
   "metadata": {},
   "source": [
    "# Comparision between BGD Vs SGD vs MBGD\n",
    "### faster in same no of epochs\n",
    "- BGD > MBGD > SGD\n",
    "\n",
    "### Faster Convergece\n",
    "- SGD > MBGD > BGD\n",
    "\n",
    "### why batch size is multiple of 2. like 2,4,8,16....\n",
    "- RAM optimizer\n",
    "\n",
    "- Minibatch Gradient descent solve vectorization RAM problem as it convert dataset into small batches\n",
    "\n",
    "- if batch_size = 150 on above example :\n",
    "    number of batches = 400/150 = 3\n",
    "    batches are 150, 150, 100\n",
    "    \n",
    "- Generally we made a code with minibatch gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e118c201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.9(tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
